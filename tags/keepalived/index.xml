<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Keepalived on Daemon365</title><link>https://daemon365.dev/tags/keepalived/</link><description>Don't let yourself stop.</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Sat, 02 Nov 2024 17:42:54 +0800</lastBuildDate><atom:link href="https://daemon365.dev/tags/keepalived/index.xml" rel="self" type="application/rss+xml"/><item><title>kube-apiserver 高可用，keepalived + haproxy</title><link>https://daemon365.dev/post/cloud/keepalived_haproxy/</link><pubDate>Sat, 02 Nov 2024 17:42:54 +0800</pubDate><guid>https://daemon365.dev/post/cloud/keepalived_haproxy/</guid><description>&lt;h2 id="为什么要做高可用"&gt;为什么要做高可用&lt;/h2&gt;
&lt;p&gt;在生产环境中，kubernetes 集群中会多多个 master 节点，每个 master 节点上都会部署 kube-apiserver 服务，实现高可用。但是 client 访问 kube-apiserver 时，需要指定 ip 或者域名，这样会出现单点故障。官方推荐的做法是使用一个负载均衡器，将多个 kube-apiserver 服务负载均衡，实现高可用，但很多时候我们是没有这个条件的。这时候就得想想办法了，比如 nignx 转发，但是 nginx 也是单点。域名的方式，但是这种方式生效时间较长，不太适合紧急情况。所以这里介绍一种使用 keepalived + haproxy 的方式实现 kube-apiserver 的高可用。这是一共公用 IP 的方式，当主节点宕机时，VIP 会自动切换到备节点，实现高可用。&lt;/p&gt;</description><content:encoded><![CDATA[<h2 id="为什么要做高可用">为什么要做高可用</h2>
<p>在生产环境中，kubernetes 集群中会多多个 master 节点，每个 master 节点上都会部署 kube-apiserver 服务，实现高可用。但是 client 访问 kube-apiserver 时，需要指定 ip 或者域名，这样会出现单点故障。官方推荐的做法是使用一个负载均衡器，将多个 kube-apiserver 服务负载均衡，实现高可用，但很多时候我们是没有这个条件的。这时候就得想想办法了，比如 nignx 转发，但是 nginx 也是单点。域名的方式，但是这种方式生效时间较长，不太适合紧急情况。所以这里介绍一种使用 keepalived + haproxy 的方式实现 kube-apiserver 的高可用。这是一共公用 IP 的方式，当主节点宕机时，VIP 会自动切换到备节点，实现高可用。</p>
<h2 id="环境准备">环境准备</h2>
<ul>
<li>master1: 192.168.31.203</li>
<li>master2: 192.168.31.34</li>
<li>master3: 192.168.31.46</li>
<li>worker1: 192.168.31.25</li>
<li>VIP （虚拟IP）:  192.168.31.230</li>
</ul>
<h2 id="安装">安装</h2>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo apt install keepalived haproxy
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl <span style="color:#111">enable</span> haproxy
</span></span><span style="display:flex;"><span>systemctl restart haproxy
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>systemctl <span style="color:#111">enable</span> keepalived
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 没有配置会出现错误 不用管</span>
</span></span><span style="display:flex;"><span>systemctl restart keepalived
</span></span></code></pre></div><h2 id="配置-keepalived">配置 keepalived</h2>
<h3 id="配置文件">配置文件</h3>
<p>编辑 keepalived 配置文件</p>
<p>编辑 /etc/keepalived/keepalived.conf</p>
<p>master1：</p>
<pre tabindex="0"><code class="language-conf" data-lang="conf"># 健康检查 查看 haproxy 的进程在不在
vrrp_script chk_haproxy {
  script &#34;killall -0 haproxy&#34;
  interval 2 # 多少秒教程一次
  weight 3 # 成功了优先级加多少
}

vrrp_instance haproxy-vip {
  state MASTER # MASTER / BACKUP 1 MASTER 2 BACKUP
  priority 100 # 优先级 强的机器高一些 三台master 分别 100 99 98
  interface enp0s3     # 网卡名称
  virtual_router_id 51 # 路由 ip 默认就好
  advert_int 1 # keepalived 之间广播频率 秒
  authentication {
    auth_type PASS
    auth_pass test_k8s 
  }
  unicast_src_ip 192.168.31.203 # 自己和其他 keepalived 通信地址
  unicast_peer { 
    192.168.31.34                    # master2 的 IP 地址
    192.168.31.46                     # master3 的 IP 地址                   
  }

  virtual_ipaddress {
    192.168.31.230 # 这里必须和其他所有的ip 在一个局域网下
  }

  track_script {
    chk_haproxy
  }
}
</code></pre><p>master2：</p>
<pre tabindex="0"><code class="language-conf" data-lang="conf">vrrp_script chk_haproxy {
  script &#34;killall -0 haproxy&#34;
  interval 2
  weight 3
}

vrrp_instance haproxy-vip {
  state BACKUP
  priority 99
  interface enp0s3
  virtual_router_id 51
  advert_int 1
  authentication {
    auth_type PASS
    auth_pass test_k8s 
  }
  unicast_src_ip 192.168.31.34
  unicast_peer { 
    192.168.31.203
    192.168.31.46
  }

  virtual_ipaddress {
    192.168.31.230
  }

  track_script {
    chk_haproxy
  }
}
</code></pre><p>master3：</p>
<pre tabindex="0"><code class="language-conf" data-lang="conf">vrrp_script chk_haproxy {
  script &#34;killall -0 haproxy&#34;
  interval 2
  weight 3
}

vrrp_instance haproxy-vip {
  state BACKUP
  priority 98
  interface enp0s3
  virtual_router_id 51
  advert_int 1
  authentication {
    auth_type PASS
    auth_pass test_k8s 
  }
  unicast_src_ip 192.168.31.46
  unicast_peer { 
    192.168.31.203
    192.168.31.34
  }

  virtual_ipaddress {
    192.168.31.230
  }

  track_script {
    chk_haproxy
  }
}
</code></pre><h3 id="测试">测试</h3>
<p>重启所有几点的 keepalived ， 虚拟 ip 会在节点 master 上，因为他的优先级高。</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e"># master 1</span>
</span></span><span style="display:flex;"><span>ip a show enp0s3
</span></span><span style="display:flex;"><span>2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc fq_codel state UP group default qlen <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    link/ether 08:00:27:ca:59:86 brd ff:ff:ff:ff:ff:ff
</span></span><span style="display:flex;"><span>    inet 192.168.31.203/24 metric <span style="color:#ae81ff">100</span> brd 192.168.31.255 scope global dynamic enp0s3
</span></span><span style="display:flex;"><span>       valid_lft 41983sec preferred_lft 41983sec
</span></span><span style="display:flex;"><span>    inet 192.168.31.230/32 scope global enp0s3
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::a00:27ff:feca:5986/64 scope link
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span></code></pre></div><p>现在我们关掉 master1 的 haproxy 或者 keepalived</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>systemctl stop haproxy
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 再查看网络信息 发现虚拟ip 没了</span>
</span></span><span style="display:flex;"><span>ip a show enp0s3
</span></span><span style="display:flex;"><span>2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc fq_codel state UP group default qlen <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    link/ether 08:00:27:ca:59:86 brd ff:ff:ff:ff:ff:ff
</span></span><span style="display:flex;"><span>    inet 192.168.31.203/24 metric <span style="color:#ae81ff">100</span> brd 192.168.31.255 scope global dynamic enp0s3
</span></span><span style="display:flex;"><span>       valid_lft 41925sec preferred_lft 41925sec
</span></span><span style="display:flex;"><span>    inet6 fe80::a00:27ff:feca:5986/64 scope link
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 在优先级第二高的 master IP 上看下网络</span>
</span></span><span style="display:flex;"><span>ip a show enp0s3
</span></span><span style="display:flex;"><span>2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc fq_codel state UP group default qlen <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    link/ether 08:00:27:11:af:4f brd ff:ff:ff:ff:ff:ff
</span></span><span style="display:flex;"><span>    inet 192.168.31.34/24 metric <span style="color:#ae81ff">100</span> brd 192.168.31.255 scope global dynamic enp0s3
</span></span><span style="display:flex;"><span>       valid_lft 41857sec preferred_lft 41857sec
</span></span><span style="display:flex;"><span>    inet 192.168.31.230/32 scope global enp0s3
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::a00:27ff:fe11:af4f/64 scope link
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 启动 master1 的 haproxy ip就会回来</span>
</span></span></code></pre></div><h3 id="配置-haproxy">配置 haproxy</h3>
<p>把 16443 端口的请求转发到 6443 端口 （3 master 的 kube-apiserver 对外端口）</p>
<p>/etc/haproxy/haproxy.cfg</p>
<pre tabindex="0"><code class="language-conf" data-lang="conf">global
    log /dev/log  local0 warning
    chroot      /var/lib/haproxy
    pidfile     /var/run/haproxy.pid
    maxconn     4000
    user        haproxy
    group       haproxy
    daemon

    stats socket /var/lib/haproxy/stats

defaults
    log global
    option  httplog
    option  dontlognull
    timeout connect 5000
    timeout client 50000
    timeout server 50000

frontend kube-apiserver
    bind *:16443
    mode tcp
    option tcplog
    default_backend kube-apiserver

backend kube-apiserver
    mode tcp
    option tcp-check
    balance roundrobin
    default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100
    server kube-apiserver-1 192.168.31.203:6443 check
    server kube-apiserver-2 192.168.31.34:6443 check
    server kube-apiserver-3 192.168.31.46:6443 check
</code></pre><h2 id="安装-kubernetes-集群">安装 kubernetes 集群</h2>
<p>master1</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm init --image-repository registry.aliyuncs.com/google_containers --control-plane-endpoint<span style="color:#f92672">=</span>192.168.31.230:16443 --v<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>
</span></span></code></pre></div><p>master2 和 master3 加入集群</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm join 192.168.31.230:16443 --token rxblci.ddh60vl370wjgtn7         --discovery-token-ca-cert-hash sha256:d712016d5b8ba4ae5c4a1bda8b6ab1944c13a04757d2c488dd0aefcfd1af0157   --certificate-key    c398d693c6ce9b664634c9b670f013da3010580c00bd444caf7d0a5a81e803f5         --control-plane --v<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>
</span></span></code></pre></div><p>worker 加入集群</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubeadm join 192.168.31.230:16443 --token rxblci.ddh60vl370wjgtn7 <span style="color:#8045ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#8045ff"></span>        --discovery-token-ca-cert-hash sha256:d712016d5b8ba4ae5c4a1bda8b6ab1944c13a04757d2c488dd0aefcfd1af0157
</span></span></code></pre></div><p>查看集群状态</p>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>kubectl get node
</span></span><span style="display:flex;"><span>NAME      STATUS     ROLES           AGE     VERSION
</span></span><span style="display:flex;"><span>master1   Ready      control-plane   21m     v1.28.2
</span></span><span style="display:flex;"><span>master2   Ready      control-plane   3m46s   v1.28.12
</span></span><span style="display:flex;"><span>master3   Ready      control-plane   2m12s   v1.28.12
</span></span><span style="display:flex;"><span>worker1   Ready      &lt;none&gt;          5s      v1.28.2
</span></span></code></pre></div><h2 id="测试-1">测试</h2>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">#  关闭 master1 的 kubelet 和 apiserver</span>
</span></span><span style="display:flex;"><span>systemctl stop kubelet
</span></span><span style="display:flex;"><span>sudo <span style="color:#111">kill</span> -9 <span style="color:#00a8c8">$(</span>pgrep kube-apiserver<span style="color:#00a8c8">)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>kubectl get node
</span></span><span style="display:flex;"><span>NAME      STATUS     ROLES           AGE     VERSION
</span></span><span style="display:flex;"><span>master1   NotReady   control-plane   25m     v1.28.2
</span></span><span style="display:flex;"><span>master2   Ready      control-plane   7m40s   v1.28.12
</span></span><span style="display:flex;"><span>master3   Ready      control-plane   6m6s    v1.28.12
</span></span><span style="display:flex;"><span>worker1   Ready      &lt;none&gt;          3m59s   v1.28.2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 关闭 master1 的 haproxy</span>
</span></span><span style="display:flex;"><span>systemctl stop haproxy
</span></span><span style="display:flex;"><span>root@master1:/home/zhy# kubectl get node
</span></span><span style="display:flex;"><span>NAME      STATUS     ROLES           AGE     VERSION
</span></span><span style="display:flex;"><span>master1   NotReady   control-plane   26m     v1.28.2
</span></span><span style="display:flex;"><span>master2   Ready      control-plane   9m12s   v1.28.12
</span></span><span style="display:flex;"><span>master3   Ready      control-plane   7m38s   v1.28.12
</span></span><span style="display:flex;"><span>worker1   Ready      &lt;none&gt;          5m31s   v1.28.2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 关闭 master2 的 keepalived</span>
</span></span><span style="display:flex;"><span>kubectl get node
</span></span><span style="display:flex;"><span>NAME      STATUS     ROLES           AGE     VERSION
</span></span><span style="display:flex;"><span>master1   NotReady   control-plane   28m     v1.28.2
</span></span><span style="display:flex;"><span>master2   Ready      control-plane   10m     v1.28.12
</span></span><span style="display:flex;"><span>master3   Ready      control-plane   9m12s   v1.28.12
</span></span><span style="display:flex;"><span>worker1   Ready      &lt;none&gt;          7m5s    v1.28.2
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 可以看到 虚拟ip 跑到了 master3 上</span>
</span></span><span style="display:flex;"><span>ip a show enp0s3
</span></span><span style="display:flex;"><span>2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu <span style="color:#ae81ff">1500</span> qdisc fq_codel state UP group default qlen <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>    link/ether 08:00:27:f1:b5:ae brd ff:ff:ff:ff:ff:ff
</span></span><span style="display:flex;"><span>    inet 192.168.31.46/24 metric <span style="color:#ae81ff">100</span> brd 192.168.31.255 scope global dynamic enp0s3
</span></span><span style="display:flex;"><span>       valid_lft 41021sec preferred_lft 41021sec
</span></span><span style="display:flex;"><span>    inet 192.168.31.230/32 scope global enp0s3
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span><span style="display:flex;"><span>    inet6 fe80::a00:27ff:fef1:b5ae/64 scope link
</span></span><span style="display:flex;"><span>       valid_lft forever preferred_lft forever
</span></span></code></pre></div>]]></content:encoded><category>cloud</category><category>keepalived</category><category>haproxy</category><category>kubernetes</category></item></channel></rss>