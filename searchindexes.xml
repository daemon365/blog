<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>go 内存管理</title><url>/post/go/go_memory_code/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html">  操作系统内存管理 操作系统管理内存的存储单元是页（page），在 linux 中一般是 4KB。而且，操作系统还会使用 虚拟内存 来管理内存，在用户程序中，我们看到的内存是不是真实的内存，而是虚拟内存。当访问或者修改内存的时候，操作系统会将虚拟内存映射到真实的内存中。申请内存的组件是 Page Table 和 MMU（Memory Management Unit）。因为这个性能很重要，所以在 CPU 中专门有一个 TLB（Translation Lookaside Buffer）来缓存 Page Table 的内容。
为什么要用虚拟内存？
保护内存，每个进程都有自己的虚拟内存，不会相互干扰。防止修改和访问别的进程的内存。 减少内存碎片，虚拟内存是连续的，而真实的内存是不连续的。 当内存不够时，可以把虚拟内存映射到硬盘上，这样就可以使用硬盘的空间来扩展内存。 如上图所示，如果直接使用真实的内存，想要连续的内存肯定是申请不到的，这就是内存碎片的问题。而使用虚拟内存，通过 Page 映射的方式，保证内存连续。
Go 内存管理单元 page 在 go 中，管理内存的存储单元也是页（Page）, 每个页的大小是 8KB。Go 内存管理是由 runtime 来管理的，runtime 会维护一个内存池，用来分配和回收内存。这样可以避免频繁的系统调用申请内存，提高性能。
mspan mspan 是 go 内存管理基本单元，一个 mspan 包含一个或者多个 page。go 中有多种 mspan，每种 mspan 给不同的内存大小使用。
class bytes/obj bytes/span objects tail waste max waste min align 1 8 8192 1024 0 87.50% 8 2 16 8192 512 0 43.75% 16 3 24 8192 341 8 29.24% 8 4 32 8192 256 0 21.88% 32 5 48 8192 170 32 31.52% 16 6 64 8192 128 0 23.44% 64 7 80 8192 102 32 19.07% 16 8 96 8192 85 32 15.95% 32 9 112 8192 73 16 13.56% 16 &amp;amp;hellip; &amp;amp;hellip; &amp;amp;hellip; …  </content></entry><entry><title>从源码分析 GMP 调度原理</title><url>/post/go/gmp_code/</url><categories><category>go</category></categories><tags/><content type="html">  本身涉及到的 go 代码 都是基于 go 1.23.0 版本
传统 OS 线程 线程是 CPU 的最小调度单位，CPU 通过不断切换线程来实现多任务的并发。这会引发一些问题（对于用户角度）：
线程的创建和销毁等是昂贵的，因为要不断在用户空间和内核空间切换。 线程的调度是由操作系统负责的，用户无法控制。而操作系统又可能不知道线程已经 IO 阻塞，导致线程被调度，浪费 CPU 资源。 线程的栈是很大的，最新版 linux 默认是 8M，会引起内存浪费。 &amp;amp;hellip;&amp;amp;hellip; 所以，最简单的办法就是复用线程，go 中使用的是 M:N 模型，即 M 个 OS 线程对应 N 个 任务。
GMP 模型 G goroutine, 一个 goroutine 代表一个任务。它有自己的栈空间，默认是 2K，栈空间可以动态增长。方式就是把旧的栈空间复制到新的栈空间，然后释放旧的栈空间。它的栈是在 heap （对于 OS） 上分配的。
M machine, 一个 M 代表一个 OS 线程。
P processor, 一个 P 代表一个逻辑处理器，它维护了一个 goroutine 队列。P 会把 goroutine 分配给 M，M 会执行 goroutine。默认的大小为 CPU 核心数。
数据结构 G 结构体在 src/runtime/runtime2.go 中定义，主要介绍一些重要的字段：
type g struct { // goroutine 的栈 两个地址，分别是栈的起始地址和结束地址 stack stack // 绑定的m m *m // goroutine 被调度走保存的中间状态 sched gobuf // goroutine 的状态 atomicstatus atomic.Uint32 } type gobuf struct { sp uintptr // stack pointer 栈指针 pc uintptr // program counter 程序要从哪里开始执行 g guintptr // goroutine 的 指针 ctxt unsafe.Pointer // 保存的上下文 ret uintptr // 返回地址 lr uintptr // link register bp uintptr // base pointer 栈的基地址 } …  </content></entry><entry><title>kube-apiserver 高可用，keepalived + haproxy</title><url>/post/cloud/keepalived_haproxy/</url><categories><category>cloud</category></categories><tags><tag>keepalived</tag><tag>haproxy</tag><tag>kubernetes</tag></tags><content type="html">  为什么要做高可用 在生产环境中，kubernetes 集群中会多多个 master 节点，每个 master 节点上都会部署 kube-apiserver 服务，实现高可用。但是 client 访问 kube-apiserver 时，需要指定 ip 或者域名，这样会出现单点故障。官方推荐的做法是使用一个负载均衡器，将多个 kube-apiserver 服务负载均衡，实现高可用，但很多时候我们是没有这个条件的。这时候就得想想办法了，比如 nignx 转发，但是 nginx 也是单点。域名的方式，但是这种方式生效时间较长，不太适合紧急情况。所以这里介绍一种使用 keepalived + haproxy 的方式实现 kube-apiserver 的高可用。这是一共公用 IP 的方式，当主节点宕机时，VIP 会自动切换到备节点，实现高可用。
环境准备 master1: 192.168.31.203 master2: 192.168.31.34 master3: 192.168.31.46 worker1: 192.168.31.25 VIP （虚拟IP）: 192.168.31.230 安装 sudo apt install keepalived haproxy systemctl enable haproxy systemctl restart haproxy systemctl enable keepalived # 没有配置会出现错误 不用管 systemctl restart keepalived 配置 keepalived 配置文件 编辑 keepalived 配置文件
编辑 /etc/keepalived/keepalived.conf
master1：
# 健康检查 查看 haproxy 的进程在不在 vrrp_script chk_haproxy { script &amp;amp;#34;killall -0 haproxy&amp;amp;#34; interval 2 # 多少秒教程一次 weight 3 # 成功了优先级加多少 } vrrp_instance haproxy-vip { state MASTER # MASTER / BACKUP 1 MASTER 2 BACKUP priority 100 # 优先级 强的机器高一些 三台master 分别 100 99 98 …  </content></entry><entry><title>boltdb 原理</title><url>/post/cloud/boltdb_principles/</url><categories><category>cloud</category></categories><tags><tag>boltdb</tag><tag>etcd</tag><tag>golang</tag><tag>数据库</tag><tag>kubernetes</tag><tag>源码分析</tag><tag>事务</tag></tags><content type="html">  简介 介绍及简单使用：https://www.cnblogs.com/daemon365/p/17690167.html 源码地址：https://github.com/etcd-io/bbolt
page 因为 boltdb 是要落盘的，所以就要操作文件。为了提高效率，boltdb 会和其他数据库一样，会按 页（page）来操作文件。而且 boltdb 使用了 linux 的 mmap 来内存映射操作文件，这样可以提高效率。
在 linux 中，每个 page 的大小是 4KB。
getconf PAGESIZE 4096 对应的每页在我们的代理里也应该有一个数据结构，来存储数据。这个数据结构就是 page。
type Pgid uint64 type Page struct { id Pgid flags uint16 // page 类型 count uint16 // page 中的元素数量 overflow uint32 // 是否有后序页，如果有，overflow 表示后续页的数量 } const ( BranchPageFlag = 0x01 LeafPageFlag = 0x02 MetaPageFlag = 0x04 FreelistPageFlag = 0x10 ) Page 里面有一个 flags 字段，用来标识这个 page 是什么类型的。boltdb 里面有四种类型的 page, 分别是 分支页（BranchPageFlag）、叶子页（LeafPageFlag）、元数据页（MetaPageFlag）、空闲列表页（FreelistPageFlag）。
分支页：由于 boltdb 使用的是 B+ 树，所以分支页用来存储 key 和子节点的指针。 叶子页：叶子页用来存储 key 和 value。 元数据页：元数据页用来存储 boltdb 的元数据，比如 boltdb 的版本号、boltdb 的根节点等。 空闲列表页：由于 boltdb 使用 copy on write，所以当一个 page 被删除的时候，boltdb 并不会立即释放这个 page，而是把这个 page 加入到空闲列表页中，等到需要新的 page 的时候，再从空闲列表页中取出一个 page。 在 page 之后会存储对用的结构，比如 meta 或者 freelist。 …  </content></entry><entry><title>etcd watch 实现原理</title><url>/post/cloud/etcd_watch_implementation_principle/</url><categories><category>cloud</category></categories><tags><tag>boltdb</tag><tag>etcd</tag><tag>golang</tag><tag>数据库</tag><tag>kubernetes</tag></tags><content type="html"><![CDATA[  介绍 在 etcd 中，watch 是一个非常重要的特性，它可以让客户端监控 etcd 中的 key 或者一组 key，当 key 发生变化时，etcd 会通知客户端。本文将介绍 etcd watch 的实现原理。
etcdctl watch /test # 当 /test 的值发生变化时，会输出如下信息 PUT /test a PUT /test b DELETE /test watch 的 api etcd watch api 是由 grpc stream 实现的，客户端通过 grpc stream 发送 watch 请求，etcd 会将 key 的变化通过 stream 返回给客户端。
rpc Watch(stream WatchRequest) returns (stream WatchResponse) { option (google.api.http) = { post: &amp;#34;/v3/watch&amp;#34; body: &amp;#34;*&amp;#34; }; } api 实现 func (ws *watchServer) Watch(stream pb.Watch_WatchServer) (err error) { sws := serverWatchStream{ lg: ws.lg, clusterID: ws.clusterID, memberID: ws.memberID, maxRequestBytes: ws.maxRequestBytes, sg: ws.sg, watchable: ws.watchable, ag: ws.ag, gRPCStream: stream, watchStream: ws.watchable.NewWatchStream(), // chan for sending control response like watcher created and canceled. ctrlStream: make(chan *pb.WatchResponse, ctrlStreamBufLen), progress: make(map[mvcc.WatchID]bool), prevKV: make(map[mvcc.WatchID]bool), fragment: make(map[mvcc.WatchID]bool), …  ]]></content></entry><entry><title>etcd MVCC 存储结构及流程</title><url>/post/cloud/etcd_mvcc_storage_structure_and_process/</url><categories><category>cloud</category></categories><tags><tag>boltdb</tag><tag>etcd</tag><tag>golang</tag><tag>数据库</tag><tag>kubernetes</tag></tags><content type="html"><![CDATA[  什么是 MVCC MVCC 是 Multi-Version Concurrency Control 的缩写，即多版本并发控制。它是一种并发控制的方法，用于在数据库系统中实现事务的隔离性。MVCC 是一种乐观锁机制，它通过保存数据的多个版本来实现事务的隔禽性。在 etcd 中，MVCC 是用于实现数据的版本控制的。而且可以查看历史版本的数据。
测试 # 添加数据 etcdctl put /test t1 OK etcdctl put /test t2 OK # 查看数据 etcdctl get /test /test t2 # 查看 json 格式数据 etcdctl get /test --write-out=json # {&amp;#34;header&amp;#34;:{&amp;#34;cluster_id&amp;#34;:8735285696067307020,&amp;#34;member_id&amp;#34;:7131777314758672153,&amp;#34;revision&amp;#34;:15,&amp;#34;raft_term&amp;#34;:4},&amp;#34;kvs&amp;#34;:[{&amp;#34;key&amp;#34;:&amp;#34;L3Rlc3Q=&amp;#34;,&amp;#34;create_revision&amp;#34;:14,&amp;#34;mod_revision&amp;#34;:15,&amp;#34;version&amp;#34;:2,&amp;#34;value&amp;#34;:&amp;#34;dDI=&amp;#34;}],&amp;#34;count&amp;#34;:1} # 查看历史版本 etcdctl get /test --rev=14 /test t1 可以看到，通过 --rev 参数可以查看历史版本的数据。也就是我第一次添加的数据。那么 json 中 revision 是什么意思呢？
revision reversion 中是 etcd 中的一个概念，它是一个递增的整数，用于标识 etcd 中的数据版本。他是一个 int64 类型。没操作一次 etcd 数据（增，删，改），reversion 就会递增。
# 删除数据 etcdctl del /test 1 # 查看 revision etcdctl get / -wjson # …  ]]></content></entry><entry><title>istio sidecar 工作方式</title><url>/post/cloud/how_istio_sidecar_works/</url><categories><category>cloud</category></categories><tags><tag>istio</tag><tag>sidecar</tag><tag>service mesh</tag><tag>kubernetes</tag><tag>iptables</tag></tags><content type="html">  istio 是什么 Istio 是一个开放源代码的服务网格，它为基于微服务的应用程序提供了一种统一的方式来连接、保护、监控和管理服务。Istio 主要解决的是在微服务架构中的服务间通信的复杂性问题，它通过提供服务间的负载均衡、服务到服务的认证、监控以及服务的弹性（例如重试、熔断等）来实现。
sidecar 是什么 sidecar 是一种设计模式，它将挂在业务容器旁边作为辅助，当业务接受流量和传出流量的时候，都先经过 sidecar 然后在到达业务容器或者发出。sidecar 可以看作是一个代理，或者是一个专门为我一个服务而工作的 gateway。这样，服务的熔断、限流、监控、日志等功能都可以在 sidecar 中实现，而不需要在业务容器中实现。从而实现了业务容器的轻量化，只需要关注业务逻辑。
在 istio 中，sidecar 使用的是 envoy，envoy 是一个高性能的代理，它支持 http1.1, http2, grpc, tcp 等协议，支持负载均衡，熔断，限流，监控等功能。envoy 是一个 c++ 项目，它的性能非常好。通过 istiod 控制平面，使用 grpc stream 的方式更新 envoy 的配置，从而实现了动态配置。
如果在 pod test 中访问 test namespace 下的 nginx service，那么流量会经过自己的 sidecar，然后到达 nginx 的 sidecar，最后到达 nginx 的容器。nginx 回复同样如此，先到达 sidecar，然后到达 test 的 sidecar，最后到达 test 的容器。
启动方式 在 kubernetes 中，当 namespace 存在 istio-injection=enabled label，那么在该 namespace 中的 pod 在启动的时候，istio 就会利用 mutating addmission webhook 的方式，自动修改 pod spec ，把 containers 中加入 sidecar 容器。当然，它也加入了一个 initcontainer，目的是做一些网络配置，能做到这个的原因是，kubernetes 的 pod 的多个 container 是使用同一个 linux network namespace, 所以 initcontainer …  </content></entry><entry><title>docker containerd runc containerd-shim等组件的关系</title><url>/post/cloud/the_relationship_between_docker_containerd_runc_containerd_shim_and_other_components/</url><categories><category>cloud</category></categories><tags><tag>docker</tag><tag>containerd</tag><tag>runc</tag><tag>containerd-shim</tag><tag>kubernetes</tag><tag>cri</tag></tags><content type="html">  早期 kubelet 创建容器工作原理 因为 docker 出生的比 k8s 早，所以 k8s 早期的容器运行时都是基于 docker 的，kubelet 通过 docker 的 api 创建容器。后来，k8s 官方不想绑死在 docker 这架马车上，就把容器运行时抽象出来，定义了一个接口，叫 CRI ( container runtime interface )，容器运行时接口, 通过这个接口，kubelet 可以和任何容器运行时交互。但是，docker 并没有实现这个接口，k8s 也不想直接失去 docker 的用户，所以 k8s 官方在 kubelet 中实现了一个叫 docker-shim 的组件，这个组件简单来说就是把 cri 接口转换成 docker 的 api，这样 kubelet 就可以和 docker 交互了, 这个组件在 kuberbetes 1.24 版本中已经被移除了。至于实现了 cri 接口的容器运行时，比如 containerd，cri-o 等，kubelet 可以直接和它们交互。
调用架构图如下：
目前 dockershim 组件已经删除，不能使用了，所以 k8s 1.24 版本之后，kubelet 只能和实现了 cri 接口的容器运行时交互，比如 containerd，cri-o 等。
这里建议使用 containerd 因为 containerd 是 docker 官方出品的，而且 containerd 也是 docker 的核心组件，docker 的容器运行时就是基于 containerd 的，所以 containerd 的稳定性和可靠性都是有保障的。
docker containerd runc 的关系 因为 podman 等新兴 container runtime 的崛起，docker 不想失去定义标准的机会，所以 docker 官方把 containerd 从 docker 中分离出来，独立成一个项目，实现了 cri 接口，这种 kubelet 就可以通过 cri 直接调用 containerd 了。然后，docker 官方又把 runc 从 containerd 中分离出来，独立成一个项目，定义了一个叫 OCI ( Open Container Initiative ) 的标准，这个标准定义了容器的格式和运行时，runc …  </content></entry><entry><title>boltdb 介绍</title><url>/post/cloud/boltdb_basics/</url><categories><category>cloud</category></categories><tags><tag>boltdb</tag><tag>etcd</tag><tag>golang</tag><tag>数据库</tag><tag>kubernetes</tag></tags><content type="html"><![CDATA[  介绍 BoltDB 是一个用 Go 语言编写的嵌入式键/值数据库。以下是关于 BoltDB 的一些基本介绍：
键/值存储: BoltDB 为应用程序提供了简单的键/值存储接口。 事务: BoltDB 支持完整的 ACID 事务。 嵌入式: 与像 MySQL 或 PostgreSQL 这样的数据库系统不同，BoltDB 不运行在单独的服务器进程中。它作为一个库被直接嵌入到你的应用程序中。 单文件存储: 所有的数据都存储在一个文件中，这使得备份和迁移变得简单。 高效的二进制存储: 数据在磁盘上使用 B+ 树结构存储，这为随机读取提供了高性能。 前缀扫描: 可以很容易地按键的前缀进行扫描，这使得它适用于范围查询。 没有外部依赖: BoltDB 不依赖于任何外部系统或库。 线程安全: BoltDB 是线程安全的，可以在多个 goroutines 中并发地使用。 BoltDB 特别适用于需要一个轻量级、高性能、易于部署和维护的数据库解决方案的场景。
虽然 BoltDB 非常有用，但它也有其局限性。例如，它不支持分布式存储，也不适用于需要多节点复制或分片的场景。但对于许多应用程序，它提供了一个简单且高性能的存储解决方案。
源码地址：
https://github.com/boltdb/bolt 这个项目已经不维护了, etcd 官方维护了一个 fork 库，api 是互通的: https://github.com/etcd-io/bbolt 谁在使用 etcd 、 tidb 、 influxdb 、 consul &amp;hellip;&amp;hellip;
架构图 引入 go get go.etcd.io/bbolt 使用 open a database Bolt 中的顶级对象是 DB。它在你的硬盘上表示为一个单独的文件，并代表了你数据的一个一致性快照。
要打开你的数据库，只需使用 bolt.Open() 函数：
package main import ( &amp;#34;log&amp;#34; bolt &amp;#34;go.etcd.io/bbolt&amp;#34; ) func main() { db, err := bolt.Open(&amp;#34;my.db&amp;#34;, 0600, nil) if err != nil { log.Fatal(err) } defer db.Close() } 请注 …  ]]></content></entry><entry><title>kube-proxy 流量流转方式</title><url>/post/cloud/kube_proxy_traffic_flow_mode/</url><categories><category>cloud</category></categories><tags><tag>kube-proxy</tag><tag>iptables</tag><tag>ipvs</tag><tag>kubernetes</tag></tags><content type="html"><![CDATA[  简介 kube-proxy 是 Kubernetes 集群中负责服务发现和负载均衡的组件之一。它是一个网络代理，运行在每个节点上, 用于 service 资源的负载均衡。它有两种模式：iptables 和 ipvs。
iptables iptables 是 Linux 系统中的一个用户空间实用程序，用于配置内核的网络包过滤和网络地址转换（NAT）规则。它是 Linux 内核中的 netfilter 框架的一部分，并负责在网络包进入、转发或离开计算机时进行筛选和处理。其主要功能和用途包括：
防火墙：iptables 提供了强大的防火墙功能，可以根据不同的规则来过滤和拒绝不需要的网络包。管理员可以创建自定义的规则集，允许或拒绝从特定 IP 地址、端口或协议的数据包。 NAT（网络地址转换）：iptables 支持 NAT 功能，可以用来将私有网络中的计算机与外部网络连接。例如，它可以在一个 NAT 路由器上将内部网络的多个设备映射到单个外部 IP 地址。 端口转发：iptables 可以将特定的端口流量从一个网络接口转发到另一个接口或目标 IP 地址，通常用于内部网络的服务公开。 负载均衡：它也可以通过 DNAT（目标网络地址转换）功能将流量转发给多个内部服务器，实现简单的负载均衡。 iptables 是通过链（chains）和表（tables）来组织规则的。每个链由一组规则组成，当网络数据包经过时，这些规则会逐一执行。常用的表包括：
filter 表：用于包过滤，是最常用的表。 nat 表：用于网络地址转换。 mangle 表：用于修改数据包的 IP 层字段。 raw 表：用于绕过连接跟踪。 链的流向为：
所以，根据上图，我们能够想象出某些常用场景中，报文的流向：
到本机某进程的报文：PREROUTING –&amp;gt; INPUT
由本机转发的报文：PREROUTING –&amp;gt; FORWARD –&amp;gt; POSTROUTING
由本机的某进程发出报文（通常为响应报文）：OUTPUT –&amp;gt; POSTROUTING
尽管在某些情况下配置 iptables 规则可能复杂，但它提供了高度的灵活性和强大的功能，使其成为 Linux 网络安全的重要组成部分。
service 负载均衡 我启动了一个 3 个 nginx pod，和一个对应的 service，service …  ]]></content></entry><entry><title>kubernetes 存储流程</title><url>/post/cloud/kubernetes_storage_process/</url><categories><category>cloud</category></categories><tags><tag>csi</tag><tag>kubernetes</tag></tags><content type="html">  PV 与 PVC PVC (PersistentVolumeClaim)，命名空间（namespace）级别的资源，由 用户 or StatefulSet 控制器（根据VolumeClaimTemplate） 创建。PVC 类似于 Pod，Pod 消耗 Node 资源，PVC 消耗 PV 资源。Pod 可以请求特定级别的资源（CPU 和内存），而 PVC 可以请求特定存储卷的大小及访问模式（Access Mode PV（PersistentVolume）是集群中的一块存储资源，可以是 NFS、iSCSI、Ceph、GlusterFS 等存储卷，PV 由集群管理员创建，然后由开发者使用 PVC 来申请 PV，PVC 是对 PV 的申请，类似于 Pod 对 Node 的申请。
静态创建存储卷 也就是我们手动创建一个pv和pvc，然后将pv和pvc绑定，然后pod使用pvc，这样就可以使用pv了。
创建一个 nfs 的 pv 以及 对应的 pvc
apiVersion: v1 kind: PersistentVolume metadata: name: nfs-pv spec: capacity: storage: 10Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Delete nfs: server: 192.168.203.110 path: /data/nfs apiVersion: v1 kind: PersistentVolumeClaim metadata: name: nfs-pvc spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi 查看 pvc
$ kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE nfs-pvc Bound nfs-pv 10Gi RWO 101s 创建一个 pod 使用 pvc
apiVersion: v1 kind: Pod metadata: name: test-nfs spec: containers: - image: ubuntu:22.04 name: …  </content></entry><entry><title>kubelet 原理分析</title><url>/post/cloud/analysis_of_kubelet_principles/</url><categories><category>cloud</category></categories><tags><tag>kubelet</tag><tag>kubernetes</tag><tag>源码分析</tag><tag>golang</tag></tags><content type="html">  Reference https://atbug.com/kubelet-source-code-analysis/ kubelet 简介 kubernetes 分为控制面和数据面，kubelet 就是数据面最主要的组件，在每个节点上启动，主要负责容器的创建、启停、监控、日志收集等工作。它是一个在每个集群节点上运行的代理，负责确保节点上的容器根据PodSpec（Pod定义文件）正确运行。
Kubelet执行以下几项重要功能：
Pod生命周期管理：Kubelet根据从API服务器接收到的PodSpecs创建、启动、终止容器。它负责启动Pod中的容器，并确保它们按预期运行。 节点状态监控：Kubelet定期监控节点和容器的状态，并将状态报告回集群的控制平面。这使得集群中的其他组件能够做出相应的调度决策。 资源管理：Kubelet负责管理分配给每个Pod的资源。这包括CPU、内存和磁盘存储资源。 健康检查：Kubelet可以执行容器健康检查，并根据检查结果决定是否需要重启容器。 与容器运行时的通信：Kubelet与容器运行时（如Docker、containerd等）通信，以管理容器的生命周期。 秘密和配置管理：Kubelet负责将秘密、配置映射等挂载到Pod的容器中，以便应用程序可以访问这些配置。 服务发现和负载均衡：尽管Kubelet本身不直接处理服务发现，但它通过设置网络规则和环境变量来支持容器内的服务发现机制。 kubelet 架构 kubelet 的架构由 N 多的组件组成，下面简单介绍下比较重要的几个：
Sync Loop: 这是Kubelet活动的核心，负责同步Pod的状态。同步循环会定期从API服务器获取PodSpecs，并确保容器的当前状态与这些规格相匹配。 PodConfig: 负责将各个配置源转换成 PodSpecs，可以选择的配置源包括：Kube-apiserver、本地文件、HTTP。 PLEG(Pod Lifecycle Event Generator)： 负责监测和缓存Pod生命周期事件，如创建、启动或停止容器，然后将这些事件通知 Sync Loop。 PodWorkers: 负责管理 Pod 的生命周期事件处理。当 Pod 生命周期事件 PLEG 检测到新的事件时，PodWorkers 会被调用来处理这些事件，包括启动新的 Pod、 …  </content></entry><entry><title>kubernetes CNI(Container Network Inferface)</title><url>/post/cloud/kubernetes_cni_container_network_inferface/</url><categories><category>cloud</category></categories><tags><tag>cni</tag><tag>kubernetes</tag><tag>network</tag></tags><content type="html"><![CDATA[  为什么需要 CNI 在 kubernetes 中，pod 的网络是使用 network namespace 隔离的，但是我们有时又需要互相访问网络，这就需要一个网络插件来实现 pod 之间的网络通信。CNI 就是为了解决这个问题而诞生的。CNI 是 container network interface 的缩写，它是一个规范，定义了容器运行时如何配置网络。CNI 插件是实现了 CNI 规范的二进制文件，它可以被容器运行时调用，来配置容器的网络。
Docker 网络 基础 计算机五层网络如下：
如果我们想把 pod 中的网络对外，首先想到的就是七层代理，比如nginx，但是我们并不知道 pod 里的网络一定是 http，甚至他可能不是tcp。所以我们像做一些网络操作，就不能在五层做了，只能在二三四层做。
Docker 实验 当我们在物理机上启动 docker daemon 不需要启动任何容器的时候，使用 ip a 命令查看网卡，发现多了一个 docker0
4: docker0: &amp;lt;NO-CARRIER,BROADCAST,MULTICAST,UP&amp;gt; mtu 1500 qdisc noqueue state DOWN group default link/ether 02:42:9b:65:e1:01 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever docker0 是一个 linux Bridge 设备，这个可以理解成一个虚拟的交换机，用来做二层网络的转发。当我们启动一个容器的时候，docker 会为这个容器创建一个 veth pair 设备，一个端口挂载在容器的 network namespace 中，另一个端口挂载在 docker0 上。这样容器就可以和 docker0 上的其他容器通信了。
docker run -d --rm -it ubuntu:22.04 sleep 3000 在物理机上查看 ip a
8: veth6bc75d9@if7: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc …  ]]></content></entry><entry><title>kubernetes client-go功能介绍</title><url>/post/cloud/kubernetes_client_go_function_introduction/</url><categories><category>cloud</category></categories><tags><tag>client-go</tag><tag>kubernetes</tag><tag>golang</tag></tags><content type="html">  原文地址 https://haiyux.cc/2023/02/26/k8s-client-go/ client-go是什么？ client-go是Kubernetes官方提供的Go语言客户端库，用于与Kubernetes API服务器交互。使用client-go，您可以编写Go语言程序来创建、修改和删除Kubernetes对象，如Pod、Deployment、Service等。
作用 client-go的主要功能包括：
连接Kubernetes API服务器：client-go提供了一个API客户端，用于连接Kubernetes API服务器。 对象管理：client-go提供了一组API，用于创建、读取、更新和删除Kubernetes对象，如Pod、Deployment、Service等。 Watch API：client-go提供了一个Watch API，可以用于监视Kubernetes对象的变化。 命名空间支持：client-go支持多个命名空间，并提供了一组API，用于管理命名空间。 认证和授权：client-go提供了一组API，用于执行身份验证和授权，以确保只有授权的用户才能对Kubernetes对象进行操作。 client-go是使用Kubernetes API的标准方式，是Kubernetes生态系统中的重要组成部分。
api client client-go 中包含四种client，RestClient, ClientSet，DynamicClient和DiscoveryClient。
ClientSet，DynamicClient，DiscoveryClient都是RestClient上的封装
RestClient RestClient是最基础的客户端，它基于HTTP请求进行了封装，实现了RESTful API。使用RESTClient提供的RESTful方法，如Get()、Put()、Post()和Delete()，可以直接与API进行交互。同时，它支持JSON和Protocol Buffers，并支持所有原生资源和自定义资源定义（CRDs）。然而，为了更加优雅地处理API交互，一般需要进一步封装，通过Clientset对RESTClient进行封装，然后再对外提供接口和服务。
package main import ( …  </content></entry><entry><title>容器启动流程（containerd 和 runc）</title><url>/post/cloud/container_startup_process_containerd_and_runc/</url><categories><category>cloud</category></categories><tags><tag>docker</tag><tag>containerd</tag><tag>runc</tag><tag>containerd-shim</tag><tag>kubernetes</tag><tag>源码分析</tag></tags><content type="html">  启动流程 containerd 作为一个 api 服务，提供了一系列的接口供外部调用，比如创建容器、删除容器、创建镜像、删除镜像等等。使用 docker 和 ctr 等工具，都是通过调用 containerd 的 api 来实现的。 kubelet 通过 cri 调用 containerd 和这些不一样，后续我会介绍到。
containerd 创建容器流程如下：
接收到 api 请求，通过调用 containerd-shim-runc-v2 调用 runc 创建容器，主要是做解压文件和准备环境的工作。 接收到 api 请求，创建一个 task，task 是一个容器的抽象，包含了容器的所有信息，比如容器的 id、容器的状态、容器的配置等等。 containerd 启动一个 containerd-shim-runc-v2 进程。 containerd-shim-runc-v2 进程 在启动一个 containerd-shim-runc-v2 进程，然后第一个 containerd-shim-runc-v2 进程退出。 containerd 通过 IPC 通信，让第二个 containerd-shim-runc-v2 启动容器。 containerd-shim-runc-v2 进程通过调用 runc start 启动容器。 runc 会调用 runc init 启动容器的 init 进程。 runc init 进程会调用 unix.Exec 的方式，替换自己的进程，启动容器的第一个进程。这个进程既是容器的启动命令，也是容器的 pid 1 进程。完成之后，runc create 进程退出。 这样 containerd-shim-runc-v2 的父进程就是 init 进程（1），而 init 进程的父进程是 containerd-shim-runc-v2 进程，这样就形成了一个进程树。
我通过 docker 启动一个容器，示例一下：
❯ docker run -d --rm -it docker.m.daocloud.io/ubuntu:22.10 sleep 3000 ❯ ps -ef|grep &amp;amp;#34;sleep 3000&amp;amp;#34; root 15042 15021 0 22:02 pts/0 00:00:00 sleep 3000 ❯ ps -ef|grep …  </content></entry><entry><title>kubernetes container device interface (CDI)</title><url>/post/cloud/kubernetes_container_device_interface_cdi/</url><categories><category>cloud</category></categories><tags><tag>cdi</tag><tag>kubernetes</tag></tags><content type="html">  CDI 是什么？ Container Device Interface (CDI) 是一个提议的标准，它定义了如何在容器运行时环境中向容器提供设备。这个提议的目的是使得设备供应商能够更容易地将其设备集成到 Kubernetes 集群中，而不必修改 Kubernetes 核心代码。
CDI 插件通常负责：
配置设备以供容器使用（例如，分配设备文件或设置必要的环境变量）。 在容器启动时将设备资源注入到容器中。 官网
https://github.com/cncf-tags/container-device-interface 为什么需要CDI？ 如果我们想在容器内使用 nvidia 的 gpu，在没有 CDI 之前，我们需要修改 containerd 的 low-level container runtime(runc) 到 nvidia runtime。这么做的原因就是使用 gpu 不单单要绑定 gpu device 文件到容器内，还需要绑定一些驱动文件和可执行命令（比如 nvidia-smi）等到容器内，还有就执行一些 hooks。 nvidia runtime 的作用就是绑定一些文件和执行一些 hooks 然后调用 runc。
现在我们可以使用 CDI 做这些事情，除了无需修改 runtime 外，还有抽象和插件化等优点。
版本及准备工作 kubelet version &amp;amp;gt;= 1.28.0 containerd version &amp;amp;gt;= 1.7.0 而且这在 k8s 1.28 (1.29版本是 beta 了 默认就打开了) 版本中是一个 alpha 版本的功能，所以我们需要在 kubelet 的启动参数中加入开启特性门：--feature-gates=DevicePluginCDIDevices =true。
sudo vim /etc/systemd/system/kubelet.service.d/10-kubeadm.conf ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS --feature-gates=DevicePluginCDIDevices=true …  </content></entry><entry><title>行为模式</title><url>/post/go/behavioral_patterns/</url><categories><category>go</category></categories><tags><tag>go</tag><tag>设计模式</tag></tags><content type="html"><![CDATA[  责任链模式 责任链模式是一种行为设计模式， 允许你将请求沿着处理者链进行发送。 收到请求后， 每个处理者均可对请求进行处理， 或将其传递给链上的下个处理者。比如 kratos,gin等开源库的中间件实现。
代码实现 package main import ( &amp;#34;context&amp;#34; &amp;#34;fmt&amp;#34; ) type Handler func(ctx context.Context, req interface{}) (resp interface{}, err error) type Middleware func(next Handler) Handler func Chain(middlewares ...Middleware) Middleware { return func(next Handler) Handler { for i := len(middlewares) - 1; i &amp;gt;= 0; i-- { next = middlewares[i](next) } return next } } func main() { c := Chain(func(next Handler) Handler { return func(ctx context.Context, req interface{}) (resp interface{}, err error) { fmt.Println(&amp;#34;handler 1 before&amp;#34;) resp, err = next(ctx, req) fmt.Println(&amp;#34;handler 1 after&amp;#34;) return resp, err } }, func(next Handler) Handler { return func(ctx context.Context, req interface{}) (resp interface{}, err error) { fmt.Println(&amp;#34;handler 2 before&amp;#34;) resp, err = next(ctx, req) fmt.Println(&amp;#34;handler 2 after&amp;#34;) return resp, err } }) resp, err := c(func(ctx …  ]]></content></entry><entry><title>结构型模式</title><url>/post/go/structural_patterns/</url><categories><category>go</category></categories><tags><tag>go</tag><tag>设计模式</tag></tags><content type="html"><![CDATA[  适配器模式 适配器模式用于转换一种接口适配另一种接口。比如，现在有个借口是对json字符串进行分析等，现在有一些yaml文件也要分析，这时候我我们就应该给yaml字符串就个适配器，转换成json字符串，然后就行分析。
代码实现 package main import ( &amp;#34;fmt&amp;#34; &amp;#34;github.com/ghodss/yaml&amp;#34; ) type Analysis interface { Analyze(string) error } type JsonAnalysis struct{} func (*JsonAnalysis) Analyze(jsonStr string) error { // 函数逻辑 fmt.Println(jsonStr) return nil } type yamlAnalysis struct { ja *JsonAnalysis } func (y *yamlAnalysis) Analyze(yamlStr string) error { bs, err := yaml.YAMLToJSON([]byte(yamlStr)) if err != nil { return err } return y.ja.Analyze(string(bs)) } func main() { ja := &amp;amp;JsonAnalysis{} err := ja.Analyze(&amp;#34;{\&amp;#34;name\&amp;#34;:\&amp;#34;zhy\&amp;#34;,\&amp;#34;age\&amp;#34;:18}&amp;#34;) if err != nil { fmt.Println(err) } ya := &amp;amp;yamlAnalysis{ja: ja} err = ya.Analyze(&amp;#34;name: you\nage: 88&amp;#34;) if err != nil { fmt.Println(err) } } /* {&amp;#34;name&amp;#34;:&amp;#34;zhy&amp;#34;,&amp;#34;age&amp;#34;:18} {&amp;#34;age&amp;#34;:88,&amp;#34;name&amp;#34;:&amp;#34;you&amp;#34;} */ 桥接模式 桥接模式分离抽象部分和实现部分。使得两部分独立扩展。
桥接模式类似于策略模式，区别在于策略模式封装一系列算法 …  ]]></content></entry><entry><title>创建者模式</title><url>/post/go/creator_mode/</url><categories><category>go</category></categories><tags><tag>go</tag><tag>设计模式</tag></tags><content type="html"><![CDATA[  单例模式 为什么要用单例模式 保证一个对象只有一个实例 ，减少内存开销。比如一些可以复用一个连接的网络，比如http2 client等，而且可以减少网络开销。
为什么不用个全局变量控制 因为任何代码都有可能覆盖掉那些变量的内容， 从而引发程序崩溃。
代码实现 package main import ( &amp;#34;fmt&amp;#34; &amp;#34;sync&amp;#34; ) type Single struct { } var single *Single var once = &amp;amp;sync.Once{} func NewSingle() *Single { once.Do(func() { single = &amp;amp;Single{ // 初始化 } }) return single } func main() { for i := 0; i &amp;lt; 1000; i++ { s := NewSingle() fmt.Printf(&amp;#34;create %d,address %p\n&amp;#34;, i, s) } } /* 结果： create 0,address 0x1164fe0 create 1,address 0x1164fe0 create 2,address 0x1164fe0 create 3,address 0x1164fe0 create 4,address 0x1164fe0 create 5,address 0x1164fe0 create 6,address 0x1164fe0 create 7,address 0x1164fe0 create 8,address 0x1164fe0 ... */ 工厂模式 我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指向新创建的对象。比如电脑支持intel cpu，现在要支持amd cpu，我们就可以让所有cpu实现接口。
简单工厂模式 实现简单，不适合复杂场景
package main import ( &amp;#34;errors&amp;#34; &amp;#34;fmt&amp;#34; ) // 工厂接口 type CpuFactory interface { Run() string } type IntelCpu struct{} func (*IntelCpu) Run() string { …  ]]></content></entry><entry><title>redis主从同步</title><url>/post/database/redis_master_slave_synchronization/</url><categories><category>database</category></categories><tags><tag>redis</tag></tags><content type="html"><![CDATA[  redis主从同步 原理：
从服务器向主服务器发送 SYNC 命令。
接到 SYNC 命令的主服务器会调用BGSAVE 命令，创建一个 RDB 文件，并使用缓冲区记录接下来执行的所有写命令。
当主服务器执行完 BGSAVE 命令时，它会向从服务器发送 RDB 文件，而从服务器则会接收并载入这个文件。
主服务器将缓冲区储存的所有写命令发送给从服务器执行。
&mdash;&mdash;&mdash;&mdash;- 1、在开启主从复制的时候，使用的是RDB方式的，同步主从数据的 2、同步开始之后，通过主库命令传播的方式，主动的复制方式实现 3、2.8以后实现PSYNC的机制，实现断线重连
环境准备 6380.conf
1、环境： 准备两个或两个以上redis实例 mkdir /data/638{0..2} #创建6380 6381 6382文件夹 配置文件示例： vim /data/6380/redis.conf port 6380 daemonize yes pidfile /data/6380/redis.pid loglevel notice logfile &#34;/data/6380/redis.log&#34; dbfilename dump.rdb dir /data/6380 protected-mode no 6381.conf
vim /data/6381/redis.conf port 6381 daemonize yes pidfile /data/6381/redis.pid loglevel notice logfile &#34;/data/6381/redis.log&#34; dbfilename dump.rdb dir /data/6381 protected-mode no 6382.conf
port 6382 daemonize yes pidfile /data/6382/redis.pid loglevel notice logfile &#34;/data/6382/redis.log&#34; dbfilename dump.rdb dir /data/6382 protected-mode no 启动三个redis实例
redis-server /data/6380/redis.conf redis-server /data/6381/redis.conf redis-server /data/6382/redis.conf 主从规划
主节点：6380 从节点：6381、6382 配置主从同步 6381/6382命令行
redis-cli -p 6381 SLAVEOF 127.0.0.1 6380 #指明主的地址
redis-cli -p 6382 SLAVEOF 127.0.0.1 6380 #指明主的地址
检查主从状态
从库：
127.0.0.1:6382&gt; info replication 127.0.0.1:6381&gt; info replication 主库：
127.0.0.1:6380&gt; info replication 测试写入数据，主库写入数据，检查从库数据 主 127.0.0.1:6380&gt; set name chaoge 从 127.0.0.1:6381&gt;get name 手动进行主从复制故障切换 #关闭主库6380redis-cli -p 6380 shutdown 检查从库主从信息，此时master_link_status:down
redis-cli -p 6381 info replication redis-cli -p 6382 info replication 既然主库挂了，我想要在6381 6382之间选一个新的主库
1.关闭6381的从库身份
redis-cli -p 6381 info replication slaveof no one 2.将6382设为6381的从库
6382连接到6381： [root@db03 ~]## redis-cli -p 6382 127.0.0.1:6382&gt; SLAVEOF no one 127.0.0.1:6382&gt; SLAVEOF 127.0.0.1 6381 3.检查6382，6381的主从信息
  ]]></content></entry><entry><title>kratos http原理</title><url>/post/kratos/kratos_http_principle/</url><categories><category>kratos</category></categories><tags><tag>go</tag><tag>kratos</tag><tag>源码分析</tag></tags><content type="html"><![CDATA[  概念 kratos 为了使http协议的逻辑代码和grpc的逻辑代码使用同一份，选择了基于protobuf的IDL文件使用proto插件生成辅助代码的方式。
protoc http插件的地址为： https://github.com/go-kratos/kratos/tree/main/cmd/protoc-gen-go-http 示例 syntax = &amp;#34;proto3&amp;#34;; package helloworld; option go_package = &amp;#34;test/helloworld;helloworld&amp;#34;; option java_multiple_files = true; option java_package = &amp;#34;helloworld&amp;#34;; import &amp;#34;google/api/annotations.proto&amp;#34;; service Greeter { rpc SayHello (HelloRequest) returns (HelloReply) { option (google.api.http) = { post: &amp;#34;/helloworld&amp;#34;, // 声明路由 body: &amp;#34;*&amp;#34; }; } } message HelloRequest { string name = 1; } message HelloReply { string msg = 1; } 使用kratos proto client xxx 生成的代码为：
// Code generated by protoc-gen-go-http. DO NOT EDIT. // versions: // - protoc-gen-go-http v2.4.0 // - protoc v3.19.4 // source: helloworld/helloworld.proto package helloworld import ( context &amp;#34;context&amp;#34; http &amp;#34;github.com/go-kratos/kratos/v2/transport/http&amp;#34; binding …  ]]></content></entry><entry><title>容器基础-- namespace,Cgroup 和 UnionFS</title><url>/post/cloud/container_basics___namespace__cgroup_and_unionfs/</url><categories><category>cloud</category></categories><tags><tag>docker</tag><tag>containerd</tag><tag>kubernetes</tag><tag>namespace</tag><tag>Cgroup</tag><tag>UnionFS</tag></tags><content type="html">  Namespace 什么是 Namespace ？ 这里的 &amp;amp;ldquo;namespace&amp;amp;rdquo; 指的是 Linux namespace 技术，它是 Linux 内核实现的一种隔离方案。简而言之，Linux 操作系统能够为不同的进程分配不同的 namespace，每个 namespace 都具有独立的资源分配，从而实现了进程间的隔离。如果你的 Linux 安装了 GCC，可以通过运行 man namespaces 命令来查看相关文档，或者你也可以访问 在线手册 获取更多信息。
介绍 下图为各种 namespace 的参数，支持的起始内核版本，以及隔离内容。
Namespace 系统调用参数 内核版本 隔离内容 UTS (Unix Time-sharing System) CLONE_NEWUTS Linux 2.4.19 主机名与域名 IPC (Inter-Process Communication) CLONE_NEWIPC Linux 2.6.19 信号量、消息队列和共享内存 PID (Process ID) CLONE_NEWPID Linux 2.6.19 进程编号 Network CLONE_NEWNET Linux 2.6.24 网络设备、网络栈、端口等等 Mount CLONE_NEWNS Linux 2.6.29 挂载点（文件系统） User CLONE_NEWUSER Linux 3.8 用户和用户组 PID Namespace： 不同用户的进程通过 PID Namespace 进行隔离，并且不同的 Namespace 中可以有相同的进程 ID。在 Docker 中，所有的 LXC（Linux 容器）进程的父进程是 Docker 进程，每个 LXC 进程具有不同的 Namespace。由于支持嵌套 Namespace，因此可以方便地实现 Docker 中的 Docker（Docker in Docker）。 Net Namespace： 有了 PID Namespace，每个 Namespace 中的进程能够相互隔离，但是网络端口仍然共享主机的端口。通过 Net Namespace 实现网络隔离，每个 Net Namespace 具有独立的网络设备、IP 地址、IP 路由表和 /proc/net 目录。这样，每个容器的网络就能够得到隔 …  </content></entry><entry><title>RabbitMQ消息队列</title><url>/post/database/rabbitmq_message_queue/</url><categories><category>database</category></categories><tags><tag>RabbitMQ</tag></tags><content type="html">  消息队列 本篇文章主要介绍了 RabbitMQ 这种消息队列，从消息队列的概念、应用场景、安装方式到它的核心概念、五种工作模式。在安装的时候推荐使用 Docker 方式进行安装。重点需要理解的就是消息队列的应用场景、核心概念和 RabbitMQ 的五种工作模式，其中用的比较多的就是发布订阅模式、主题模式。
队列 (Queue) 是一种常见的数据结构，其最大的特性就是先进先出(Firist In First Out)，作为最基础的数据结构，队列应用很广泛，比如我们熟知的 Redis 基础数据类型 List，其底层数据结构就是队列。
消息队列 (Messaeg Queue) 是一种使用队列 (Queue) 作为底层存储数据结构，可用于解决不同进程与应用之间通讯的分布式消息容器，也称为消息中间件。
目前使用得比较多的消息队列有 ActiveMQ，RabbitMQ，Kafka，RocketMQ 等。本文主要讲述的是 RabbitMQ，RabbitMQ 是用 Erlang 语言开发的一个实现了 AMQP 协议的消息队列服务器，相比其他同类型的消息队列，最大的特点在保证可观的单机吞吐量的同时，延时方面非常出色。
RabbitMQ 支持多种客户端，比如：GO、Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP 等。
AMQP，即 Advanced Message Queuing Protocol，高级消息队列协议，是应用层协议的一个开放标准，为面向消息的中间件设计，它是一种应用程序之间的通信方法，消息队列在分布式系统开发中应用非常广泛。这里是 AMQP 官网 amqp.org 消息队列使用广泛，其应用场景有很多，下面我们列举比较常见的四个场景：
1、消息通讯 消息队列最主要功能收发消息，其内部有高效的通讯机制，因此非常适合用于消息通讯。
我们可以基于消息队列开发点对点聊天系统，也可以开发广播系统，用于将消息广播给大量接收者。
2、异步处理 一般我们写的程序都是顺序执行 (同步执行)，比如一个用户注册函数，其执行顺序如下：
1、写入用户注册数据。 2、发送注册邮件。 3、发送注册成功的短信通知。 4、更新统计数据。 按照上面的执行顺序，要全部执行完毕，才能返回成功，但其实在第 1 步执行成功后，其他的步骤完全可以异步执行， …  </content></entry><entry><title>http和https</title><url>/post/network/http_and_https/</url><categories><category>network</category></categories><tags><tag>network</tag></tags><content type="html">  HTTP协议是什么？ HTTP协议是超文本传输协议的缩写，英文是Hyper Text Transfer Protocol。它是从WEB服务器传输超文本标记语言(HTML)到本地浏览器的传送协议。 设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。 HTPP有多个版本，目前广泛使用的是HTTP/1.1版本。 HTTP原理 HTTP是一个基于TCP/IP通信协议来传递数据的协议，传输的数据类型为HTML 文件,、图片文件, 查询结果等。
HTTP协议一般用于B/S架构（）。浏览器作为HTTP客户端通过URL向HTTP服务端即WEB服务器发送所有请求。
我们以访问百度为例：
访问百度流程
http1.*和http2 这个Akamai公司建立的一个官方的演示，使用HTTP/1.1和HTTP/2同时请求379张图片，观察请求的时间，明显看出HTTP/2性能占优势。
多路复用：通过单一的HTTP/2连接请求发起多重的请求-响应消息，多个请求stream共享一个TCP连接，实现多流并行而不是依赖建立多个TCP连接。
HTTP报文格式
HTTP特点 http协议支持客户端/服务端模式，也是一种请求/响应模式的协议。 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。 灵活：HTTP允许传输任意类型的数据对象。传输的类型由Content-Type加以标记。 无连接：限制每次连接只处理一个请求。服务器处理完请求，并收到客户的应答后，即断开连接，但是却不利于客户端与服务器保持会话连接，为了弥补这种不足，产生了两项记录http状态的技术，一个叫做Cookie,一个叫做Session。 无状态：无状态是指协议对于事务处理没有记忆，后续处理需要前面的信息，则必须重传。 为什么要用https？ 实际使用中，绝大说的网站现在都采用的是https协议，这也是未来互联网发展的趋势。下面是通过wireshark抓取的一个博客网站的登录请求过程。
博客登录抓包
可以看到访问的账号密码都是明文传输， 这样客户端发出的请求很容易被不法分子截取利用，因此，HTTP协议不适合传输一些敏感信息，比如：各种账号、密码等信息，使用http协议传输隐私信息非常不安全。
一般http中存在如下问题：
请求信息明文传输，容易被窃听截取。 数据的完整性未校验， …  </content></entry><entry><title>golang操作etcd</title><url>/post/go/golang_operates_etcd/</url><categories><category>go</category></categories><tags><tag>boltdb</tag><tag>etcd</tag><tag>golang</tag><tag>数据库</tag><tag>kubernetes</tag></tags><content type="html">  etcd是近几年比较火热的一个开源的、分布式的键值对数据存储系统，提供共享配置、服务的注册和发现，本文主要介绍etcd的安装和使用。
etcd介绍 etcd 是使用Go语言开发的一个开源的、高可用的分布式key-value存储系统，可以用于配置共享和服务的注册和发现。
类似项目有zookeeper和consul。
etcd具有以下特点：
完全复制：集群中的每个节点都可以使用完整的存档 高可用性：Etcd可用于避免硬件的单点故障或网络问题 一致性：每次读取都会返回跨多主机的最新写入 简单：包括一个定义良好、面向用户的API（gRPC） 安全：实现了带有可选的客户端证书身份验证的自动化TLS 快速：每秒10000次写入的基准速度 可靠：使用Raft算法实现了强一致、高可用的服务存储目录 etcd应用场景 服务发现 服务发现要解决的也是分布式系统中最常见的问题之一，即在同一个分布式集群中的进程或服务，要如何才能找到对方并建立连接。本质上来说，服务发现就是想要了解集群中是否有进程在监听 udp 或 tcp 端口，并且通过名字就可以查找和连接。
配置中心 将一些配置信息放到 etcd 上进行集中管理。
这类场景的使用方式通常是这样：应用在启动的时候主动从 etcd 获取一次配置信息，同时，在 etcd 节点上注册一个 Watcher 并等待，以后每次配置有更新的时候，etcd 都会实时通知订阅者，以此达到获取最新配置信息的目的。
分布式锁 因为 etcd 使用 Raft 算法保持了数据的强一致性，某次操作存储到集群中的值必然是全局一致的，所以很容易实现分布式锁。锁服务有两种使用方式，一是保持独占，二是控制时序。
保持独占即所有获取锁的用户最终只有一个可以得到。etcd 为此提供了一套实现分布式锁原子操作 CAS（CompareAndSwap）的 API。通过设置prevExist值，可以保证在多个节点同时去创建某个目录时，只有一个成功。而创建成功的用户就可以认为是获得了锁。 控制时序，即所有想要获得锁的用户都会被安排执行，但是获得锁的顺序也是全局唯一的，同时决定了执行顺序。etcd 为此也提供了一套 API（自动创建有序键），对一个目录建值时指定为POST动作，这样 etcd 会自动在目录下生成一个当前最大的值为键，存储这个新的值（客户端编号）。同时还可以使用 API 按顺序 …  </content></entry><entry><title>隔离</title><url>/post/microservice/isolation/</url><categories><category>microservice</category></categories><tags><tag>go</tag><tag>grpc</tag></tags><content type="html">  什么是隔离？ 隔离，本质上是对系统或资源进行分割，从而实现当系统发生故障时能限定传播范围和影响范围，即发生故障后只有出问题的服务不可用，保证其他服务仍然可用。
服务隔离 动静隔离 例如 CDN
小到 CPU 的 cacheline false sharing、数据库 mysql 表设计中避免 bufferpool 频繁过期，隔离动静表，大到架构设计中的图片、静态资源等缓存加速。本质上都体现的一样的思路，即加速/缓存访问变换频次小的。比如 CDN 场景中，将静态资源和动态 API 分离，也是体现了隔离的思路:
降低应用服务器负载，静态文件访问负载全部通过CDN。 对象存储存储费用最低。 海量存储空间，无需考虑存储架构升级。 静态CDN带宽加速，延迟低。 archive: 稿件表，存储稿件的名称、作者、分类、tag、状态等信息，表示稿件的基本信息。 在一个投稿流程中，一旦稿件创建改动的频率比较低。 archive_stat: 稿件统计表，表示稿件的播放、点赞、收藏、投币数量，比较高频的更新。 随着稿件获取流量，稿件被用户所消费，各类计数信息更新比较频繁。 MySQL BufferPool 是用于缓存 DataPage 的，DataPage 可以理解为缓存了表的行，那么如果频繁更新 DataPage 不断会置换，会导致命中率下降的问题，所以我们在表设计中，仍然可以沿用类似的思路，其主表基本更新，在上游 Cache 未命中，透穿到 MySQL，仍然有 BufferPool 的缓存。
读写隔离 例如主从，除此之外还有常见的 CQRS 模式，分库分表等
常见的隔离技术，当用于读取操作的服务器出现故障时，写服务器照常可以运作，反之也一样。
轻重隔离 核心隔离：例如上面讲到将核心业务独立部署，非核心业务共享资源 热点隔离：例如上面讲到的 remote cache 到 local cache 用户隔离：不同的用户可能有不同的级别，例如上面讲到的外部用户和管理员 物理隔离 线程 常见的例子就是线程池，这个在 Golang 中一般不用过多考虑，runtime 已经帮我们管理好了
主要通过线程池进行隔离，也是实现服务隔离的基础。（可将图中隔离媒介换成线程池即可）
把业务进行分类并交给不同的线程池进行处理，当某个线程池处理一种业务请求发生问题时，不会讲故障扩散和影响到其他线程池，保证服务可 …  </content></entry><entry><title>限流</title><url>/post/microservice/current_limitation/</url><categories><category>microservice</category></categories><tags><tag>grpc</tag><tag>go</tag></tags><content type="html">  令牌桶算法 是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌。令牌桶算法的描述如下：
假设限制2r/s，则按照500毫秒的固定速率往桶中添加令牌。 桶中最多存放 b 个令牌，当桶满时，新添加的令牌被丢弃或拒绝。 当一个 n 个字节大小的数据包到达，将从桶中删除n 个令牌，接着数据包被发送到网络上。 如果桶中的令牌不足 n 个，则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）。 令牌桶速率限制算法: golang.org/x/time/rate
漏桶算法 作为计量工具(The Leaky Bucket Algorithm as a Meter)时，可以用于流量整形(Traffic Shaping)和流量控制(TrafficPolicing)，漏桶算法的描述如下：
一个固定容量的漏桶，按照常量固定速率流出水滴。 如果桶是空的，则不需流出水滴。 可以以任意速率流入水滴到漏桶。 如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的。 漏桶率限制算法: go.uber.org/ratelimit
过载保护 令牌桶与漏桶的缺点 漏斗桶/令牌桶确实能够保护系统不被拖垮, 但不管漏斗桶还是令牌桶, 其防护思路都是设定一个指标, 当超过该指标后就阻止或减少流量的继续进入，当系统负载降低到某一水平后则恢复流量的进入。但其通常都是被动的，其实际效果取决于限流阈值设置是否合理，但往往设置合理不是一件容易的事情。
集群增加机器或者减少机器限流阈值是否要重新设置? 设置限流阈值的依据是什么? 人力运维成本是否过高? 当调用方反馈429时, 这个时候重新设置限流, 其实流量高峰已经过了重新评估限流是否有意义? 这些其实都是采用漏斗桶/令牌桶的缺点, 总体来说就是太被动, 不能快速适应流量变化。 因此我们需要一种自适应的限流算法，即: 过载保护，根据系统当前的负载自动丢弃流量。
过载保护方法 计算系统临近过载时的峰值吞吐作为限流的阈值来进行流量控制，达到系统保护。
服务器临近过载时，主动抛弃一定量的负载，目标是自保。 在系统稳定的前提下，保持系统的吞吐量。 利特尔法则 计算吞吐量：利特尔法则 L = λ * W
利特尔法则由麻省理工大学斯隆商学院（MIT Sloan School of Management）的教授 John Little﹐于 1961  …  </content></entry><entry><title>超时控制</title><url>/post/microservice/timeout_control/</url><categories><category>microservice</category></categories><tags><tag>grpc</tag><tag>go</tag></tags><content type="html">  什么是超时控制？ 超时控制，使我们的服务之间调用可以快速抛错。比如API接口设置1s超时API调用A服务用了500ms，服务A调用和服务B用了600ms，n那么现在已经超时，还要调用服务C等等，再返回超时错误吗？这回事使服务C后面的链路做了无用功，浪费服务器资源。
GRPC的截止时间 截止时间以请求开始的绝对时间来表示（即使 API 将它们表示为持续时间偏移），并且应 用于多个服务调用。发起请求的应用程序设置截止时间，整个请求链需要在截止时间之前 进行响应。 gRPC API 支持为 RPC 使用截止时间，出于多种原因，在 gRPC 应用程序中使 用截止时间始终是一种最佳实践。由于 gRPC 通信是在网络上发生的，因此在 RPC 和响应 之间会有延迟。另外，在一些特定的场景中， gRPC 服务本身可能要花费更多的时间来响 应，这取决于服务的业务逻辑。如果客户端应用程序在开发时没有指定截止时间，那么它 们会无限期地等待自己所发起的 RPC 请求的响应，而资源都会被正在处理的请求所占用。 这会让服务和客户端都面临资源耗尽的风险，增加服务的延迟，甚至可能导致整个 gRPC 服务崩溃。
客户端应用程序的截止时间设置为 50 毫秒（截止时间 = 当前时间 + 偏移量）。客户端和 ProductMgt 服务之间的网络延迟为 0 毫秒， ProductMgt 服务的处理延迟为 20 毫秒。 商 品管理服务（ ProductMgt 服务）必须将截止时间的偏移量设置为 30 毫秒。 因为库存服 务（ Inventory 服务）需要 30 毫秒来响应， 所以截止时间的事件会在两个客户端上发生 （ ProductMgt 调用 Inventory 服务和客户端应用程序）。
ProductMgt 服务的业务逻辑将延迟时间增加了 20 毫秒。 随后， ProductMgt 服务的调用逻 辑触发了超出截止时间的场景，并且传播回客户端应用程序。因此，在使用截止时间时， 要明确它们适用于所有服务场景。
conn, err := grpc.Dial(address, grpc.WithInsecure()) if err != nil { log.Fatalf(&amp;#34;did not connect: %v&amp;#34;, err) } defer conn.Close() client := pb.NewOrderManagementClient(conn) clientDeadline := time.Now().Add( time.Duration(2 * time.Second)) ctx, cancel := context.WithDeadline(context.Background(), clientDeadline) defer cancel() // 调用方法传入ctx   </content></entry><entry><title>Go命令行工具cobra</title><url>/post/go/go_command_line_tool_cobra/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html">  关于 Cobra 是 Go 的 CLI 框架。它包含一个用于创建功能强大的现代 CLI 应用程序的库，以及一个用于快速生成基于 Cobra 的应用程序和命令文件的工具。
Cobra 由 Go 项目成员和 hugo 作者 spf13 创建，已经被许多流行的 Go 项目采用，比如 kubernetes、docker等
特性 简单的基于子命令的 CLIs：app server、app fetch 等； 完全兼容 POSIX（可移植操作系统接口） 的标志（包括短版和长版） 嵌套子命令 全局、局部和级联的标志 使用 cobra init appname 和 cobra add cmdname 轻松生成应用程序和命令 智能提示（app srver &amp;amp;hellip;did you mean app server） 自动生成命令和标志的帮助 自动识别 -h、--help 等帮助标识 自动为你的应用程序生成的 bash 自动完成 自动为你的应用程序生成 man 手册 命令别名，以便你可以更改内容而不会破坏它们 定义自己的帮助，用法等的灵活性。 可选与 viper 紧密集成，可用于 12factor 应用程序 概念 Cobra 构建在命令（commands）、参数（arguments）和 标志（flags）上。
Commands 代表动作，Args 是事物，Flags 是这些动作的修饰符。
最好的应用程序在使用时会像句子一样读起来。用户将知道如何使用该应用程序，因为他们将自然地了解如何使用它。
遵循的模式是 APPNAME VERB NOUN --ADJECTIVE。 或 APPNAME COMMAND ARG --FLAG
一些真实的例子可以更好地说明这一点。
在以下示例中，server 是命令，port 是标志：
hugo server --port=1313 在此命令中，我们告诉 Git 克隆 url 的内容：
git clone URL --bare 命令（Command） 命令是应用程序的核心。应用程序提供的每一个交互都包含在 Command 中。一个命令可以有子命令和可选的运行一个动作。
在上面的示例中，server 是命令。
Cobra.Command API )
标志（Flags） 一个标志是一种修饰命令行为的方式。Cobra 支持完全符合 [ …  </content></entry><entry><title>lua基础</title><url>/post/others/lua_basics/</url><categories><category>others</category></categories><tags><tag>lua</tag></tags><content type="html">  什么是lua Lua 是一个小巧的 脚本语言 。它是 巴西 里约热内卢天主教大学 （Pontifical Catholic University of Rio de Janeiro）里的一个由Roberto Ierusalimschy、Waldemar Celes 和 Luiz Henrique de Figueiredo三人所组成的研究小组于1993年开发的。 其设计目的是为了通过灵活嵌入应用程序中从而为应用程序提供灵活的扩展和定制功能。Lua由标准C编写而成，几乎在所有操作系统和平台上都可以编译，运行。Lua并没有提供强大的库，这是由它的定位决定的。所以Lua不适合作为开发独立应用程序的语言。Lua 有一个同时进行的JIT项目，提供在特定平台上的即时编译功能。
安装 mac：
brew install lua 检验：
lua -v Lua 5.4.2 Copyright (C) 1994-2020 Lua.org, PUC-Rio 注释 单行注释 两个减号是单行注释:
-- 多行注释 --[[ 多行注释 多行注释 --]] 标示符 Lua 标示符用于定义一个变量，函数获取其他用户定义的项。标示符以一个字母 A 到 Z 或 a 到 z 或下划线 _ 开头后加上 0 个或多个字母，下划线，数字（0 到 9）。
最好不要使用下划线加大写字母的标示符，因为Lua的保留字也是这样的。
Lua 不允许使用特殊字符如 @, $, 和 % 来定义标示符。 Lua 是一个区分大小写的编程语言。
关键词 以下列出了 Lua 的保留关键词。保留关键字不能作为常量或变量或其他用户自定义标示符：
and break do else elseif end false for function if in local nil not or repeat return then true until while goto 一般约定，以下划线开头连接一串大写字母的名字（比如 _VERSION）被保留用于 Lua 内部全局变量。
全局变量 在默认情况下，变量总是认为是全局的。
全局变量不需要声明，给一个变量赋值后即创建了这个全局变量，访问一个没有初始化的全局变量也不会出错，只不过得到的结果是：nil。
\&amp;amp;gt; print(b) nil \&amp;amp;gt; b=10 \&amp;amp;gt; print(b) 10 …  </content></entry><entry><title>kubernetes集群最新版安装</title><url>/post/cloud/kubernetes_cluster_latest_version_installation/</url><categories><category>cloud</category></categories><tags><tag>kubernetes</tag></tags><content type="html"><![CDATA[  原文地址：https://haiyux.cc/2022/09/21/k8s-install/ 虚拟机准备 我这里准备了三台虚拟机，分别部署一个master和两个node，操作系统位ubuntu 20.04。以下为特殊说明为三台机器都要做此操作
安装容器runtime 之前，我们用的容器runtime基本都是docker，但是docker并没有实现k8s的CRI，是在kubelet的有一个组件叫docker-shim做转化，在kubernetes v1.24版本以上这个组件已经废弃，这里选择containerd做容器runtime。当然，containerd是可以使用docker的镜像的。如果非要使用docker的话，被kubernetes废弃的docker-shim被docker自己维护起来了，可以试试看。但是不建议纯纯的浪费资源。
安装 apt install -y containerd 生成默认配置
mkdir /etc/containerd containerd config default &amp;gt; /etc/containerd/config.toml 配置systemd cgroup驱动程序
sed -i &amp;#39;s/SystemdCgroup = false/SystemdCgroup = true/g&amp;#39; /etc/containerd/config.toml 设置代理和修改pause镜像
重所周知的原因
镜像加速 我这里用的网易docker源 你也可以用别的 阿里源等
限免的的 https://xxxxx.mirror.aliyuncs.com 是阿里云加速，xxxx是我屏蔽字段
https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors 可以自啊这个地址申请自己的
sed -i &amp;#39;s|config_path = &amp;#34;&amp;#34;|config_path = &amp;#34;/etc/containerd/certs.d/&amp;#34;|g&amp;#39; /etc/containerd/config.toml mkdir -p /etc/containerd/certs.d/docker.io mkdir -p /etc/containerd/certs.d/docker.io …  ]]></content></entry><entry><title>redis发布订阅</title><url>/post/database/redis_publish_subscribe/</url><categories><category>database</category></categories><tags><tag>redis</tag></tags><content type="html">  什么是发布和订阅 Redis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。
Redis 客户端可以订阅任意数量的频道。
发布和订阅 1、客户端可以订阅频道如下图
2、当给这个频道发布消息后，消息就会发送给订阅的客户端
发布订阅命令行实现 1、 打开一个客户端订阅channel1
SUBSCRIBE channel1
2、打开另一个客户端，给channel1发布消息hello
publish channel1 hello
返回的1是订阅者数量
3、打开第一个客户端可以看到发送的消息
注：发布的消息没有持久化，如果在订阅的客户端收不到hello，只能收到订阅后发布的消息
  </content></entry><entry><title>vscode常用快捷键及插件</title><url>/post/others/vscode_commonly_used_shortcut_keys_and_plug_ins/</url><categories><category>others</category></categories><tags><tag>vscode</tag></tags><content type="html">  macOS 全局 Command + Shift + P / F1 显示命令面板 Command + P 快速打开 Command + Shift + N 打开新窗口 Command + W 关闭窗口 基本 Command + X 剪切（未选中文本的情况下，剪切光标所在行） Command + C 复制（未选中文本的情况下，复制光标所在行） ``Option + Up` 向上移动行 Option + Down 向下移动行 Option + Shift + Up 向上复制行 Option + Shift + Down 向下复制行 Command + Shift + K 删除行 Command + Enter 下一行插入 Command + Shift + Enter 上一行插入 Command + Shift + \ 跳转到匹配的括号 Command + [ 减少缩进 Command + ] 增加缩进 Home 跳转至行首 End 跳转到行尾 Command + Up 跳转至文件开头 Command + Down 跳转至文件结尾 Ctrl + PgUp 按行向上滚动 Ctrl + PgDown 按行向下滚动 Command + PgDown 按屏向下滚动 Command + PgUp 按屏向上滚动 Command + Shift + [ 折叠代码块 Command + Shift + ] 展开代码块 Command + K Command + [ 折叠全部子代码块 Command + K Command + ] 展开全部子代码块 Command + K Command + 0 折叠全部代码块 Command + K Command + J 展开全部代码块 Command + K Command + C 添加行注释 Command + K Command + U 移除行注释 Command + / 添加、移除行注释 Option + Shift + A 添加、移除块注释 Option + Z 自动换行、取消自动换行 多光标与选择 Option + 点击 插入多个光标 Command + Option + Up 向上插入光标 Command + Option + Down 向下插入光标 Command + U 撤销上一个光标操作 Option + Shift + I 在所 …  </content></entry><entry><title>makefile</title><url>/post/cloud/makefile/</url><categories><category>cloud</category></categories><tags><tag>makefile</tag></tags><content type="html"><![CDATA[  make make是一个构建自动化工具，会在当前目录下寻找Makefile或makefile文件。如果存在相应的文件，它就会依据其中定义好的规则完成构建任务。
makefile 什么是makefile？或许很多Winodws的程序员都不知道这个东西，因为那些Windows的IDE都为你做了这个工作，但我觉得要作一个好的和professional的程序员，makefile还是要懂。这就好像现在有这么多的HTML的编辑器，但如果你想成为一个专业人士，你还是要了解HTML的标识的含义。特别在Unix下的软件编译，你就不能不自己写makefile了，会不会写makefile，从一个侧面说明了一个人是否具备完成大型工程的能力。因为，makefile关系到了整个工程的编译规则。一个工程中的源文件不计数，其按类型、功能、模块分别放在若干个目录中，makefile定义了一系列的规则来指定，哪些文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译，甚至于进行更复杂的功能操作，因为makefile就像一个Shell脚本一样，其中也可以执行操作系统的命令。makefile带来的好处就是——“自动化编译”，一旦写好，只需要一个make命令，整个工程完全自动编译，极大的提高了软件开发的效率。make是一个命令工具，是一个解释makefile中指令的命令工具，一般来说，大多数的IDE都有这个命令，比如：Delphi的make，Visual C++的nmake，Linux下GNU的make。可见，makefile都成为了一种在工程方面的编译方法。
规则概述 Makefile由多条规则组成，每条规则主要由两个部分组成，分别是依赖的关系和执行的命令。
其结构如下所示：
[target] ... : [prerequisites] ... [command] ... ... 其中：
targets：规则的目标 prerequisites：可选的要生成 targets 需要的文件或者是目标。 command：make 需要执行的命令（任意的 shell 命令）。可以有多条命令，每一条命令占一行。 举个例子：
build: CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o xx 示例 .PHONY: all build run gotool clean help BINARY=&#34;coursemanager&#34; all: build build: CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o ${BINARY} run: @go run ./ gotool: go fmt ./ go vet ./ clean: @if [ -f ${BINARY} ] ; then rm ${BINARY} ; fi help: @echo &#34;make - 格式化 Go 代码, 并编译生成二进制文件&#34; @echo &#34;make build - 编译 Go 代码, 生成二进制文件&#34; @echo &#34;make run - 直接运行 Go 代码&#34; @echo &#34;make clean - 移除二进制文件和 vim swap files&#34; @echo &#34;make gotool - 运行 Go 工具 &#39;fmt&#39; and &#39;vet&#39;&#34; 参考文章:
https://www.liwenzhou.com/posts/Go/makefile/ https://blog.csdn.net/weixin_38391755/article/details/80380786   ]]></content></entry><entry><title>Go工程化 - 依赖注入</title><url>/post/kratos/go_engineering___dependency_injection/</url><categories><category>kratos</category></categories><tags><tag>go</tag><tag>kratos</tag><tag>wire</tag></tags><content type="html">  我们在微服务框架 kratos v2 的默认项目模板中 kratos-layout 使用了 google/wire 进行依赖注入，也建议开发者在维护项目时使用该工具。
wire 乍看起来比较违反直觉，导致很多同学不理解为什么要用或不清楚如何用（也包括曾经的我），本文来帮助大家理解 wire 的使用。
What wire 是由 google 开源的一个供 Go 语言使用的依赖注入代码生成工具。它能够根据你的代码，生成相应的依赖注入 go 代码。
而与其它依靠反射实现的依赖注入工具不同的是，wire 能在编译期（准确地说是代码生成时）如果依赖注入有问题，在代码生成时即可报出来，不会拖到运行时才报，更便于 debug。
Why 理解依赖注入 什么是依赖注入？为什么要依赖注入？ 依赖注入就是 Java 遗毒（不是）
依赖注入 (Dependency Injection，缩写为 DI)，可以理解为一种代码的构造模式（就是写法），按照这样的方式来写，能够让你的代码更加容易维护。
对于很多软件设计模式和架构的理念，我们都无法理解他们要绕好大一圈做复杂的体操、用奇怪的方式进行实现的意义。他们通常都只是丢出来一段样例，说这样写就很好很优雅，由于省略掉了这种模式是如何发展出来的推导过程，我们只看到了结果，导致理解起来很困难。那么接下来我们来尝试推导还原一下整个过程，看看代码是如何和为什么演进到依赖注入模式的，以便能够更好理解使用依赖注入的意义。
依赖是什么？ 这里的依赖是个名词，不是指软件包的依赖（比如那坨塞在 node_modules 里面的东西），而是指软件中某一个模块（对象/实例）所依赖的其它外部模块（对象/实例）。
注入到哪里？ 被依赖的模块，在创建模块时，被注入到（即当作参数传入）模块的里面。
不 DI 是啥样？DI 了又样子？ 下面用 go 伪代码来做例子，领会精神即可。
假设个场景，你在打工搞一个 web 应用，它有一个简单接口。最开始的项目代码可能长这个样子：
# 下面为伪代码，忽略了很多与主题无关的细节 type App struct { } # 假设这个方法将会匹配并处理 GET /biu/&amp;amp;lt;id&amp;amp;gt; 这样的请求 func (a *App) GetData(id string) string { # todo: write your data query …  </content></entry><entry><title>kratos v2版本命令行工具使用</title><url>/post/kratos/kratos_v2_command_line_tool_usage/</url><categories><category>kratos</category></categories><tags><tag>go</tag><tag>kratos</tag></tags><content type="html"><![CDATA[  使用 下载 go install github.com/go-kratos/kratos/cmd/kratos/v2@latest 查看是否安装成功
kratos -v kratos version v2.1.3 升级 kratos upgrade 查看帮助 kratos --help Kratos: An elegant toolkit for Go microservices. Usage: kratos [command] Available Commands: changelog Get a kratos change log completion generate the autocompletion script for the specified shell help Help about any command new Create a service template proto Generate the proto files run Run project upgrade Upgrade the kratos tools Flags: -h, --help help for kratos -v, --version version for kratos Use &#34;kratos [command] --help&#34; for more information about a command. new命令 kratos new 命令为创建一个kratos项目
参数：
-r repo地址 默认为https://github.com/go-kratos/kratos-layout
-b git版本 默认为main分支
-t 超时时间 默认为60s
也可添加环境变量KRATOS_LAYOUT_REPO 知道远程repo
创建一个项目
kratos new helloworld 因为默认远程仓库地址是 github上的，在国内很容易创建失败，所以要需要设置终端或者git代理（什么是终端代理和git代理可以百度或者google一下）。
当然你也可以使用-r 知道国内仓库 我们提供一个国内镜像https://gitee.com/go-kratos/kratos-layout。
如果嫌弃每次都要-r指定麻烦，也可以把KRATOS_LAYOUT_REPO=https://gitee.com/go-kratos/kratos-layout 加入到path中。
kratos new helloworld -r https://gitee.com/go-kratos/kratos-layout proto命令 proto命令下有 add client 和 server子命令
add kratos proto add 为创建一个proto模板
kratos proto add api/helloworld/v2/hello.proto 在目录api/helloworld/v2 下可以看到生成的文件
syntax = &#34;proto3&#34;; package api.helloworld.v2; option go_package = &#34;helloworld/api/helloworld/v2;v2&#34;; option java_multiple_files = true; option java_package = &#34;api.helloworld.v2&#34;; service Hello { rpc CreateHello (CreateHelloRequest) returns (CreateHelloReply); rpc UpdateHello (UpdateHelloRequest) returns (UpdateHelloReply); rpc DeleteHello (DeleteHelloRequest) returns (DeleteHelloReply); rpc GetHello (GetHelloRequest) returns (GetHelloReply); rpc ListHello (ListHelloRequest) returns (ListHelloReply); } message CreateHelloRequest {} message CreateHelloReply {} message UpdateHelloRequest {} message UpdateHelloReply {} message DeleteHelloRequest {} message DeleteHelloReply {} message GetHelloRequest {} message GetHelloReply {} message ListHelloRequest {} message ListHelloReply {} client kratos proto client 为生成 Proto 代码
使用这个命令需要下载 protobuf 工具 protoc，可以在官网下载对应版本 Protobuf release版本 kratos proto client api/helloworld/v2/ 这条命令就可以编译api/helloworld/v2/下的所有.proto文件
如果我们需要 import 其他proto文件 可以在命令后面加上protoc的参数
比如
kratos proto client api/helloworld/v2/ --proto_path=api/helloworld/v2 默认也会把 ./third_party 下import 进来 需要第三方的proto文件 可以放在这里
server kratos proto server为指定proto文件生成简单的service代码
参数：
-t 生成代码的位置 默认是internal/service 比如
kratos proto server api/helloworld/v2/hello.proto -t=internal/service/hello 生成的代码
package service import ( &#34;context&#34; pb &#34;helloworld/api/helloworld/v2&#34; ) type HelloService struct { pb.UnimplementedHelloServer } func NewHelloService() *HelloService { return &amp;HelloService{} } func (s *HelloService) ListHello(ctx context.Context, req *pb.ListHelloRequest) (*pb.ListHelloReply, error) { return &amp;pb.ListHelloReply{}, nil } run命令 启动服务
kratos run 原文地址 kratos v2版本命令行工具使用 - haiyux&rsquo;s blog   ]]></content></entry><entry><title>从kratos分析breaker熔断器源码实现</title><url>/post/kratos/analyzing_the_breaker_fuse_source_code_implementation_from_kratos/</url><categories><category>kratos</category></categories><tags><tag>go</tag><tag>kratos</tag><tag>breaker</tag><tag>源码分析</tag></tags><content type="html">  为什么要用熔断 前面我们讲过限流保证服务的可用性，不被突如其来的流量打爆。但是两种情况是限流解决不了的。
如果我们服务只能处理1000QPS，但是有10wQPS打过来，服务还是会炸。因为拒绝请求也需要成本。 服务但是io型的，会把mysql，redis，mq等中间件打挂。 所以，我们遵循一个思路，可不可以client端在失败的多的时候就不调用了，直接返回错误呢？
什么是熔断 熔断器是为了当依赖的服务已经出现故障时，主动阻止对依赖服务的请求。保证自身服务的正常运行不受依赖服务影响，防止雪崩效应。
源码分析 源码地址 https://github.com/go-kratos/aegis/tree/main/circuitbreaker CircuitBreaker 接口 type CircuitBreaker interface { Allow() error MarkSuccess() MarkFailed() } Allow() 判断熔断器是否允许通过 MarkSuccess() 熔断器成功的回调 MarkFailed() 熔断器失败的回调 Group 结构体 type Group struct { mutex sync.Mutex val atomic.Value New func() CircuitBreaker } mutex 互斥锁，使val这个map不产生数据竞争 val map，存储name -&amp;amp;gt; CircuitBreaker New 生成一个CircuitBreaker Get方法 // Get . func (g *Group) Get(name string) CircuitBreaker { m, ok := g.val.Load().(map[string]CircuitBreaker) if ok { breaker, ok := m[name] if ok { return breaker // 很具name从val拿出 breaker 如果存在返回 } } // slowpath for group don`t have specified name breaker. g.mutex.Lock() nm := make(map[string]CircuitBreaker, len(m)+1) for k, v := range m …  </content></entry><entry><title>从kratos分析BBR限流源码实现</title><url>/post/kratos/analyzing_the_implementation_of_bbr_current_limiting_source_code_from_kratos/</url><categories><category>kratos</category></categories><tags><tag>go</tag><tag>kratos</tag><tag>BBR</tag><tag>源码分析</tag></tags><content type="html">  什么是自适应限流 自适应限流从整体维度对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。
核心目标：
自动嗅探负载和 qps，减少人工配置 削顶，保证超载时系统不被拖垮，并能以高水位 qps 继续运行 限流规则 计算吞吐量：利特尔法则 L = λ * W
如上图所示，如果我们开一个小店，平均每分钟进店 2 个客人(λ)，每位客人从等待到完成交易需要 4 分钟(W)，那我们店里能承载的客人数量就是 2 * 4 = 8 个人
同理，我们可以将 λ 当做 QPS， W 呢是每个请求需要花费的时间，那我们的系统的吞吐就是 L = λ * W ，所以我们可以使用利特尔法则来计算系统的吞吐量。
指标介绍 指标名称 指标含义 cpu 最近 1s 的 CPU 使用率均值，使用滑动平均计算，采样周期是 250ms inflight 当前处理中正在处理的请求数量 pass 请求处理成功的量 rt 请求成功的响应耗时 滑动窗口 在自适应限流保护中，采集到的指标的时效性非常强，系统只需要采集最近一小段时间内的 qps、rt 即可，对于较老的数据，会自动丢弃。为了实现这个效果，kratos 使用了滑动窗口来保存采样数据。
如上图，展示了一个具有两个桶（bucket）的滑动窗口（rolling window）。整个滑动窗口用来保存最近 1s 的采样数据，每个小的桶用来保存 500ms 的采样数据。 当时间流动之后，过期的桶会自动被新桶的数据覆盖掉，在图中，在 1000-1500ms 时，bucket 1 的数据因为过期而被丢弃，之后 bucket 3 的数据填到了窗口的头部。
限流公式 判断是否丢弃当前请求的算法如下：
cpu &amp;amp;gt; 800 AND (Now - PrevDrop) &amp;amp;lt; 1s AND (MaxPass * MinRt * windows / 1000) &amp;amp;lt; InFlight MaxPass 表示最近 5s 内，单个采样窗口中最大的请求数。 MinRt 表示最近 5s 内，单个采样窗口中最小的响应时间。 windows 表示一秒内采样窗口的数量，默认配置中是 5s 50 个 …  </content></entry><entry><title>Kratos漫游指南 1 - 概览</title><url>/post/kratos/the_hitchhikers_guide_to_kratos_1___overview/</url><categories><category>kratos</category></categories><tags><tag>go</tag><tag>kratos</tag></tags><content type="html">  您好，地球人，欢迎来到Kratos漫游指南。
对于刚开始研究Kratos框架的开发者来说，目前的文档有些零散，这与我们的模块化设计有一些关系，不过Don&amp;amp;rsquo;t panic，从这篇文章开始，我将试图打破这一现状，漫游指南系列将循序渐进地介绍Kratos框架，理顺框架的使用思路，使您更快上手Kratos。
同时，这个系列也会逐步整合进官方文档中，同时重新组织整个文档的结构和内容，敬请期待。
本篇是该系列的第一篇，主要介绍Kratos的整体概况。
设计哲学 Kratos是一个Go语言实现的微服务框架，说得更准确一点，它更类似于一个使用Go构建微服务的工具箱，开发者可以按照自己的习惯选用或定制其中的的组件，来打造自己的微服务。也正是由于这样的原因，Kratos并不绑定于特定的基础设施，不限定于某种注册中心，或数据库ORM等，所以您可以十分轻松地将任意库集成进项目里，与Kratos共同运作。
围绕这样的核心设计理念，我们设计了如下的项目生态：
kratos Kratos框架核心，主要包含了基础的CLI工具，内置的HTTP/gRPC接口生成和服务生命周期管理，提供链路追踪、配置文件、日志、服务发现、监控等组件能力和相关接口定义。 contrib 基于上述核心定义的基础接口，对配置文件、日志、服务发现、监控等服务进行具体实现所形成的一系列插件，可以直接使用它们，也可以参考它们的代码，做您需要的服务的适配，从而集成进kratos项目中来。 aegis 我们将服务可用性相关的算法：如限流、熔断等算法放在了这个独立的项目里，几乎没有外部依赖，它更不依赖Kratos，您可以在直接在任意项目中使用。您也可以轻松将它集成到Kratos中使用，提高服务的可用性。 layout 我们设计的一个默认的项目模板，它包含一个参考了DDD和简洁架构设计的项目结构、Makefile脚本和Dockerfile文件。但这个项目模板不是必需的，您可以任意修改它，或使用自己设计的项目结构，Kratos依然可以正常工作。框架本身不对项目结构做任何假设和限制，您可以按照自己的想法来使用，具有很强的可定制性。 gateway 这个是我们刚刚起步，用Go开发的API Gateway，后续您可以使用它来作为您Kratos微服务的网关，用于微服务API的治理，项目正在施工中，欢迎关注。 仓库、 …  </content></entry><entry><title>基于 OpenTelemetry 的链路追踪</title><url>/post/kratos/link_tracing_based_on_opentelemetry/</url><categories><category>kratos</category></categories><tags><tag>go</tag><tag>kratos</tag><tag>opentelemetry</tag></tags><content type="html">  链路追踪的前世今生 分布式跟踪（也称为分布式请求跟踪）是一种用于分析和监控应用程序的方法，尤其是使用微服务架构构建的应用程序。分布式跟踪有助于精确定位故障发生的位置以及导致性能差的原因。
起源 链路追踪(Distributed Tracing)　一词最早出现于谷歌发布的论文 《Dapper, a Large-Scale Distributed Systems Tracing Infrastructure》 中,这篇论文对于实现链路追踪,对于后来出现的 Jaeger、Zipkin 等开源分布式追踪项目设计理念仍有很深的影响。
微服务架构是一个分布式的架构,会有很多个不同的服务。不同的服务之前相互调用,如果出现了错误由于一个请求经过了 N 个服务。随着业务的增加越来越多的服务之间的调用，如果没有一个工具去记录调用链，解决问题的时候就会像下面图片里小猫咪玩的毛线球一样，毫无头绪，无从下手
所以需要有一个工具能够清楚的了解一个请求经过了哪些服务,顺序是如何,从而能够轻易的定位问题。
百家争艳 从谷歌发布 Dapper 后，分布式链路追踪工具越来越多，以下简单列举了一些常用的链路追踪系统
Skywalking 阿里 鹰眼 大众点评 CAT Twitter Zipkin Naver pinpoint Uber Jaeger 争锋相对？ 随着链路追踪工具越来越多，开源领域主要分为两派，一派是以 CNCF技术委员 会为主的 OpenTracing 的规范，例如 jaeger zipkin 都是遵循了OpenTracing 的规范。而另一派则是谷歌作为发起者的 OpenCensus，而且谷歌本身还是最早提出链路追踪概念的公司，后期连微软也加入了 OpenCensus
OpenTelemetry 诞生 OpenTelemetric 是一组 API、SDK、模组和集成，专为创建和管理‎‎遥测数据‎‎（如追踪、指标和日志）而设
微软加入 OpenCensus 后，直接打破了之前平衡的局面，间接的导致了 OpenTelemetry 的诞生 谷歌和微软下定决心结束江湖之乱，首要的问题是如何整合两个两个社区已有的项目，OpenTelemetry 主要的理念就是，兼容 OpenCensus 和 OpenTracing ，可以让使用者无需改动或者很小的改动就可以接入 OpenTelemetry …  </content></entry><entry><title>通过 layout 探索 kratos 运行原理</title><url>/post/kratos/explore_the_working_principle_of_kratos_through_layout/</url><categories><category>kratos</category></categories><tags><tag>go</tag><tag>kratos</tag></tags><content type="html"><![CDATA[  创建项目 首先需要安装好对应的依赖环境，以及工具：
go 下载 protoc go install google.golang.org/protobuf/cmd/protoc-gen-go@latest protoc-gen-go go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest # 创建项目模板 kratos new helloworld cd helloworld # 拉取项目依赖 go mod download # 生成proto模板 kratos proto add api/helloworld/helloworld.proto # 生成proto源码 kratos proto client api/helloworld/helloworld.proto # 生成server模板 kratos proto server api/helloworld/helloworld.proto -t internal/service 执行命令后,会在当前目录下生成一个 service 工程,工程骨架如下,具体的工程骨架说明可以访问 layout 运行项目 # 生成所有proto源码、wire等等 go generate ./... # 编译成可执行文件 go build -o ./bin/ ./... # 运行项目 ./bin/helloworld -conf ./configs 看到如下输出则证明项目启动正常
level=INFO module=app service_id=7114ad8a-b3bf-11eb-a1b9-f0189850d2cb service_name= version= level=INFO module=transport/grpc msg=[gRPC] server listening on: [::]:9000 level=INFO module=transport/http msg=[HTTP] server listening on: [::]:8000 测试接口
curl &amp;#39;http://127.0.0.1:8000/helloworld/krtaos&amp;#39; 输出： { &amp;#34;message&amp;#34;: &amp;#34;Hello …  ]]></content></entry><entry><title>Prometheus</title><url>/post/cloud/prometheus/</url><categories><category>cloud</category></categories><tags><tag>prometheus</tag><tag>kubernetes</tag></tags><content type="html">  Prometheus简介 什么是 Prometheus Prometheus 是在 Soundcloud 以开源软件的形式进行研发的系统监控和告警工具包，自此以后，许多公司和组织都采用了 Prometheus 作为监控告警工具。Prometheus 的开发者和用户社区非常活跃，它现在是一个独立的开源项目，可以独立于任何公司进行维护。Prometheus 于 2016 年 5 月加入 CNCF 基金会，成为继 Kubernetes 之后的第二个 CNCF 托管项目。
Prometheus 的优势 Prometheus 的主要优势有：
由指标名称和和键/值对标签标识的时间序列数据组成的多维 数据模型 。 强大的 查询语言 PromQL 。 不依赖分布式存储；单个服务节点具有自治能力。 时间序列数据是服务端通过 HTTP 协议主动拉取获得的。 也可以通过中间网关来 推送时间序列数据 。 可以通过静态配置文件或服务发现来获取监控目标。 支持多种类型的图表和仪表盘。 Prometheus 的组件 Prometheus 生态系统由多个组件组成，其中有许多组件是可选的：
Prometheus Server 作为服务端，用来存储时间序列数据。 客户端库 用来检测应用程序代码。 用于支持临时任务的 推送网关 。 Exporter 用来监控 HAProxy，StatsD，Graphite 等特殊的监控目标，并向 Prometheus 提供标准格式的监控样本数据。 alartmanager 用来处理告警。 其他各种周边工具。 其中大多数组件都是用 Go 编写的，因此很容易构建和部署为静态二进制文件。
Prometheus 的架构 Prometheus 的整体架构以及生态系统组件如下图所示：
Prometheus Server 直接从监控目标中或者间接通过推送网关来拉取监控指标，它在本地存储所有抓取到的样本数据，并对此数据执行一系列规则，以汇总和记录现有数据的新时间序列或生成告警。可以通过 Grafana 或者其他工具来实现监控数据的可视化。
数据类型 Prometheus 所有采集的监控数据均以指标（metric）的形式保存在内置的 时间序列 数据库当中（TSDB）：属于同一指标名称，同一标签集合的、有时间戳标记的数据流。除了存储的时间序列，Prometheus 还可以根据查询请求产生临 …  </content></entry><entry><title>kratos 日志库的使用姿势</title><url>/post/kratos/how_to_use_the_log_library/</url><categories><category>kratos</category></categories><tags><tag>go</tag><tag>kratos</tag></tags><content type="html"><![CDATA[  什么是日志 所谓日志（Log）是指系统所指定对象的某些操作和其操作结果按时间有序的集合。log文件就是日志文件，log文件记录了系统和系统的用户之间交互的信息，是自动捕获人与系统终端之间交互的类型、内容或时间的数据收集方法。
日志是用来记录，用户操作，系统状态，错误信息等等内容的文件，是一个软件系统的重要组成部分。一个良好的日志规范，对于系统运行状态的分析，以及线上问题的解决具有重大的意义。
日志规范 在开发软件打印日志时，需要注意一些问题，举例可能不全，可以自行百度相关文章或查看文章底部文献：
重要功能日志尽可能的完善。 不要随意打印无用的日志，过多无用的日志会增加分析日志的难度。 日志要区分等级 如 debug，warn，info，error 等。 捕获到未处理错误时最好打印错误堆栈信息 Go 语言常用的日志库 Go 语言标准库中就为我们提供了一个日志库 log，除了这个以外还有很多日志库，如 logrus，glog，logx，Uber 的 zap 等等，例如 zap 就有很多的优点：
高性能 配置项丰富 多种日志级别 支持Hook 丰富的工具包 提供了sugar log 多种日志打印格式 &amp;hellip; 简单使用 package main import ( &amp;#34;errors&amp;#34; &amp;#34;go.uber.org/zap&amp;#34; ) var logger *zap.Logger func init() { logger, _ = zap.NewProduction() } func main() { logger.Error( &amp;#34;My name is baobao&amp;#34;, zap.String(&amp;#34;from&amp;#34;, &amp;#34;Hulun Buir&amp;#34;), zap.Error(errors.New(&amp;#34;no good&amp;#34;))) logger.Info(&amp;#34;Worked in the Ministry of national development of China!&amp;#34;, zap.String(&amp;#34;key&amp;#34;, &amp;#34;eat🍚&amp;#34;), zap.String(&amp;#34;key&amp;#34;, &amp;#34;sleep😴&amp;#34;)) defer logger.Sync() } …  ]]></content></entry><entry><title>Linux基础系统优化</title><url>/post/cloud/linux_basic_system_optimization/</url><categories><category>cloud</category></categories><tags><tag>linux</tag></tags><content type="html">  Linux基础系统优化 Linux的网络功能相当强悍，一时之间我们无法了解所有的网络命令，在配置服务器基础环境时，先了解下网络参数设定命令。
ifconfig　查询、设置网卡和ip等参数 ifup,ifdown 脚本命令，更简单的方式启动关闭网络 ip　符合指令，直接修改上述功能 在我们刚装好linux的时候，需要用xshell进行远程连接，那就得获取ip地址，有时候网卡默认是没启动的，Linux也就拿不到ip地址，因此我们得手动启动网卡
编辑网卡配置文件vim /etc/sysconfig/network-scripts/ifcfg-eth0 修改配置参数ONBOOT=yes 网卡配置文件详解 网络配置文件：/etc/sysconfig/network 网络接口配置文件：etc/sysconfig/network-scripts/ifcfg-INTERFACE_NAME DEVICE=: 关联的设备名称，要与文件名的后半部“INTERFACE_NAME”保持一致; BOOTPROTO={static|none|dhcp|bootp}:引导协议；要使用静态地址，使用static或none；dhcp表示使用DHCP服务器获取地址； IPADDR=IP地址 NETMASK=：子网掩码 GATEWAY=：设定默认网关； ONBOOT=：开机时是否自动激活此网络接口； HWADDR=： 硬件地址，要与硬件中的地址保持一致；可省； USERCTL={yes|no}: 是否允许普通用户控制此接口； PEERDNS={yes|no}: 是否在BOOTPROTO为dhcp时接受由DHCP服务器指定的DNS地址； ifup,ifdown命令 启动/关闭一块网卡 ifup eth0 ifdown eth0 ifconfig命令 ifconfig 查看网卡的ip地址 接输入ifconfig会列出已经启动的网卡，也可以输入ifconfig eth0单独显示eth0的信息 选项解释是： th0 网卡的代号 o 回环地址loopback net IPv4的Ip地址 etmask 子网掩码 roadcast 广播地址 X/TX 流量发/收情况 tx是发送（transport），rx是接收(receive) ackets 数据包数 rrors 数据包错误数 ropped …  </content></entry><entry><title>Linux核心知识</title><url>/post/cloud/linux_core_knowledge/</url><categories><category>cloud</category></categories><tags><tag>linux</tag></tags><content type="html">  电脑：辅助人脑的工具 现在的人们几乎无时无刻都会碰电脑！不管是桌上型电脑(桌机)、笔记型电脑(笔电)、平板电脑、智慧型手机等等，这些东西都算是电脑。虽然接触的这么多，但是，你了解电脑里面的元件有什么吗？以桌机来说，电脑的机壳里面含有什么元件？不同的电脑可以应用在哪些工作？你生活周遭有哪些电器用品内部是含有电脑相关元件的？底下我们就来谈一谈这些东西呢！
所谓的电脑就是一种计算机，而计算机其实是：『接受使用者输入指令与资料，经由中央处理器的数学与逻辑单元运算处理后，以产生或储存成有用的资讯』。因此，只要有输入设备(不管是键盘还是触控式萤幕)及输出设备(例如电脑萤幕或直接由印表机列印出来)，让你可以输入资料使该机器产生资讯的，那就是一部计算机了。
好了，根据这个定义你知道哪些东西是计算机了吗？其实包括一般商店用的简易型加减乘除计算机、打电话用的手机、开车用的卫星定位系统(GPS)、提款用的提款机(ATM)、你上课会使用的桌上型个人电脑、外出可能会带的笔记型电脑(包括notebook与netbook)，还有近几年(2015前后)非常热门的平板电脑与智慧型手机，甚至是未来可能会大流行的单版电脑(Xapple pi, banana pi, Raspberry pi, )与智慧型手表，甚至于更多的智慧型穿戴式电脑等等，这些都是计算机喔！
电脑硬件的组成 关于电脑的硬件组成部分，其实你可以观察你的桌上型电脑来分析一下，依外观来说这家伙主要可分为三部分，分别是：
输入单元：包括键盘、滑鼠、读卡机、扫描器、手写板、触控萤幕等等一堆； 主机部分：这个就是系统单元，被主机机壳保护住了，里面含有一堆板子、CPU 与主记忆体等； 输出单元：例如萤幕、印表机等等 我们主要透过输入设备如滑鼠与键盘来将一些资料输入到主机里面，然后再由主机的功能处理成为图表或文章等资讯后， 将结果传输到输出设备，如萤幕或印表机上面。那主机里面含有什么元件呢？如果你曾经拆开过电脑主机机壳(包括拆开你的智慧型手机也一样喔！)， 会发现其实主机里面最重要的就是一片主机板，上面安插了中央处理器(CPU) 以及主记忆体、硬碟(或记忆卡) 还有一些介面卡装置而已。当然大部分智慧型手机是将这些元件直接焊接在主机板上面而不是插卡啦！
整部主机的重点在于中央处理器(Central Processing Unit, CPU)，CPU为一 …  </content></entry><entry><title>Linux常用命令</title><url>/post/cloud/common_linux_commands/</url><categories><category>cloud</category></categories><tags><tag>linux</tag></tags><content type="html">  常用指令 ls	显示文件或目录
-l 列出文件详细信息l(list) -a 列出当前目录下所有文件及目录，包括隐藏的a(all) mkdir 创建目录
-p 创建目录，若无父目录，则创建p(parent) cd 切换目录
touch 创建空文件
echo 创建带有内容的文件。
cat 查看文件内容
cp 拷贝
mv 移动或重命名
rm 删除文件
-r 递归删除，可删除子目录及文件 -f 强制删除 find 在文件系统中搜索某文件
wc 统计文本中行数、字数、字符数
grep 在文本文件中查找某个字符串
rmdir 删除空目录
tree 树形结构显示目录，需要安装tree包
pwd 显示当前目录
ln 创建链接文件
more、less 分页显示文本文件内容
head、tail 显示文件头、尾内容
ctrl+alt+F1 命令行全屏模式
系统管理命令 stat 显示指定文件的详细信息，比ls更详细 who 显示在线登陆用户 whoami 显示当前操作用户 hostname 显示主机名 uname 显示系统信息 top 动态显示当前耗费资源最多进程信息 ps 显示瞬间进程状态 ps -aux du 查看目录大小 du -h /home带有单位显示目录信息 df 查看磁盘大小 df -h 带有单位显示磁盘信息 ifconfig 查看网络情况 ping 测试网络连通 netstat 显示网络状态信息 man 命令不会用了，找男人 如：man ls clear 清屏 alias 对命令重命名 如：alias showmeit=&amp;amp;quot;ps -aux&amp;amp;quot; ，另外解除使用unaliax showmeit kill 杀死进程，可以先用ps 或 top命令查看进程的id，然后再用kill命令杀死进程。 打包压缩相关命令 gzip 例如：zip -r mysql.zip mysql 该句命令的含义是：将mysql文件夹压缩成mysql.zip zip -r abcdef.zip abc def.txt 这句命令的意思是将文件夹abc和文件def.txt压缩成一个压缩包abcdef.zip bzip2 与zip命令相反，这是解压命令，用起来很简单。 如：unzip mysql.zip 在当前目录下直接解压mysql.zip。 tar -c 归档文件 -x 压缩文件 -z …  </content></entry><entry><title>微服务架构及raft协议</title><url>/post/microservice/microservice_architecture_and_raft_protocol/</url><categories><category>microservice</category></categories><tags><tag>etcd</tag></tags><content type="html">  微服务架构全景图 服务注册和发现 Client side implement
调用需要维护所有调用服务的地址 有一定的技术难度，需要rpc框架支持 Server side implement
架构简单 有单点故障 注册中心 etcd注册中心
分布式一致性系统 基于raft一致性协议 etcd使用场景
服务注册和发现 共享配置 分布式锁 Leader选举 Raft协议详解 应用场景
解决分布式系统一致性的问题 基于复制的 工作机制
leader选举 日志复制 安全性 基本概念 raft协议演示：http://www.kailing.pub/raft/index.html
角色
Follower角色 Leader角色 Candicate角色 Term（任期）概念
在raft协议中，将时间分成一个个term（任期） 复制状态机 在一个分布式系统数据库中,如果每个节点的状态一致,每个节点都执行相同的命令序列,那么最终他们会得到一个一致的状态。也就是和说,为了保证整个分布式系统的一致性,我们需要保证每个节点执行相同的命令序列,也就是说每个节点的日志要保持一样。所以说,保证日志复制一致就是Raf等一致性算法的工作了
这里就涉及 Replicated State Machine(复制状态机),如上图所示。在一个节点上,一致性模块( Consensus Module,也就是分布式共识算法)接收到了来自客户端的命令。然后把接收到的命令写入到日志中,该节点和其他节点通过一致性模块进行通信确保每个日志最终包含相同的命令序列。一旦这些日志的命令被正确复制,每个节点的状态机( State Machine)都会按照相同的序列去执行他们,从而最终得到一致的状态。然后将达成共识的结果返回给客户端,如下图所示。
心跳（heartbeats）和超时机制（timeout） 在Ra算法中,有两个 timeout机制来控制领导人选举一个是选举定时器( elation timeou):
即 Follower等待成为 Candidate状态的等待时间,这个时间被随机设定为150ms-300ms之间
另一个是 headrbeat timeout:在某个节点成为 Leader以后,它会发送 Append Entries消息给其他节点,这些消息就是通过 heartbeat timeout来传送, Follower接收 …  </content></entry><entry><title>golang map实现原理</title><url>/post/go/golang_map_implementation_principle/</url><categories><category>go</category></categories><tags><tag>go</tag><tag>源码分析</tag></tags><content type="html">  这篇文章主要讲 map 的赋值、删除、查询、扩容的具体执行过程，仍然是从底层的角度展开。结合源码，看完本文一定会彻底明白 map 底层原理。
我要说明的是，这里对 map 的基本用法涉及比较少，我相信可以通过阅读其他入门书籍了解。本文的内容比较深入，但是由于我画了各种图，我相信很容易看懂。
什么是 map 维基百科里这样定义 map：
In computer science, an associative array, map, symbol table, or dictionary is an abstract data type composed of a collection of (key, value) pairs, such that each possible key appears at most once in the collection.
简单说明一下：在计算机科学里，被称为相关数组、map、符号表或者字典，是由一组 &amp;amp;lt;key, value&amp;amp;gt; 对组成的抽象数据结构，并且同一个 key 只会出现一次。
有两个关键点：map 是由 key-value 对组成的；key 只会出现一次。
和 map 相关的操作主要是：
增加一个 k-v 对 —— Add or insert； 删除一个 k-v 对 —— Remove or delete； 修改某个 k 对应的 v —— Reassign； 查询某个 k 对应的 v —— Lookup； 简单说就是最基本的 增删查改。
map 的设计也被称为 “The dictionary problem”，它的任务是设计一种数据结构用来维护一个集合的数据，并且可以同时对集合进行增删查改的操作。最主要的数据结构有两种：哈希查找表（Hash table）、搜索树（Search tree）。
哈希查找表用一个哈希函数将 key 分配到不同的桶（bucket，也就是数组的不同 index）。这样，开销主要在哈希函数的计算以及数组的常数访问时间。在很多场景下，哈希查找表的性能很高。
哈希查找表一般会存在“碰撞”的问题，就是说不同的 key 被哈希到了同一个 bucket。一般有两种应对方法：链表法和开放地址法。链表法将一个 bucket 实现成一个链表，落在同一个 bucket 中的 key 都会插入这个链表。开放 …  </content></entry><entry><title>分布式ID生成器及redis，etcd分布式锁</title><url>/post/microservice/distributed_id_generator_and_redis__etcd_distributed_lock/</url><categories><category>microservice</category></categories><tags><tag>redis</tag><tag>etcd</tag></tags><content type="html">  分布式id生成器 有时我们需要能够生成类似MySQL自增ID这样不断增大，同时又不会重复的id。以支持业务中的高并发场景。比较典型的，电商促销时，短时间内会有大量的订单涌入到系统，比如每秒10w+。明星出轨时，会有大量热情的粉丝发微博以表心意，同样会在短时间内产生大量的消息。
在插入数据库之前，我们需要给这些消息、订单先打上一个ID，然后再插入到我们的数据库。对这个id的要求是希望其中能带有一些时间信息，这样即使我们后端的系统对消息进行了分库分表，也能够以时间顺序对这些消息进行排序。
Twitter的snowflake算法是这种场景下的一个典型解法。先来看看snowflake是怎么一回事：
snowflake中的比特位分布
首先确定我们的数值是64位，int64类型，被划分为四部分，不含开头的第一个bit，因为这个bit是符号位。用41位来表示收到请求时的时间戳，单位为毫秒，然后五位来表示数据中心的id，然后再五位来表示机器的实例id，最后是12位的循环自增id（到达1111,1111,1111后会归0）。
这样的机制可以支持我们在同一台机器上，同一毫秒内产生2 ^ 12 = 4096条消息。一秒共409.6万条消息。从值域上来讲完全够用了。
数据中心加上实例id共有10位，可以支持我们每数据中心部署32台机器，所有数据中心共1024台实例。
表示timestamp的41位，可以支持我们使用69年。当然，我们的时间毫秒计数不会真的从1970年开始记，那样我们的系统跑到2039/9/7 23:47:35就不能用了，所以这里的timestamp实际上只是相对于某个时间的增量，比如我们的系统上线是2018-08-01，那么我们可以把这个timestamp当作是从2018-08-01 00:00:00.000的偏移量。
worker_id分配 timestamp，datacenter_id，worker_id和sequence_id这四个字段中，timestamp和sequence_id是由程序在运行期生成的。但datacenter_id和worker_id需要我们在部署阶段就能够获取得到，并且一旦程序启动之后，就是不可更改的了（想想，如果可以随意更改，可能被不慎修改，造成最终生成的id有冲突）。
一般不同数据中心的机器，会提供对应的获取数据中心id的API，所 …  </content></entry><entry><title>zap高性能日志</title><url>/post/go/zap_high_performance_log/</url><categories><category>go</category></categories><tags><tag>go</tag><tag>zap</tag></tags><content type="html">  摘要 日志在整个工程实践中的重要性不言而喻，在选择日志组件的时候也有多方面的考量。详细、正确和及时的反馈是必不可少的，但是整个性能表现是否也是必要考虑的点呢？在长期的实践中发现有的日志组件对于计算资源的消耗十分巨大，这将导致整个服务成本的居高不下。此文从设计原理深度分析了 zap 的设计与实现上的权衡，也希望整个的选择、考量的过程能给其他的技术团队在开发高性能的 Go 组件时带来一定的借鉴意义。
前言 日志作为整个代码行为的记录，是程序执行逻辑和异常最直接的反馈。对于整个系统来说，日志是至关重要的组成部分。通过分析日志我们不仅可以发现系统的问题，同时日志中也蕴含了大量有价值可以被挖掘的信息，因此合理地记录日志是十分必要的。
我们的业务通常会记录大量的 Debug 日志，但在实际测试过程中，发现我们使用的日志库 seelog 性能存在严重的瓶颈，在我们的对比结果中发现：zap 表现非常突出，单线程 Qps 也是 logrus、seelog 的数倍。
在分析源码后 zap 设计与实现上的考量让我感到受益颇多，在这里我们主要分享一下以下几个方面：
zap 为何有这么高的性能 对于我们自己的开发有什么值得借鉴的地方 如何正确的使用 Go 开发高性能的组件 为什么选择使用ZAP 它同时提供了结构化日志记录和printf风格的日志记录 它非常的快 根据Uber-go Zap的文档，它的性能比类似的结构化日志包更好——也比标准库更快。 以下是Zap发布的基准测试信息
记录一条消息和10个字段:
Package Time Time % to zap Objects Allocated ⚡️ zap 862 ns/op +0% 5 allocs/op ⚡️ zap (sugared) 1250 ns/op +45% 11 allocs/op zerolog 4021 ns/op +366% 76 allocs/op go-kit 4542 ns/op +427% 105 allocs/op apex/log 26785 ns/op +3007% 115 allocs/op logrus 29501 ns/op +3322% 125 allocs/op log15 29906 ns/op +3369% 122 allocs/op 记录一个静态字符串，没有任何上下文或printf风格的模 …  </content></entry><entry><title>golang channel原理</title><url>/post/go/golang_channel_principle/</url><categories><category>go</category></categories><tags><tag>go</tag><tag>源码分析</tag></tags><content type="html"><![CDATA[  channel介绍 channel一个类型管道，通过它可以在goroutine之间发送和接收消息。它是Golang在语言层面提供的goroutine间的通信方式。
众所周知，Go依赖于称为CSP（Communicating Sequential Processes）的并发模型，通过Channel实现这种同步模式。Go并发的核心哲学是不要通过共享内存进行通信; 相反，通过沟通分享记忆。
下面以简单的示例来演示Go如何通过channel来实现通信。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;time&amp;#34; ) func goRoutineA(a &amp;lt;-chan int) { val := &amp;lt;-a fmt.Println(&amp;#34;goRoutineA received the data&amp;#34;, val) } func goRoutineB(b chan int) { val := &amp;lt;-b fmt.Println(&amp;#34;goRoutineB received the data&amp;#34;, val) } func main() { ch := make(chan int, 3) go goRoutineA(ch) go goRoutineB(ch) ch &amp;lt;- 3 time.Sleep(time.Second * 1) } 结果为：goRoutineA received the data 3
上面只是个简单的例子，只输出goRoutineA ，没有执行goRoutineB，说明channel仅允许被一个goroutine读写。
go并发知识： 链接 说道channel这里不得不提通道的结构hchan。
hchan 源代码在src/runtime/chan.go
type hchan struct { qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element …  ]]></content></entry><entry><title>golang GC 垃圾回收机制</title><url>/post/go/golang_gc_garbage_collection_mechanism/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html">  垃圾回收(Garbage Collection，简称GC)是编程语言中提供的自动的内存管理机制，自动释放不需要的对象，让出存储器资源，无需程序员手动执行。
Golang中的垃圾回收主要应用三色标记法，GC过程和其他用户goroutine可并发运行，但需要一定时间的STW(stop the world)，STW的过程中，CPU不执行用户代码，全部用于垃圾回收，这个过程的影响很大，Golang进行了多次的迭代优化来解决这个问题。
Go V1.3之前的标记-清除(mark and sweep)算法 此算法主要有两个主要的步骤：
标记(Mark phase) 清除(Sweep phase) 第一步，暂停程序业务逻辑, 找出不可达的对象，然后做上标记。第二步，回收标记好的对象。
操作非常简单，但是有一点需要额外注意：mark and sweep算法在执行的时候，需要程序暂停！即 STW(stop the world)。也就是说，这段时间程序会卡在哪儿。
第二步, 开始标记，程序找出它所有可达的对象，并做上标记。如下图所示：
第三步, 标记完了之后，然后开始清除未标记的对象. 结果如下.
第四步, 停止暂停，让程序继续跑。然后循环重复这个过程，直到process程序生命周期结束。
标记-清扫(mark and sweep)的缺点 STW，stop the world；让程序暂停，程序出现卡顿 (重要问题)。 标记需要扫描整个heap 清除数据会产生heap碎片 所以Go V1.3版本之前就是以上来实施的, 流程是
Go V1.3 做了简单的优化,将STW提前, 减少STW暂停的时间范围.如下所示
这里面最重要的问题就是：mark-and-sweep 算法会暂停整个程序 。
Go是如何面对并这个问题的呢？接下来G V1.5版本 就用三色并发标记法来优化这个问题.
Go V1.5的三色并发标记法 三色标记法 实际上就是通过三个阶段的标记来确定清楚的对象都有哪些. 我们来看一下具体的过程.
第一步 , 就是只要是新创建的对象,默认的颜色都是标记为“白色”.
这里面需要注意的是, 所谓“程序”, 则是一些对象的跟节点集合.
所以上图,可以转换如下的方式来表示.
第二步, 每次GC回收开始, 然后从根节点开始遍历所有对象，把遍历到的对象从白色集合放入“灰色”集合。
第三步, 遍历灰色集 …  </content></entry><entry><title>viper配置管理</title><url>/post/go/viper_configuration_management/</url><categories><category>go</category></categories><tags><tag>go</tag><tag>viper</tag></tags><content type="html"><![CDATA[  安装 go get github.com/spf13/viper viper支持的功能 1、可以设置默认值 2、可以加载多种格式的配置文件，如JSON，TOML，YAML，HCL和Java属性配置文件 3、应用程序运行过程中，保持监听和重新读取配置文件 4、可以从环境变量读取配置 5、可以从远程配置系统读取配置 6、可以读取命令行标志作为配置 7、可以从缓冲区中读取 8、设置显式的值
在GitHub中，作者是这样描述viper对于开发人员的作用：在构建现代化应用程序的过程中，开发人员可以通过使用viper而不必考虑配置文件的格式问题。 viper具体的帮助 1、可以查找、加载和反序列化多种格式的配置文件，如JSON, TOML, YAML, HCL, Java属性配置格式。 2、提供一种为不同配置选项设置默认值的机制 3、提供一种通过命令行标志覆盖指定配置选项值的机制 4、提供了一种别名系统，可以在避免破坏现有代码的前提下，轻松地重命名参数 5、当用户提供的命令行或配置文件的配置选项与默认的配置选项相同时，可以很容易通过选项值结果看出优先级的差异。
viper提供的配置方式的优先级顺序如下(由高到低)： 1.设置显示调用(explicit call to Set) 2.命令行标志(flag) 3.环境变量(env) 4.配置文件(config) 5.远程键/值存储(key/value store) 6.默认值(default)
viper的简单使用 把值存入Viper 建立默认值 一个好的配置系统应该支持默认值。键不需要默认值，但如果没有通过配置文件、环境变量、远程配置或命令行标志（flag）设置键，则默认值非常有用。
例如：
viper.SetDefault(&amp;#34;ContentDir&amp;#34;, &amp;#34;content&amp;#34;) viper.SetDefault(&amp;#34;LayoutDir&amp;#34;, &amp;#34;layouts&amp;#34;) viper.SetDefault(&amp;#34;Taxonomies&amp;#34;, map[string]string{&amp;#34;tag&amp;#34;: &amp;#34;tags&amp;#34;, &amp;#34;category&amp;#34;: &amp;#34;categories&amp;#34;}) 读取配置文件 Viper需要最少知道在哪里查找配置文件的 …  ]]></content></entry><entry><title>docker</title><url>/post/cloud/docker/</url><categories><category>cloud</category></categories><tags><tag>docker</tag></tags><content type="html">  docker的定义 Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。 Docker 使用 Google 公司推出的 Go 语言 进行开发实现。 docker是linux容器的一种封装，提供简单易用的容器使用接口。它是最流行的Linux容器解决方案。 docker的接口相当简单，用户可以方便的创建、销毁容器。 docker将应用程序与程序的依赖，打包在一个文件里面。运行这个文件就会生成一个虚拟容器。 程序运行在虚拟容器里，如同在真实物理机上运行一样，有了docker，就不用担心环境问题了。
docker和虚拟机的区别 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱 系统支持量 单机支持上千个容器 一般几十个 虚拟机也可以制作模板，基于模板创建虚拟机，保证环境问题一致
虚拟机（virtual machine）就是带环境安装的一种解决方案。它可以在一种操作系统里面运行另一种操作系统，比如在 Windows 系统里面运行 Linux 系统。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。
虽然用户可以通过虚拟机还原软件的原始环境。但是，这个方案有几个缺点。
资源占用多冗余 步骤多 启动慢 用上docker容器后，可以实现开发、测试和生产环境的统一化和标准化。
镜像作为标准的交付件，可在开发、测试和生产环境上以容器来运行，最终实现三套环境上的应用以及运行所依赖内容的完全一致。
Linux容器不是模拟一个完整的操作系统，而是对进程进行隔离。在正常进程的外面套了一个保护层，对于容器里面进程来说，它接触的资源都是虚拟的，从而实现和底层系统的隔离。
启动快 资源占用少 体积小 docker容器的优势 更高效的利用系统资源 更快速的启动时间 持续交付和部署 更轻松的迁移 docker的三大概念 镜像 image Docker镜像就是一个只读的模板。 镜像可以用来创建Docker容器。 Docker提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下载 …  </content></entry><entry><title>golangHTML标签提取器soup</title><url>/post/go/golanghtml_tag_extractor_soup/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html">  什么是soup 类似python中beatifulsoup，用于提取html标签提取，多用于爬虫。它可以很好的处理不规范标记并生成剖析树(parse tree)。 它提供简单又常用的导航，搜索以及修改剖析树的操作。利用它我们不在需要编写正则表达式就可以方便的实现网页信息的提取。soup是一个小型的网页提取包，其接口与beauthoulsoup非常相似。
下载 go get github.com/anaskhan96/soup 接口 var Headers map[string]string 将头文件设置为键-值对的映射，这是单独调用Header()的替代方法 var Cookies map[string]string 将Cookie设置为键-值对的映射，这是单独调用Cookie()的另一种方法 func Get(string) (string,error) {} 将url作为参数，返回HTML字符串 func GetWithClient(string, *http.Client) {} 将url和自定义HTTP客户端作为参数，返回HTML字符串 func Post(string, string, interface{}) (string, error) {} 以url、bodyType和负载为参数，返回HTML字符串 func PostForm(string, url.Values) {} 接受url和正文。bodyType设置为“application/x-www-form-urlencoded func Header(string, string) {} 接受key，value对，将其设置为Get（）中的HTTP请求的头 func Cookie(string, string) {} 接受key，value对，将其设置为要与Get（）中的HTTP请求一起发送的Cookie func HTMLParse(string) Root {} 以HTML字符串为参数，返回一个指向构造的DOM的指针 func Find([]string) Root {} Element标记，（属性键值对）作为参数，返回指向第一个出现的指针 func FindAll([]string) []Root {} 与Find（）相同，但返回指向所有匹配项的指针 func …  </content></entry><entry><title>thrift的介绍及其使用</title><url>/post/microservice/introduction_and_use_of_thrift/</url><categories><category>microservice</category></categories><tags><tag>thrift</tag><tag>go</tag></tags><content type="html">  什么是thrift Thrift是Facebook于2007年开发的跨语言的rpc服框架，提供多语言的编译功能，并提供多种服务器工作模式；用户通过Thrift的IDL（接口定义语言）来描述接口函数及数据类型，然后通过Thrift的编译环境生成各种语言类型的接口文件，用户可以根据自己的需要采用不同的语言开发客户端代码和服务器端代码。
例如，我想开发一个快速计算的RPC服务，它主要通过接口函数getInt对外提供服务，这个RPC服务的getInt函数使用用户传入的参数，经过复杂的计算，计算出一个整形值返回给用户；服务器端使用java语言开发，而调用客户端可以是java、c、python等语言开发的程序，在这种应用场景下，我们只需要使用Thrift的IDL描述一下getInt函数（以.thrift为后缀的文件），然后使用Thrift的多语言编译功能，将这个IDL文件编译成C、java、python几种语言对应的“特定语言接口文件”（每种语言只需要一条简单的命令即可编译完成），这样拿到对应语言的“特定语言接口文件”之后，就可以开发客户端和服务器端的代码了，开发过程中只要接口不变，客户端和服务器端的开发可以独立的进行。
Thrift为服务器端程序提供了很多的工作模式，例如：线程池模型、非阻塞模型等等，可以根据自己的实际应用场景选择一种工作模式高效地对外提供服务；
Thrift的官方网站：http://thrift.apache.org/
thrift的协议结构 Thrift是一种c/s的架构体系。TServer主要任务是高效的接受客户端请求，并将请求转发给Processor处理。
最上层是用户自行实现的业务逻辑代码； Processor是由thrift编译器自动生成的代码，它封装了从输入数据流中读数据和向数据流中写数据的操作，它的主要工作是：从连接中读取数据，把处理交给用户实现impl，最后把结果写到连接上。 TProtocol是用于数据类型解析的，将结构化数据转化为字节流给TTransport进行传输。从TProtocol以下部分是thirft的传输协议和底层I/O通信。 TTransport是与底层数据传输密切相关的传输层，负责以字节流方式接收和发送消息体，不关注是什么数据类型。 底层IO负责实际的数据传输，包括socket、文件和压缩数据流等。 下载 下载thrift编 …  </content></entry><entry><title>grpc服务发现与负载均衡</title><url>/post/microservice/grpc_service_discovery_and_load_balancing/</url><categories><category>microservice</category></categories><tags><tag>grpc</tag><tag>go</tag></tags><content type="html">  前言 在后台服务开发中，高可用性是构建中核心且重要的一环。服务发现（Service discovery）和负载均衡（Load Balance）一直都是我关注的话题。今天来谈一下我在实际中是如何理解及落地的。
负载均衡 &amp;amp;amp;&amp;amp;amp; 服务发现 基础 负载均衡 ，顾名思义，是通过某种手段将流量 / 请求分配到不通的服务器上去，保证后台的每个服务收到的请求都尽可能保持平衡 服务发现 ，就是指客户端按照某种约定的方式主动去（注册中心）寻找服务，然后再连接相应的服务 关于负载均衡的构建与实现，可以看下这几篇文章：
gRPC 服务发现 &amp;amp;amp; 负载均衡 gRPC Load Balancing Load Balancing in gRPC 服务发现概念 我们说的服务发现，一般理解为客户端如何发现 (并连接到) 服务，这里一般包含三个组件：
服务消费者：一般指客户端（可以是简单的 TCP-Client 或者是 RPC-Client ） 服务提供者：一般指服务提供方，如传统服务，微服务等 服务注册中心：用来存储（Key-Value）服务提供者的服务，一般以 DNS/HTTP/RPC 等方式对外暴露接口 负载均衡概念 我们把 LB 看作一个组件，根据组件位置的不同，大致上分为三种：
集中式 LB（Proxy Model） 独立的 LB, 可以是硬件实现，如 F5，或者是 nginx 这种内置 Proxy-pass 或者 upstream 功能的网关，亦或是 LVS/HAPROXY，之前也使用 DPDK 开发过类似的专用网关。
进程内 LB（Balancing-aware Client） 进程内 LB（集成到客户端），此方案将 LB 的功能集成到服务消费方进程里，也被称为软负载或者客户端负载方案。服务提供方启动时，首先将服务地址注册到服务注册表，同时定期报心跳到服务注册表以表明服务的存活状态，相当于健康检查，服务消费方要访问某个服务时，它通过内置的 LB 组件向服务注册表查询，同时缓存并定期刷新目标服务地址列表，然后以某种负载均衡策略选择一个目标服务地址，最后向目标服务发起请求。LB 和服务发现能力被分散到每一个服务消费者的进程内部，同时服务消费方和服务提供方之间是直接调用，没有额外开销，性能比较好。
独立 LB 进程（External Load Balancing …  </content></entry><entry><title>grpc基础</title><url>/post/microservice/grpc_basics/</url><categories><category>microservice</category></categories><tags><tag>grpc</tag><tag>go</tag></tags><content type="html">  RPC 框架原理 RPC 框架的目标就是让远程服务调用更加简单、透明，RPC 框架负责屏蔽底层的传输方式（TCP 或者 UDP）、序列化方式（XML/Json/ 二进制）和通信细节。服务调用者可以像调用本地接口一样调用远程的服务提供者，而不需要关心底层通信细节和调用过程。
业界主流的 RPC 框架整体上分为三类：
支持多语言的 RPC 框架，比较成熟的有 Google 的 gRPC、facebook的Apache、Thrift； 只支持特定语言的 RPC 框架，例如新浪微博的 Motan； 支持服务治理等服务化特性的分布式服务框架，其底层内核仍然是 RPC 框架, 例如阿里的 Dubbo。 gRPC是什么 gRPC 是一个高性能、开源和通用的 RPC 框架，面向移动和 HTTP/2 设计。目前提供 C、Java 和 Go 语言版本，分别是：grpc, grpc-java, grpc-go. 其中 C 版本支持 C, C++, Node.js, Python, Ruby, Objective-C, PHP 和 C## 支持.
gRPC 基于 HTTP/2 标准设计，带来诸如双向流、流控、头部压缩、单 TCP 连接上的多复用请求等特。这些特性使得其在移动设备上表现更好，更省电和节省空间占用。
grc优点 多语言：语言中立，支持多种语言。 轻量级、高性能：序列化支持 PB(Protocol Buffer)和 JSON，PB 是一种语言无关的高性能序列化框架。 可插拔 IDL：基于文件定义服务，通过 proto3 工具生成指定语言的数据结构、服务端接口以及客户端 Stub。 移动端：基于标准的 HTTP2 设计，支持双向流、消息头压缩、单 TCP 的多路复用、服务端推送等特性，这些特性使得 gRPC 在移动端设备上更加省电和节省网络流量。 安全 HTTP2 规范当使用 TLS 时强制使用 TLS 1.2 及以上的版本，并且在部署上对允许的密码施加一些额外的限制以避免已知的比如需要 SNI 支持的问题。并且期待 HTTP2 与专有的传输安全机制相结合，这些传输机制的规格说明不能提供有意义的建议。
gRPC使用 使用gRPC， 我们可以一次性的在一个.proto文件中定义服务并使用任何支持它的语言去实现客户端和服务端，反过来，它们可以应用在各种场景中，从Google的服务器到你 …  </content></entry><entry><title>SQL查询语句执行流程</title><url>/post/database/sql_query_statement_execution_process/</url><categories><category>database</category></categories><tags><tag>mysql</tag></tags><content type="html">  msyql执行流程 你有个最简单的表，表里只有一个 ID 字段，在执行下面这个查询语句时：：
select * from T where ID=10； 我们看到的只是输入一条语句，返回一个结果，却不知道这条语句在 MySQL 内部的执行过程。
下面我给出的是 MySQL 的基本架构示意图，从中你可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。
大体上，MySQL 分为 Server 层和存储引擎层两部分。
Server 层包括连接器、查询缓存、分析器、执行器等，以及所有的内置函数（如日期、时间、数学和加密函数等）和跨存储引擎的功能（如存储过程、触发器、视图）。
存储引擎层负责数据的存储和提取，支持 InnoDB、MyISAM、Memory 等多个存储引擎。MySQL 5.5.5 版本后默认存储存储引擎是 InnoDB。
连接器 验证账号密码是否正确 到权限表里面查出你拥有的权限，之后的执行语句，都会依赖这个权限数据。 查询缓存 在建立连接后，就开始执行 select 语句了，执行前首先会查询缓存。
MySQL 拿到查询请求后，会先查询缓存，看是不是执行过这条语句。执行过的语句及其结果会以 key-value 对的形式保存在一定的内存区域中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个value 就会被直接返回给客户端。
如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，会提升效率。
但是查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。对于更新压力大的数据库来说，查询缓存的命中率会非常低。如果业务中需要有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。MySQL 提供了这种按需使用的方式。可以将参数 query_cache_type 设置成 DEMAND，对于默认的 SQL 语句都将不使用查询缓存。
MySQL 8.0 版本将查询缓存的功能删除了。
分析器 如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。
分析器先会做“词法分析”。你 …  </content></entry><entry><title>golang jwt</title><url>/post/go/golang_jwt/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  什么是JWT？ JWT全称JSON Web Token是一种跨域认证解决方案，属于一个开放的标准，它规定了一种Token实现方式，目前多用于前后端分离项目和OAuth2.0业务场景下。
JWT作用？ JWT就是一种基于Token的轻量级认证模式，服务端认证通过后，会生成一个JSON对象，经过签名后得到一个Token（令牌）再发回给用户，用户后续请求只需要带上这个Token，服务端解密之后就能获取该用户的相关信息了。
下载jwt go get -u github.com/golang-jwt/jwt 生成JWT和解析JWT 我们在这里直接使用jwt-go这个库来实现我们生成JWT和解析JWT的功能。
定义需求
我们需要定制自己的需求来决定JWT中保存哪些数据
type MyClaims struct { UserID uint64 `json:&#34;user_id&#34;` Username string `json:&#34;username&#34;` jwt.StandardClaims } 定义JWT的过期时间和Secret(盐)：
const TokenExpireDuration = time.Hour * 24 * 2 // 过期时间 -2天 var Secret = []byte(&#34;i am zhaohaiyu&#34;) // Secret(盐) 用来加密解密 生成JWT //生成 jwt token func genToken(userID uint64, username string) (string, error) { var claims = MyClaims{ userID, username, jwt.StandardClaims{ ExpiresAt: time.Now().Add(TokenExpireDuration).Unix(), // 过期时间 Issuer: &#34;zhaohaiyu&#34;, // 签发人 }, } token := jwt.NewWithClaims(jwt.SigningMethodHS256, claims) signedToken, err := token.SignedString([]byte(Secret)) if err != nil { return &#34;&#34;, fmt.Errorf(&#34;生成token失败:%v&#34;, err) } return signedToken, nil } 解析JWT //验证jwt token func ParseToken(tokenStr string) (*MyClaims, error) { token, err := jwt.ParseWithClaims(tokenStr, &amp;MyClaims{}, func(token *jwt.Token) (i interface{}, err error) { // 解析token return Secret, nil }) if err != nil { return nil, err } if claims, ok := token.Claims.(*MyClaims); ok &amp;&amp; token.Valid { // 校验token return claims, nil } return nil, errors.New(&#34;invalid token&#34;) } 在gin框架中使用JWT r.POST(&#34;/auth/token&#34;, GetTokenHandler) 登录生成token func GetTokenHandler(c *gin.Context) { // 接收参数 var user UserInfo err := c.ShouldBind(&amp;user) if err != nil { c.JSON(http.StatusOK, gin.H{ &#34;code&#34;: 1001, &#34;err_info&#34;: &#34;参数错误&#34;, }) return } // 验证密码 if user.Username == &#34;root&#34; &amp;&amp; user.Password == &#34;123&#34; { // 生成Token tokenString, err := GenToken(user.Username) if err != nil { c.JSON(http.StatusOK, gin.H{ &#34;code&#34;: 1001, &#34;err_info&#34;: &#34;生成token错误&#34;, }) return } c.JSON(http.StatusOK, gin.H{ &#34;code&#34;: 2000, &#34;msg&#34;: &#34;success&#34;, &#34;data&#34;: gin.H{&#34;token&#34;: tokenString}, }) return } else { c.JSON(http.StatusOK, gin.H{ &#34;code&#34;: 2002, &#34;msg&#34;: &#34;用户名或密码错误&#34;, }) return } return } jwt中间件验证 // JWThMiddleware 中间件 func JWThMiddleware() func(c *gin.Context) { return func(c *gin.Context) { // 客户端携带Token有三种方式 1.放在请求头 2.放在请求体 3.放在URI // 这里假设Token放在Header的token中 token := c.Request.Header.Get(&#34;token&#34;) if token == &#34;&#34; { // 处理 没有token的时候 c.Abort() // 不会继续停止 return } // 解析 mc, err := ParseToken(token) if err != nil { // 处理 解析失败 c.Abort() return } // 将当前请求的userID信息保存到请求的上下文c上 c.Set(&#34;userID&#34;, mc.UserID) c.Next() } }   ]]></content></entry><entry><title>mysql索引</title><url>/post/database/mysql_index/</url><categories><category>database</category></categories><tags><tag>mysql</tag></tags><content type="html">  什么是索引 一般的应用系统，都是读多写少。而且插入操作和一般的更新操作很少出现性能问题（因为有redo log锁cache缓存）。在生产环境中，我们遇到最多的，也是最容易出问题的，还是一些复杂的查询操作，因此对查询语句的优化显然是重中之重。说起加速查询，就不得不提到索引了。索引的核心思想就是加速查询。
索引的原理 索引原理 索引的目的在于提高查询效率，可以类比字典，如果要查“mysql”这个单词，我们肯定需要定位到m字母，然后从下往下找到y字母，再找到剩下的sql。如果没有索引，那么你可能需要把所有单词看一遍才能找到你想要的，如果我想找到m开头的单词呢？或者ze开头的单词呢？是不是觉得如果没有索引，这个事情根本无法完成？
本质都是：通过不断地缩小想要获取数据的范围来筛选出最终想要的结果，同时把随机的事件变成顺序的事件，也就是说，有了这种索引机制，我们可以总是用同一种查找方式来锁定数据。
数据库也是一样，但显然要复杂许多，因为不仅面临着等值查询，还有范围查询(&amp;amp;gt;、&amp;amp;lt;、between、in)、模糊查询(like)、并集查询(or)等等。数据库应该选择怎么样的方式来应对所有的问题呢？我们回想字典的例子，能不能把数据分成段，然后分段查询呢？最简单的如果1000条数据，1到100分成第一段，101到200分成第二段，201到300分成第三段……这样查第250条数据，只要找第三段就可以了，一下子去除了90%的无效数据。但如果是1千万的记录呢，分成几段比较好？稍有算法基础的同学会想到搜索树，其平均复杂度是lgN，具有不错的查询性能。但这里我们忽略了一个关键的问题，复杂度模型是基于每次相同的操作成本来考虑的，数据库实现比较复杂，数据保存在磁盘上，而为了提高性能，每次又可以把部分数据读入内存来计算，因为我们知道访问磁盘的成本大概是访问内存的十万倍左右，所以简单的搜索树难以满足复杂的应用场景。
磁盘IO与预读 考虑到磁盘IO是非常高昂的操作，计算机操作系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，因为局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际 …  </content></entry><entry><title>mysql事务</title><url>/post/database/mysql_transaction/</url><categories><category>database</category></categories><tags><tag>mysql</tag><tag>事务</tag></tags><content type="html">  事务是什么 事务就是指逻辑上的一组SQL语句操作，组成这组操作的各个SQL语句，执行时要么全成功要么全失败。
在 MySQL 中，事务支持是在引擎层实现的。MySQL 是一个支持多引擎的系统，但并不是所有的引擎都支持事务。
比如 MySQL 原生的 MyISAM 引擎就不支持事务，这也是 MyISAM 被 InnoDB 取代的重要原因之一
事务的四大特性 原子性(Atomicity) 事务是一个不可分割的单位，事务中的所有SQL等操作要么都发生，要么都不发生。 一致性(Consistency) 事务发生前和发生后，数据的完整性必须保持一致。 隔离性(Isolation) 当并发访问数据库时，一个正在执行的事务在执行完毕前，对于其他的会话是不可见的，多个并发事务之间的数据是相互隔离的。也就是其他人的操作在这个事务的执行过程中是看不到这个事务的执行结果的，也就是他们拿到的是这个事务执行之前的内容，等这个事务执行完才能拿到新的数据。 持久性(Durability) 一个事务一旦被提交，它对数据库中的数据改变就是永久性的。如果出了错误，事务也不允撤销，只能通过&amp;amp;rsquo;补偿性事务&amp;amp;rsquo;。 事务的开启 开启:
begin/start transaction 执行第一个语句是开启事务
start transaction with consistent snapshot 直接开启事务
隐性事务：set autocommit=0，这个命令会将这个线程的自动提交关掉。
意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。
有些客户端连接框架会默认连接成功后先执行一个 set autocommit=0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。
提交:commit
回滚:rollback
在事务中混合使用存储引擎 MySQL服务器层不管理事务，事务是由下层的存储引擎实现的。所以在同一个事务中，使用多种存储引擎是不可靠的。
如果在事务中混合使用了事务型和非事务型的表（例如innodb和myisam表），在正常提交的情况下不会有什么问题。
但如果该事务需要回滚，非事务型的表上的变更就无法撤销，这会导致数据库处于不一致的状态，这种 …  </content></entry><entry><title>mysql 锁</title><url>/post/database/mysql_lock/</url><categories><category>database</category></categories><tags><tag>mysql</tag></tags><content type="html">  MySQL中的锁 数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。
根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类
全局锁 全局锁就是对整个数据库实例加锁。
MySQL提供了一个加全局读锁的方法，命令是Flush tables with read lock。当需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句
全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都select出来存成文本
但是让整个库都只读，可能出现以下问题：
如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆 如果在从库上备份，那么在备份期间从库不能执行主库同步过来的binlog，会导致主从延迟 在可重复读隔离级别下开启一个事务能够拿到一致性视图
官方自带的逻辑备份工具是mysqldump。当mysqldump使用参数–single-transaction的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。single-transaction只适用于所有的表使用事务引擎的库
既然要全库只读，为什么不使用set global readonly=true的方式？
在有些系统中，readonly的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此修改global变量的方式影响面更大 在异常处理机制上有差异。如果执行Flush tables with read lock命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高
表级锁 MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。
表锁的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户 …  </content></entry><entry><title>msyql redo log和binlog</title><url>/post/database/msyql_redo_log_and_binlog/</url><categories><category>database</category></categories><tags><tag>mysql</tag></tags><content type="html">  更新语句执行流程 下面是这个表的创建语句，这个表有一个主键 ID 和一个整型字段 c：
create table T(ID int primary key, c int); 如果要将 ID=2 这一行的值加 1，SQL 语句就会这么写：
update T set c=c+1 where ID=2; 前面我有跟你介绍过 SQL 语句基本的执行链路，这里我再把那张图拿过来，你也可以先简单看看这个图回顾下。首先，可以确定的说，查询语句的那一套流程，更新语句也是同样会走一遍。
通过连接器，客户端与 MySQL 建立连接 update 语句会把 T 表上的所有查询缓存结果清空 分析器会通过词法分析和语法分析识别这是一条更新语句 优化器会决定使用 ID 这个索引（聚簇索引） 执行器负责具体执行，找到匹配的一行，然后更新 更新过程中还会涉及 redo log（重做日志）和 binlog（归档日志）的操作 其中，这两种日志默认在数据库的 data 目录下，redo log 是 ib_logfile0 格式的，binlog 是 xxx-bin.000001 格式的。
接下来让我们分别去研究下日志模块中的 redo log 和 binlog。
日志模块：redo log 在 MySQL 中，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就采用了日志（redo log）来提升更新效率。
而日志和磁盘配合的整个过程，其实就是 MySQL 里的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。
具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（redolog buffer）里面，并更新内存（buffer pool），这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候（如系统空闲时），将这个操作记录更新到磁盘里面（刷脏页）。
redo log 是 InnoDB 存储引擎层的日志，又称重做日志文件，redo log 是循环写的，redo log 不是记录数据页更新之后的状态，而是记录这个页做了什么改动。
redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的 …  </content></entry><entry><title>MySQL基础数据类型</title><url>/post/database/mysql_basic_data_types/</url><categories><category>database</category></categories><tags><tag>mysql</tag></tags><content type="html">  数值类型 MySQL支持所有标准SQL数值数据类型。
这些类型包括严格数值数据类型(INTEGER、SMALLINT、DECIMAL和NUMERIC)，以及近似数值数据类型(FLOAT、REAL和DOUBLE PRECISION)。
关键字INT是INTEGER的同义词，关键字DEC是DECIMAL的同义词。
BIT数据类型保存位字段值，并且支持MyISAM、MEMORY、InnoDB和BDB表。
作为SQL标准的扩展，MySQL也支持整数类型TINYINT、MEDIUMINT和BIGINT。下面的表显示了需要的每个整数类型的存储和范围。
类型 大小 范围（有符号） 范围（无符号） 用途 TINYINT 1 字节 (-128，127) (0，255) 小整数值 SMALLINT 2 字节 (-32 768，32 767) (0，65 535) 大整数值 MEDIUMINT 3 字节 (-8 388 608，8 388 607) (0，16 777 215) 大整数值 INT或INTEGER 4 字节 (-2 147 483 648，2 147 483 647) (0，4 294 967 295) 大整数值 BIGINT 8 字节 (-9 233 372 036 854 775 808，9 223 372 036 854 775 807) (0，18 446 744 073 709 551 615) 极大整数值 FLOAT 4 字节 (-3.402 823 466 E+38，-1.175 494 351 E-38)，0，(1.175 494 351 E-38，3.402 823 466 351 E+38) 0，(1.175 494 351 E-38，3.402 823 466 E+38) 单精度 浮点数值 DOUBLE 8 字节 (-1.797 693 134 862 315 7 E+308，-2.225 073 858 507 201 4 E-308)，0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 0，(2.225 073 858 507 201 4 E-308，1.797 693 134 862 315 7 E+308) 双精度 浮点数值 DECIMAL 对DECIMAL(M,D) …  </content></entry><entry><title>MySQL数据完整性约束</title><url>/post/database/mysql_data_integrity_constraints/</url><categories><category>database</category></categories><tags><tag>mysql</tag></tags><content type="html">  主键约束 主键可以是表中的某一列，也可以是表中的多个列所构成的一个组合；其中，由多个列组合而成的主键也称为复合主键。在MySQL中，主键列必须遵守以下规则。
（1）每一个表只能定义一个主键。
（2）唯一性原则。主键的值，也称键值，必须能够唯一表示表中的每一条记录，且不能为NULL。
（3）最小化规则。复合主键不能包含不必要的多余列。也就是说，当从一个复合主键中删除一列后，如果剩下的列构成的主键仍能满足唯一性原则，那么这个复合主键是不正确的。
（4）一个列名在复合主键的列表中只能出现一次。
示例：创建学生信息表tb_student时，将学号（stu_id）字段设置为主键。
CREATE TABLE tb_student ( stu_id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(30) ); 示例：创建用户信息表tb_student时，将学号（stu_id）和所在班级号（class_id）字段设置为复合主键。
CREATE TABLE tb_student ( stu_id INT AUTO_INCREMENT, name VARCHAR(30), class_id INT NOT NULL, PRIMARY KEY (stu_id,class_id) ); 示例：通过修改数据表结构，添加主键约束。
ALTER TABLE tb_student ADD CONSTRAINT PRIMARY KEY(stu_id); 唯一约束 唯一约束使用UNIQUE关键字来定义。唯一约束的值必须是唯一的，且不能为空（NULL）。
在MySQL中，唯一约束与主键之间存在以下两点区别。
（1）一个表只能创建一个主键，但可以定义多个唯一约束。
（2）定义主键约束时，系统会自动创建PRIMARY KEY索引，而定义候选键约束时，系统会自动创建UNIQUE索引。
示例：创建用户信息表tb_student时，将学号（stu_id）和姓名（name）设置为唯一约束。
CREATE TABLE tb_student ( stu_id INT UNIQUE, name VARCHAR(30) UNIQUE ); 示例：创建用户信息表tb_student时，将学号（stu_id）和姓名（name）字段设置为复合唯一约束。
CREATE TABLE …  </content></entry><entry><title>golang web源码解析</title><url>/post/go/golang_web_source_code_analysis/</url><categories><category>go</category></categories><tags><tag>go</tag><tag>源码分析</tag></tags><content type="html"><![CDATA[  Go的web工作原理 在Go中使用及其简单的代码即可开启一个web服务。如下：
//开启web服务 func test(){ http.HandleFunc(&amp;#34;/&amp;#34;, sayHello) err := http.ListenAndServe(&amp;#34;:9090&amp;#34;,nil) if err!=nil { log.Fatal(&amp;#34;ListenAndServer:&amp;#34;,err) } } func sayHello(w http.ResponseWriter, r *http.Request){ r.ParseForm() fmt.Println(&amp;#34;path&amp;#34;,r.URL.Path) fmt.Println(&amp;#34;scheme&amp;#34;,r.URL.Scheme) fmt.Fprintf(w, &amp;#34;Hello Guest!&amp;#34;) } 在使用ListenAndServe这个方法时，系统就会给我们指派一个路由器，DefaultServeMux是系统默认使用的路由器，如果ListenAndServe这个方法的第2个参数传入nil，系统就会默认使用DefaultServeMux。当然，这里也可以传入自定义的路由器。
先来看http.HandleFunc(&amp;quot;/&amp;quot;, sayHello)，从HandleFunc方法点进去，如下：
func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(pattern, handler) } 在这里调用了DefaultServeMux的HandleFunc方法，这个方法有两个参数，pattern是匹配的路由规则，handler表示这个路由规则对应的处理方法，并且这个处理方法有两个参数。
在我们书写的代码示例中，pattern对应/，handler对应sayHello，当我们在浏览器中输入http://localhost:9090时，就会触发sayHello方法。
我们再顺着DefaultServeMux的HandleFunc方法继续点下去，如下：
func (mux *ServeMux) HandleFunc(pattern …  ]]></content></entry><entry><title>redis持久化</title><url>/post/database/redis_persistence/</url><categories><category>database</category></categories><tags><tag>redis</tag></tags><content type="html">  Redis是一种内存型数据库，一旦服务器进程退出，数据库的数据就会丢失，为了解决这个问题，Redis提供了两种持久化的方案，将内存中的数据保存到磁盘中，避免数据的丢失。
RDB持久化 redis提供了RDB持久化的功能，这个功能可以将redis在内存中的的状态保存到硬盘中，它可以手动执行。
也可以再redis.conf中配置，定期执行。
RDB持久化产生的RDB文件是一个经过压缩的二进制文件，这个文件被保存在硬盘中，redis可以通过这个文件还原数据库当时的状态。
内存数据保存到磁盘
在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）
优点：速度快，适合做备份，主从复制就是基于RDB持久化功能实现
rdb通过再redis中使用save命令触发 rdb
rdb配置参数： dir /data/6379/ dbfilename dbmp.rdb 每过900秒 有1个操作就进行持久化 save 900秒 1个修改类的操作 save 300秒 10个操作 save 60秒 10000个操作 save 900 1 save 300 10 save 60 10000 redis持久化之RDB实践 1.启动redis服务端,准备配置文件
daemonize yes port 6379 logfile /data/6379/redis.log dir /data/6379 #定义持久化文件存储位置 dbfilename dbmp.rdb #rdb持久化文件 bind 10.0.0.10 127.0.0.1 #redis绑定地址 requirepass redhat #redis登录密码 save 900 1 #rdb机制 每900秒 有1个修改记录 save 300 10 #每300秒 10个修改记录 save 60 10000 #每60秒内 10000修改记录 2.启动redis服务端
3.登录redis设置一个key
redis-cli -a redhat 4.此时检查目录，/data/6379底下没有dbmp.rdb文件
5.通过save触发持久化，将数据写入RDB文件
127.0.0.1:6379&amp;amp;gt; set age 18 OK 127.0.0.1:6379&amp;amp;gt; save OK AOF持久化 AOF（append-only log …  </content></entry><entry><title>redis基础</title><url>/post/database/redis_basics/</url><categories><category>database</category></categories><tags><tag>redis</tag></tags><content type="html"><![CDATA[  redis介绍 Redis 是完全开源的，遵守 BSD 协议，是一个高性能的 key-value 数据库。
Redis 与其他 key - value 缓存产品有以下三个特点：
Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 redis的安装 brew install redis(mac) yum install redis(centos) apt-get install redis(ubuntu) redis的命令网站 Redis 命令参考 — Redis 命令参考 (redisfans.com) redis的基本操作 redis的五大数据类型 redis的五大数据类型是: String(字符串)、Hash(哈希)、List(列表)、Set(集合)、和zset(sorted set:有序集合)
redis键操作 keys *查看当前库所有key (匹配：keys *1) exists key判断某个key是否存在 type key 查看你的key是什么类型 del key 删除指定的key数据 unlink key 根据value选择非阻塞删除 仅将keys从keyspace元数据中删除，真正的删除会在后续异步操作。 expire key 10 10秒钟：为给定的key设置过期时间 ttl key 查看还有多少秒过期，-1表示永不过期，-2表示已过期 select命令切换数据库 dbsize查看当前数据库的key的数量 flushdb清空当前库 flushall通杀全部库 字符串(String) 简介 String是Redis最基本的类型，你可以理解成与Memcached一模一样的类型，一个key对应一个value。
String类型是二进制安全的。意味着Redis的string可以包含任何数据。比如jpg图片或者序列化的对象。
String类型是Redis最基本的数据类型，一个Redis中字符串value最多可以是512M
常用命令 set &amp;lt;key&amp;gt;&amp;lt;value&amp;gt;添加键值对 get …  ]]></content></entry><entry><title>nginx简介,使用</title><url>/post/cloud/introduction_to_nginx__usage/</url><categories><category>cloud</category></categories><tags><tag>nginx</tag><tag>linux</tag></tags><content type="html">  nginx是什么 nginx是一个开源的，支持高性能，高并发的www服务和代理服务软件。
支持高并发，能支持几万并发连接
资源消耗少，在3万并发连接下开启10个nginx线程消耗的内存不到200M
可以做http反向代理和负载均衡
支持异步网络i/o事件模型epoll
Tengine是由淘宝网发起的Web服务器项目。它在Nginx的基础上，针对大访问量网站的需求，添加了很多高级功能和特性。T目标是打造一个高效、稳定、安全、易用的Web平台。
安装环境依赖包 yum install gcc-c++ pcre pcre-devel zlib zlib-devel gcc patch libffi-devel python-devel zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel openssl openssl-devel -y 安装并启动nginx 下载源码包 http://tengine.taobao.org/download/tengine-2.3.3.tar.gz
解压缩源码 tar -zxvf tengine-2.3.3.tar.gz配置
编译安装 开启nginx状态监测功能
./configure make &amp;amp;amp;&amp;amp;amp; make install nginx操作，进入nginx下的sbin目录（默认在/usr/local下）
启动./nginx -c指定配置文件 关闭./nginx -s stop 重新加载./nginx -s reload 检查配置文件 ./nginx -t 部署一个web站点 nginx默认站点是Nginx目录下的html文件夹，这里可以从nginx.conf中查到
location / { root html; # 这里是默认的站点html文件夹，也就是 /usr/local/nginx/html 文件夹下的内容 index index.html index.htm; # 站点首页文件名是index.html } 如果要部署网站业务数据，只需要把开发好的程序全放到html …  </content></entry><entry><title>golang sqlx</title><url>/post/go/golang_sqlx/</url><categories><category>go</category></categories><tags><tag>golang</tag><tag>sqlx</tag></tags><content type="html"><![CDATA[  在项目中我们通常可能会使用database/sql连接MySQL数据库。本文借助使用sqlx实现批量插入数据的例子，介绍了sqlx中可能被你忽视了的sqlx.In和DB.NamedExec方法。
sqlx介绍 在项目中我们通常可能会使用database/sql连接MySQL数据库。sqlx可以认为是Go语言内置database/sql的超集，它在优秀的内置database/sql基础上提供了一组扩展。这些扩展中除了大家常用来查询的Get(dest interface{}, ...) error和Select(dest interface{}, ...) error外还有很多其他强大的功能。
安装sqlx go get github.com/jmoiron/sqlx 基本使用 连接数据库 var db *sqlx.DB func initDB() (err error) { dsn := &amp;#34;user:password@tcp(127.0.0.1:3306)/sql_test?charset=utf8mb4&amp;amp;parseTime=True&amp;#34; // 也可以使用MustConnect连接不成功就panic db, err = sqlx.Connect(&amp;#34;mysql&amp;#34;, dsn) if err != nil { fmt.Printf(&amp;#34;connect DB failed, err:%v\n&amp;#34;, err) return } db.SetMaxOpenConns(20) db.SetMaxIdleConns(10) return } 查询 查询单行数据示例代码如下：
// 查询单条数据示例 func queryRowDemo() { sqlStr := &amp;#34;select id, name, age from user where id=?&amp;#34; var u user err := db.Get(&amp;amp;u, sqlStr, 1) if err != nil { fmt.Printf(&amp;#34;get failed, err:%v\n&amp;#34;, err) return } fmt.Printf(&amp;#34;id:%d name:%s age:%d\n&amp;#34;, u.ID, u.Name, u.Age) } 查询多行 …  ]]></content></entry><entry><title>golang redis</title><url>/post/go/golang_redis/</url><categories><category>go</category></categories><tags><tag>golang</tag><tag>redis</tag></tags><content type="html"><![CDATA[  安装 下载第三方包:
go get -u github.com/go-redis/redis/v9 连接 // 定义一个rdis客户端 var redisdb *redis.Client // 初始化 func initClient() (err error) { redisdb = redis.NewClient(&amp;redis.Options{ Addr: &#34;localhost:6379&#34;, // post端口 Password: &#34;&#34;, // 密码 DB: 0, // 使用redis的库 }) _, err = redisdb.Ping(context.Background()).Result() if err != nil { fmt.Println(&#34;连接失败&#34;) return } return } 使用 set/get示例 func redisExample() { ctx := context.Background() err := redisdb.Set(ctx, &#34;score&#34;, 100, 0).Err() if err != nil { fmt.Printf(&#34;set score failed, err:%v\n&#34;, err) return } val, err := redisdb.Get(ctx, &#34;score&#34;).Result() if err != nil { fmt.Printf(&#34;get score failed, err:%v\n&#34;, err) return } fmt.Println(&#34;score&#34;, val) val2, err := redisdb.Get(ctx, &#34;name&#34;).Result() if err == redis.Nil { fmt.Println(&#34;name does not exist&#34;) } else if err != nil { fmt.Printf(&#34;get name failed, err:%v\n&#34;, err) return } else { fmt.Println(&#34;name&#34;, val2) } } zset示例 func redisExample2() { ctx := context.Background() zsetKey := &#34;language_rank&#34; languages := []*redis.Z{ &amp;redis.Z{Score: 90.0, Member: &#34;Golang&#34;}, &amp;redis.Z{Score: 98.0, Member: &#34;Java&#34;}, &amp;redis.Z{Score: 95.0, Member: &#34;Python&#34;}, &amp;redis.Z{Score: 97.0, Member: &#34;JavaScript&#34;}, &amp;redis.Z{Score: 99.0, Member: &#34;C/C++&#34;}, } // ZADD num, err := redisdb.ZAdd(ctx, zsetKey, languages...).Result() if err != nil { fmt.Printf(&#34;zadd failed, err:%v\n&#34;, err) return } fmt.Printf(&#34;zadd %d succ.\n&#34;, num) // 把Golang的分数加10 newScore, err := redisdb.ZIncrBy(ctx, zsetKey, 10.0, &#34;Golang&#34;).Result() if err != nil { fmt.Printf(&#34;zincrby failed, err:%v\n&#34;, err) return } fmt.Printf(&#34;Golang&#39;s score is %f now.\n&#34;, newScore) // 取分数最高的3个 ret, err := redisdb.ZRevRangeWithScores(ctx, zsetKey, 0, 2).Result() if err != nil { fmt.Printf(&#34;zrevrange failed, err:%v\n&#34;, err) return } for _, z := range ret { fmt.Println(z.Member, z.Score) } // 取95~100分的 op := &amp;redis.ZRangeBy{ Min: &#34;95&#34;, Max: &#34;100&#34;, } ret, err = redisdb.ZRangeByScoreWithScores(ctx, zsetKey, op).Result() if err != nil { fmt.Printf(&#34;zrangebyscore failed, err:%v\n&#34;, err) return } for _, z := range ret { fmt.Println(z.Member, z.Score) } } 输出结果如下：
$ ./06redis_demo zadd 0 succ. Golang&#39;s score is 100.000000 now. Golang 100 C/C++ 99 Java 98 JavaScript 97 Java 98 C/C++ 99 Golang 100   ]]></content></entry><entry><title>golang nethttp包</title><url>/post/go/golang_nethttp_package/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  http协议 超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络传输协议，所有的WWW文件都必须遵守这个标准。设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。
关于http(https)协议: https://www.cnblogs.com/yuemoxi/p/15162601.html http包中重要的类型和接口 server：HTTP服务器，定义监听的地址、端口，处理器等信息。 conn：用户每次请求的链接。 response：返回给用户的信息。 request：用户请求的信息。 Handler: 处理器，用户请求到来时，服务器的处理逻辑，它是一个包含ServeHTTP方法的接口。 http包的运行流程 http包如何实现高并发 http包中，server每接收一个用户请求，都会生成一个conn链接，并生成一个goroutines来处理对应的conn。所以每个请求都是独立的，相互不阻塞的。
c := srv.newConn(rw) c.setState(c.rwc, StateNew) go c.serve(ctx) 处理器(Handler)和多路复用器(ServeMux) func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { handler := sh.srv.Handler if handler == nil { handler = DefaultServeMux } if req.RequestURI == &amp;#34;*&amp;#34; &amp;amp;&amp;amp; req.Method == &amp;#34;OPTIONS&amp;#34; { handler = globalOptionsHandler{} } handler.ServeHTTP(rw, req) } 所以当我们的处理器为空时，http包会默认帮我们生成一个DefaultServeMux处理器。 不是说第二个参数是处理器吗，但是DefaultServeMux是一个ServeMux结构的实例, 是一个多路复用器。这是怎么回事？ 其实处理器是一个拥有ServeHTTP方法的接口，只要实现了这个方法，它就是一个处理器。所以DefaultServeMux不 …  ]]></content></entry><entry><title>nethttp和gin 路由</title><url>/post/go/nethttp_and_gin_routing/</url><categories><category>go</category></categories><tags><tag>go</tag><tag>gin</tag></tags><content type="html"><![CDATA[  net/http 路由注册 func test1() { http.HandleFunc(&amp;#34;/&amp;#34;, func(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, &amp;#34;Hello world!&amp;#34;) }) err := http.ListenAndServe(&amp;#34;:9001&amp;#34;, nil) if err != nil { log.Fatal(&amp;#34;ListenAndServer:&amp;#34;, err) } } 在使用ListenAndServe这个方法时，系统就会给我们指派一个路由器，DefaultServeMux是系统默认使用的路由器，如果ListenAndServe这个方法的第2个参数传入nil，系统就会默认使用DefaultServeMux。当然，这里也可以传入自定义的路由器。
先看http.HandleFunc(&amp;quot;/&amp;quot;, ...)，从HandleFunc方法点进去，如下：
func HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { DefaultServeMux.HandleFunc(pattern, handler) } 在这里调用了DefaultServeMux的HandleFunc方法，这个方法有两个参数，pattern是匹配的路由规则，handler表示这个路由规则对应的处理方法，并且这个处理方法有两个参数。
在我们书写的代码示例中，pattern对应/，handler对应sayHello，当我们在浏览器中输入http://localhost:9001时，就会触发匿名函数。
我们再顺着DefaultServeMux的HandleFunc方法继续点下去，如下：
func (mux *ServeMux) HandleFunc(pattern string, handler func(ResponseWriter, *Request)) { if handler == nil { panic(&amp;#34;http: nil handler&amp;#34;) } mux.Handle(pattern, HandlerFunc(handler)) } 在这个方 …  ]]></content></entry><entry><title>网络编程</title><url>/post/network/network_programming/</url><categories><category>network</category></categories><tags><tag>network</tag></tags><content type="html">  网络层次划分 为了使不同计算机厂家生产的计算机能够相互通信，以便在更大的范围内建立计算机网络，国际标准化组织（ISO）在1978年提出了&amp;amp;quot;开放系统互联参考模型&amp;amp;quot;，即著名的OSI/RM模型（Open System Interconnection/Reference Model）。它将计算机网络体系结构的通信协议划分为七层，自下而上依次为：物理层（Physics Layer）、数据链路层（Data Link Layer）、网络层（Network Layer）、传输层（Transport Layer）、会话层（Session Layer）、表示层（Presentation Layer）、应用层（Application Layer）。其中第四层完成数据传送服务，上面三层面向用户。
osi七层协议 互联网协议按照功能不同分为osi七层或tcp/ip五层 物理层 物理层由来：上面提到，孤立的计算机之间要通信，就必须接入internet
物理层功能：主要是基于电器特性发送高低电压(电信号)，高电压对应数字1，低电压对应数字0
光纤： 双绞线：
数据链路层 数据链路层由来：单纯的电信号0和1没有任何意义，必须规定电信号多少位一组，每组什么意思
数据链路层的功能：定义了电信号的分组方式
以太网协议：
早期的时候各个公司都有自己的分组方式，后来形成了统一的标准，即以太网协议ethernet ethernet规定
一组电信号构成一个数据豹，叫做‘帧’ 每一数据帧分成：报头head和数据data两部分 head包含：(固定18个字节) 发送者／源地址，6个字节 接收者／目标地址，6个字节 数据类型，6个字节 data包含：(最短46字节，最长1500字节) 数据包的具体内容 head长度＋data长度＝最短64字节，最长1518字节，超过最大限制就分片发送 mac地址：
每块网卡出厂时都被烧制上一个世界唯一的mac地址，长度为48位2进制，通常由12位16进制数表示（前六位是厂商编号，后六位是流水线号）
广播：
有了mac地址，同一网络内的两台主机就可以通信了（一台主机通过arp协议获取另外一台主机的mac地址）
ethernet采用最原始的方式，广播的方式进行通信，即计算机通信***
网络层 网络层由来：有了ethernet、mac地址、广播的发送方式，世界上的计算机 …  </content></entry><entry><title>proto buffer</title><url>/post/microservice/protocol_buffer/</url><categories><category>microservice</category></categories><tags><tag>go</tag><tag>protobuf</tag></tags><content type="html">  protobuf是一种高效的数据格式，平台无关、语言无关、可扩展，可用于 RPC 系统和持续数据存储系统。
protobuf介绍 Protobuf是Protocol Buffer的简称，它是Google公司于2008年开源的一种高效的平台无关、语言无关、可扩展的数据格式，目前Protobuf作为接口规范的描述语言，可以作为Go语言RPC接口的基础工具。
protobuf使用 protobuf是一个与语言无关的一个数据协议，所以我们需要先编写IDL文件然后借助专用工具生成指定语言的代码，从而实现数据的序列化与反序列化过程。
大致开发流程如下： 1. IDL编写 2. 生成指定语言的代码 3. 序列化和反序列化
protobuf语法 官网： https://developers.google.cn/protocol-buffers/docs/proto3 (英文)
三方： https://colobu.com/2017/03/16/Protobuf3-language-guide (中文)
编译器安装 ptotoc mac安装：
brew info protobuf cdn下载：(下载需要的版本)
cdn下载链接 linux/mac 编译安装
教程 protoc-gen-go 安装生成Go语言代码的工具
两个版本：
github版本 github.com/golang/protobuf/protoc-gen-go google版本 google.golang.org/protobuf/cmd/protoc-gen-go 区别在于前者是旧版本，后者是google接管后的新版本，他们之间的API是不同的，也就是说用于生成的命令，以及生成的文件都是不一样的。
因为目前的gRPC-go源码中的example用的是后者的生成方式，为了与时俱进，本文也采取最新的方式。
安装：
go install google.golang.org/protobuf/cmd/protoc-gen-go@latest go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@latest 编写IDL代码 新建一个名为person.proto的文件具体内容如下：
// 指定使用protobuf版本 // 此处使用v3版本 syntax = …  </content></entry><entry><title>go mod</title><url>/post/go/go_mod/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html">  go module是 Go1.11版本之后官方推出的版本管理工具，并且从Go1.13版本开始，go module将是Go语言默认的依赖管理工具。
GO111MODULE 要启用go module支持首先要设置环境变量GO111MODULE，通过它可以开启或关闭模块支持，它有三个可选值：off、on、auto，默认值是auto。
GO111MODULE=off禁用模块支持，编译时会从GOPATH和vendor文件夹中查找包。
GO111MODULE=on启用模块支持，编译时会忽略GOPATH和vendor文件夹，只根据 go.mod下载依赖。
GO111MODULE=auto，当项目在$GOPATH/src外且项目根目录有go.mod文件时，开启模块支持。
简单来说，设置GO111MODULE=on之后就可以使用go module了，以后就没有必要在GOPATH中创建项目了，并且还能够很好的管理项目依赖的第三方包信息。
使用 go module 管理依赖后会在项目根目录下生成两个文件go.mod和go.sum。
GOPROXY Go1.11之后设置GOPROXY命令为：
1 export GOPROXY=https://goproxy.cn Go1.13之后GOPROXY默认值为https://proxy.golang.org，在国内是无法访问的，所以十分建议大家设置GOPROXY，这里我推荐使用 goproxy.cn 。
go env -w GOPROXY=https://goproxy.cn,direct go mod命令 常用的go mod命令如下：
go mod download 下载依赖的module到本地cache（默认为$GOPATH/pkg/mod目录） go mod edit 编辑go.mod文件 go mod graph 打印模块依赖图 go mod init 初始化当前文件夹, 创建go.mod文件 go mod tidy 增加缺少的module，删除无用的module go mod vendor 将依赖复制到vendor下 go mod verify 校验依赖 go mod why 解释为什么需要依赖 go.mod go.mod文件记录了项目所有的依赖信息，其结构大致如下：
module test go 1.15 require ( …  </content></entry><entry><title>golang 模板 htmltemplate与texttemplate</title><url>/post/go/golang_template_htmltemplate_and_texttemplate/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  html模板生成: html/template包实现了数据驱动的模板，用于生成可对抗代码注入的安全HTML输出。它提供了和text/template包相同的接口，Go语言中输出HTML的场景都应使用text/template包。 模板语法 {{.}} 模板语法都包含在{{和}}中间，其中{{.}}中的点表示当前对象。
当我们传入一个结构体对象时，我们可以根据.来访问结构体的对应字段。例如：
// main.go func sayHello(w http.ResponseWriter, r *http.Request) { // 解析指定文件生成模板对象 tmpl, err := template.ParseFiles(&amp;#34;./hello.html&amp;#34;) if err != nil { fmt.Println(&amp;#34;create template failed, err:&amp;#34;, err) return } var user = struct { name string age int }{ name:&amp;#34;zhaohaiyu&amp;#34;, age:18, } // 利用给定数据渲染模板，并将结果写入w tmpl.Execute(w, user) } func main() { http.HandleFunc(&amp;#34;/&amp;#34;, sayHello) err := http.ListenAndServe(&amp;#34;:9090&amp;#34;, nil) if err != nil { fmt.Println(&amp;#34;HTTP server failed,err:&amp;#34;, err) return } } Hello 姓名 {{.Name}} 年龄：{{.Age}} 同理，当我们传入的变量是map时，也可以在模板文件中通过.根据key来取值。 注释 {{/* a comment */}}
pipeline pipeline是指产生数据的操作。比如{{.}}、{{.Name}}等。Go的模板语法中支持使用管道符号|链接多个命令，用法和unix下的管道类似：|前面的命令会将运算结果(或返回值)传递给后一个命令的最后一个位置。 **注意：**并不是只有使用了|才是pipeline。Go的模板语法中，pipeline的概念是传递数据，只要能产生数据的，都 …  ]]></content></entry><entry><title>golang 反射</title><url>/post/go/golang_reflection/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  变量的内在机制 Go语言中的变量是分为两部分的:
类型信息：预先定义好的元信息。 值信息：程序运行过程中可动态变化的。 反射介绍 反射是指在程序运行期对程序本身进行访问和修改的能力。程序在编译时，变量被转换为内存地址，变量名不会被编译器写入到可执行部分。在运行程序时，程序无法获取自身的信息。
支持反射的语言可以在程序编译期将变量的反射信息，如字段名称、类型信息、结构体信息等整合到可执行文件中，并给程序提供接口访问反射信息，这样就可以在程序运行期获取类型的反射信息，并且有能力修改它们。
Go程序在运行期使用reflect包访问程序的反射信息。
在上一篇博客中我们介绍了空接口。 空接口可以存储任意类型的变量，那我们如何知道这个空接口保存的数据是什么呢？ 反射就是在运行时动态的获取一个变量的类型信息和值信息。
reflect包 在Go语言的反射机制中，任何接口值都由是一个具体类型和具体类型的值两部分组成的(我们在上一篇接口的博客中有介绍相关概念)。 在Go语言中反射的相关功能由内置的reflect包提供，任意接口值在反射中都可以理解为由reflect.Type和reflect.Value两部分组成，并且reflect包提供了reflect.TypeOf和reflect.ValueOf两个函数来获取任意对象的Value和Type。
reflect.Type 和 reflect.Value 反射是由 reflect 包提供的。它定义了两个重要的类型，Type 和 Value。一个 Type 表示一个Go类型。它是一个接口，有许多方法来区分类型以及检查它们的组成部分，例如一个结构体的成员或一个函数的参数等。唯一能反映 reflect.Type 实现的是接口的类型描述信息（§7.5），也正是这个实体标识了接口值的动态类型。
函数 reflect.TypeOf 接受任意的 interface{} 类型，并以 reflect.Type 形式返回其动态类型：
t := reflect.TypeOf(3) // a reflect.Type fmt.Println(t.String()) // &amp;#34;int&amp;#34; fmt.Println(t) // &amp;#34;int&amp;#34; 其中 TypeOf(3) 调用将值 3 传给 interface{} 参数。回到 7.5节 的将一个具体 …  ]]></content></entry><entry><title>Gin框架介绍及使用</title><url>/post/go/introduction_and_use_of_gin_framework/</url><categories><category>go</category></categories><tags><tag>go</tag><tag>gin</tag></tags><content type="html"><![CDATA[  Gin框架介绍 基于 httprouter 开发的Web框架。 中文文档 ，齐全。 简单易用的轻量级框架。 Gin框架安装 go get -u github.com/gin-gonic/gin 实例:
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;github.com/gin-gonic/gin&amp;#34; ) func main() { r := gin.Default() // 创建一个默认的路由引擎 // 也可以用gin.New() gin.Default()多用了日志和panic的recover中间件 r.GET(&amp;#34;/helloworld&amp;#34;, func(c *gin.Context) { c.JSON(200, gin.H{ // c.JSON：返回JSON格式的数据 &amp;#34;msg&amp;#34;: &amp;#34;Hello world!&amp;#34;, }) }) err := r.Run(&amp;#34;127.0.0.1:8001&amp;#34;) // 启动HTTP服务，默认在127.0.0.1:8001启动服务 if err != nil { fmt.Println(&amp;#34;run gin field&amp;#34;) return } } RESTful API REST与技术无关，代表的是一种软件架构风格，REST是Representational State Transfer的简称，中文翻译为“表征状态转移”或“表现层状态转化”。
简单来说，REST的含义就是客户端与Web服务器之间进行交互的时候，使用HTTP协议中的4个请求方法代表不同的动作。
GET用来获取资源 POST用来新建资源 PUT用来更新资源 DELETE用来删除资源。 只要API程序遵循了REST风格，那就可以称其为RESTful API。目前在前后端分离的架构中，前后端基本都是通过RESTful API来进行交互。
例如，我们现在要编写一个管理书籍的系统，我们可以查询对一本书进行查询、创建、更新和删除等操作，我们在编写程序的时候就要设计客户端浏览器与我们Web服务端交互的方式和路径。按照经验我们通常会设计成如下模式：
请求方法 URL 含义 GET /book 查询书籍信息 POST /create_book 创建书籍记录 POST …  ]]></content></entry><entry><title>goalng包和命令工具</title><url>/post/go/goalng_package_and_command_tools/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  包简介 任何包系统设计的目的都是为了简化大型程序的设计和维护工作，通过将一组相关的特性放进一个独立的单元以便于理解和更新，在每个单元更新的同时保持和程序中其它单元的相对独立性。这种模块化的特性允许每个包可以被其它的不同项目共享和重用，在项目范围内、甚至全球范围统一的分发和复用。
每个包一般都定义了一个不同的名字空间用于它内部的每个标识符的访问。每个名字空间关联到一个特定的包，让我们给类型、函数等选择简短明了的名字，这样可以在使用它们的时候减少和其它部分名字的冲突。
每个包还通过控制包内名字的可见性和是否导出来实现封装特性。通过限制包成员的可见性并隐藏包API的具体实现，将允许包的维护者在不影响外部包用户的前提下调整包的内部实现。通过限制包内变量的可见性，还可以强制用户通过某些特定函数来访问和更新内部变量，这样可以保证内部变量的一致性和并发时的互斥约束。
包的导入 每个包是由一个全局唯一的字符串所标识的导入路径定位。出现在import语句中的导入路径也是字符串。
import ( &amp;#34;fmt&amp;#34; &amp;#34;math/rand&amp;#34; &amp;#34;encoding/json&amp;#34; &amp;#34;golang.org/x/net/html&amp;#34; &amp;#34;github.com/go-sql-driver/mysql&amp;#34; ) 包声明 在每个Go语言源文件的开头都必须有包声明语句。包声明语句的主要目的是确定当前包被其它包导入时默认的标识符（也称为包名）。
通常来说，默认的包名就是包导入路径名的最后一段，因此即使两个包的导入路径不同，它们依然可能有一个相同的包名。例如，math/rand包和golang.org/x/exp/rand包的包名都是rand。
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;math/rand&amp;#34; ) // 导入rand包 用rand包里的方法函数等 func main() { fmt.Println(rand.Int63n(10000)) // 9410 } package main import ( &amp;#34;fmt&amp;#34; &amp;#34;golang.org/x/exp/rand&amp;#34; ) func main() { fmt.Println(rand.Int63n(10000)) …  ]]></content></entry><entry><title>golang 单元测试</title><url>/post/go/golang_unit_testing/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html">  go test go test命令是一个按照一定的约定和组织来测试代码的程序。在包目录内，所有以_test.go为后缀名的源文件在执行go build时不会被构建成包的一部分，它们是go test测试的一部分。
go test命令会遍历所有的*_test.go文件中符合上述命名规则的函数，生成一个临时的main包用于调用相应的测试函数，接着构建并运行、报告测试结果，最后清理测试中生成的临时文件。
在*_test.go文件中有三种类型的函数，单元测试函数、基准测试函数和示例函数。
类型 格式 作用 测试函数 函数名前缀为Test 测试程序的一些逻辑行为是否正确 基准函数 函数名前缀为Benchmark 测试函数的性能 示例函数 函数名前缀为Example 为文档提供示例文档 测试函数 每个测试函数必须导入testing包。测试函数有如下的签名：
func TestName(t *testing.T) { // ... } 测试函数的名字必须以Test开头，可选的后缀名必须以大写字母开头：
func TestSin(t *testing.T) { /* ... */ } func TestCos(t *testing.T) { /* ... */ } func TestLog(t *testing.T) { /* ... */ } 其中参数t用于报告测试失败和附加的日志信息。testing.T的拥有的方法如下：
func (c *T) Error(args ...interface{}) func (c *T) Errorf(format string, args ...interface{}) func (c *T) Fail() func (c *T) FailNow() func (c *T) Failed() bool func (c *T) Fatal(args ...interface{}) func (c *T) Fatalf(format string, args ...interface{}) func (c *T) Log(args ...interface{}) func (c *T) Logf(format string, args ...interface{}) func (c *T) Name() string func (t *T) …  </content></entry><entry><title>golang context包</title><url>/post/go/golang_context_package/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html">  go context标准库 context包在Go1.7版本时加入到标准库中。其设计目标是给Golang提供一个标准接口来给其他任务发送取消信号和传递数据。其具体作用为：
可以通过context发送取消信号。
可以指定截止时间（Deadline)，context在截止时间到期后自动发送取消信号。
可以通过context传输一些数据。
context在Golang中最主要的用途是控制协程任务的取消，但是context除了协程以外也可以用在线程控制等非协程的情况。
基本概念 context的核心是其定义的Context接口类型。围绕着Context接口类型存在两种角色：
父任务：创建Context，将Context对象传递给子任务，并且根据需要发送取消信号来结束子任务。
子任务：使用Context类型对象，当收到父任务发来的取消信号，结束当前任务并退出。
接下来我们从这两个角色的视角分别看一下Context对象。
context接口 type Context interface { Deadline() (deadline time.Time, ok bool) Done() chan struct{} Err() error Value(key interface{}) interface{} } Deadline方法需要返回当前Context被取消的时间，也就是完成工作的截止时间（deadline）；
Done方法需要返回一个Channel，这个Channel会在当前工作完成或者上下文被取消之后关闭，多次调用Done方***返回同一个Channel；
Err方***返回当前Context结束的原因，它只会在Done返回的Channel被关闭时才会返回非空的值；
如果当前Context被取消就会返回Canceled错误；
如果当前Context超时就会返回DeadlineExceeded错误；
Value方***从Context中返回键对应的值，对于同一个上下文来说，多次调用Value 并传入相同的Key会返回相同的结果，该方法仅用于传递跨API和进程间跟请求域的数据；
Background()和TODO() Go内置两个函数：Background()和TODO()，这两个函数分别返回一个实现了Context接口的background和todo。我们代码中最开始都是以 …  </content></entry><entry><title>golang channel</title><url>/post/go/golang_channel/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  什么是channel channels 是一种类型安全的消息队列，充当两个 goroutine 之间的管道，将通过它同步的进行任意资源的交换。chan 控制 goroutines 交互的能力从而创建了 Go 同步机制。当创建的 chan 没有容量时，称为无缓冲通道。反过来，使用容量创建的 chan 称为缓冲通道。
要了解通过 chan 交互的 goroutine 的同步行为是什么，我们需要知道通道的类型和状态。根据我们使用的是无缓冲通道还是缓冲通道，场景会有所不同，所以让我们单独讨论每个场景。
无缓冲管道 make ： ch := make(chan struct{}) 无缓冲 chan 没有容量，因此进行任何交换前需要两个 goroutine 同时准备好。当 goroutine 试图将一个资源发送到一个无缓冲的通道并且没有goroutine 等待接收该资源时，该通道将锁住发送 goroutine 并使其等待。当 goroutine 尝试从无缓冲通道接收，并且没有 goroutine 等待发送资源时，该通道将锁住接收 goroutine 并使其等待。
无缓冲信道的本质是保证同步。
无缓冲channel在消息发送时需要接收者就绪。声明无缓冲channel的方式是不指定缓冲大小。以下是一个列子：
package main import ( &amp;#34;sync&amp;#34; &amp;#34;time&amp;#34; ) func main() { c := make(chan string) var wg sync.WaitGroup wg.Add(2) go func() { defer wg.Done() c &amp;lt;- `foo` }() go func() { defer wg.Done() time.Sleep(time.Second * 1) println(`Message: `+ &amp;lt;-c) }() wg.Wait() } 第一个协程会在发送消息foo时阻塞，原因是接收者还没有就绪：这个特性在 标准文档 中描述如下：
如果缓冲大小设置为0或者不设置，channel为无缓冲类型，通信成功的前提是发送者和接收者都处于就绪状态。
effective Go 文档也有相应的描述：
无缓冲channel，发送者会阻塞直到接收者接收了发送的值。
为了更好的理解channel的特性， …  ]]></content></entry><entry><title>golang并发</title><url>/post/go/golang_concurrency/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  goroutine goroutine是Go并行设计的核心。goroutine说到底其实就是线程，但是它比线程更小，十几个goroutine可能体现在底层就是五六个线程，Go语言内部帮你实现了这些goroutine之间的内存共享。执行goroutine只需极少的栈内存(大概是4~5KB)，当然会根据相应的数据伸缩。也正因为如此，可同时运行成千上万个并发任务。goroutine比thread更易用、更高效、更轻便。
goroutine是通过Go的runtime管理的一个线程管理器。goroutine通过go关键字实现了，其实就是一个普通的函数。
go hello(a, b, c) 通过关键字go就启动了一个goroutine。我们来看一个例子
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;runtime&amp;#34; ) func say(s string) { for i := 0; i &amp;lt; 5; i++ { runtime.Gosched() fmt.Println(s) } } func main() { go say(&amp;#34;world&amp;#34;) //开一个新的Goroutines执行 say(&amp;#34;hello&amp;#34;) //当前Goroutines执行 } // 以上程序执行后将输出： // hello // world // hello // world // hello // world // hello // world // hello 我们可以看到go关键字很方便的就实现了并发编程。 上面的多个goroutine运行在同一个进程里面，共享内存数据，不过设计上我们要遵循：不要通过共享来通信，而要通过通信来共享。
goroutine的调度机制 Go runtime的调度器： 在了解Go的运行时的scheduler之前，需要先了解为什么需要它，因为我们可能会想，OS内核不是已经有一个线程scheduler了嘛？ 熟悉POSIX API的人都知道，POSIX的方案在很大程度上是对Unix process进场模型的一个逻辑描述和扩展，两者有很多相似的地方。 Thread有自己的信号掩码，CPU affinity等。但是很多特征对于Go程序来说都是累赘。 尤其是context上下文切换的耗时。另一个原因是Go的垃 …  ]]></content></entry><entry><title>go语言文件系统</title><url>/post/go/go_language_file_system/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  检测文件是否存在 //存在返回 true，不存在返回 false func fileIfExist(filename string) bool { _, err := os.Stat(filename) if nil != err { fmt.Println(filename, &#34;is not exist!&#34;) return false } if os.IsNotExist(err) { return false } return true } 打开文件 f, err := os.Open(filename) if nil != err { fmt.Println(&#34;open&#34;, filename, &#34;failed!&#34;) return } defer f.Close() 如果文件不存在，就会返回错误，如果存在就以只读的方式打开文件。
还可以使用 os.OpenFile() 打开文件，达到不存在就新建，存在就清空（os.O_TRUNC）的目的。当然，也可以不清空文件（os.O_APPEND）。
f, err := os.OpenFile(filename, os.O_RDWR | os.O_CREATE | os.O_TRUNC, 0666) if nil != err { fmt.Println(&#34;create&#34;, filename, &#34;failed!&#34;) return } defer f.Close() 新建文件 f, err := os.Create(filename) if nil != err { fmt.Println(&#34;create&#34;, filename, &#34;failed!&#34;) return } defer f.Close() 注意：如果文件已经存在，那么 os.Create() 会将文件清空。可以使用 os.OpenFile() 新建文件， 参数 flag 为 os.O_CREATE | os.O_EXCL。如果文件已经存在，那么该函数就会返回错误。
f, err := os.OpenFile(filename, os.O_CREATE | os.O_EXCL, 0666) if nil != err { fmt.Println(&#34;create&#34;, filename, &#34;failed!&#34;) return } defer f.Close() 读取文件 读取全部内容 content := make([]byte, 1024) //需要预先分配空间 f, _ := os.Open(filename) defer f.Close() _, err := f.Read(content) if nil != err { fmt.Println(&#34;read&#34;, filename, &#34;failed!&#34;) return } 读取文件内容可以使用 File 的方法——Read。但是使用该方法时需要预先分配空间，用于存储读取的文件内容。我们当然可以提前获取文件的大小，但是这种方式仍然不如 ioutil.ReadAll() 方便。甚至可以直接使用 ioutil.ReadFile()。
ioutil.ReadAll()：
f, _ := os.Open(filename) defer f.Close() content, err := ioutil.ReadAll(f) if nil != err { fmt.Println(&#34;read&#34;, filename, &#34;failed!&#34;) return } fmt.Println(string(content)) ioutil.ReadFile()：
content, err := ioutil.ReadFile(filename) if nil != err { fmt.Println(&#34;read&#34;, filename, &#34;failed!&#34;) return } fmt.Println(string(content)) 按行读取 f, _ := os.Open(filename) defer f.Close() scanner := bufio.NewScanner(f) //按行读取 for scanner.Scan() { fmt.Println(scanner.Text()) //输出文件内容 } 写入文件 f, _ := os.OpenFile(filename, os.O_WRONLY | os.O_APPEND, 0666) defer f.Close() _, err = f.WriteString(&#34;target_compile_option&#34;) if nil != err { fmt.Println(err) } 这里使用 os.OpenFile() 以追加的方式打开文件。为什么不使用 os.Open() 打开文件呢？因为 os.Open() 是以只读的方式打开文件，无法向文件写入数据。
我们也可以使用 ioutil.WriteFile() 写文件。
writeContent := &#34;write file test&#34; err = ioutil.WriteFile(filename, []byte(writeContent), os.ModePerm) if nil != err { fmt.Println(&#34;write&#34;, filename, &#34;failed!&#34;) } 注意：使用 ioutil.WriteFile(filename string, data []byte, perm os.FileMode) 向文件中写入时，如果文件存在，文件会先被清空，然后再写入。如果文件不存在，就会以 perm 权限先创建文件，然后再写入。
关闭文件 直接调用 File 的 Close() 方法。
f, _ := os.Open(filename) f.Close() 最好使用 defer 关键字执行 Close() 方法，这样能够保证函数退出时文件能被关闭。
删除文件 err := os.Remove(filename) 删除文件前确保文件没有被其他程序使用。如果在当前程序中该文件已被打开，需要先关闭（Close()）文件。
  ]]></content></entry><entry><title>golang方法</title><url>/post/go/golang_method/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  方法声明 在函数声明时，在其名字之前放上一个变量，即是一个方法。这个附加的参数会将该函数附加到这种类型上，即相当于为这种类型定义了一个独占的方法。
package main import &#34;fmt&#34; type People struct { name string age uint8 } func (p People) SayHello() { fmt.Println(p.name, &#34;: hello world&#34;) p.age = 20 } func main() { p := People{name: &#34;zhaohaiyu&#34;, age: 18} p.SayHello() // zhaohaiyu : hello world fmt.Println(p.age)	//18 } 基于指针对象的方法 当调用一个函数时，会对其每一个参数值进行拷贝，如果一个函数需要更新一个变量，或者函数的其中一个参数实在太大我们希望能够避免进行这种默认的拷贝，这种情况下我们就需要用到指针了。
package main import &#34;fmt&#34; type People struct { name string age uint8 } func (p *People) SayHello() { fmt.Println(p.name, &#34;: hello world&#34;) p.age = 20 } func main() { p := People{name: &#34;zhaohaiyu&#34;, age: 18} p.SayHello() // zhaohaiyu : hello world fmt.Println(p.age)	// 20 } 调用时p为person的结构体对象,SayHello是People结构体指针的方法,在go中可以直接调用,亦可以(&amp;p).SayHello()
Nil也是一个合法的接收器类型
package main import &#34;fmt&#34; type MySlice []int func (m *MySlice) sum() int { var num int for _, i := range *m { num += i } return num } func main() { m := MySlice{1,2,3,4,5} fmt.Println(m.sum()) // 15 m = nil fmt.Println(m.sum()) // 0 } 封装 一个对象的变量或者方法如果对调用方是不可见的话，一般就被定义为“封装”。封装有时候也被叫做信息隐藏，同时也是面向对象编程最关键的一个方面。
Go语言只有一种控制可见性的手段：大写首字母的标识符会从定义它们的包中被导出，小写字母的则不会。这种限制包内成员的方式同样适用于struct或者一个类型的方法。因而如果我们想要封装一个对象，我们必须将其定义为一个struct。
这也就是前面的小节中IntSet被定义为struct类型的原因，尽管它只有一个字段：
type IntSet struct { words []uint64 } 当然，我们也可以把IntSet定义为一个slice类型，尽管这样我们就需要把代码中所有方法里用到的s.words用*s替换掉了：
type IntSet []uint64   ]]></content></entry><entry><title>golang复杂数据结构</title><url>/post/go/golang_complex_data_structure/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html">  数组 **数组是一个由固定长度的特定类型元素组成的序列，一个数组可以由零个或多个元素组成。**因为数组的长度是固定的，因此在Go语言中很少直接使用数组。
数组的每个元素可以通过索引下标来访问，索引下标的范围是从0开始到数组长度减1的位置。内置的len函数将返回数组中元素的个数。
var a [3]int // 长度为3的数组 fmt.Println(a[0]) // 打印第一个数据 fmt.Println(a[len(a)-1]) // 打印最后一个数据 for i, v := range a { fmt.Printf(&amp;amp;#34;%d %d\n&amp;amp;#34;, i, v) // 循环数组 i为索引 v为数据 } 默认情况下，数组的每个元素都被初始化为元素类型对应的零值
数组的初始化:
var a [3]int = [3]int{1, 2, 3} b := [...]int{1, 2, 3} a = [4]int{1, 2, 3, 4} // panic 数据初始化就是定长了 长度不能变化 切片 Slice（切片）代表变长的序列，序列中每个元素都有相同的类型。一个slice类型一般写作[]T，其中T代表slice中元素的类型；slice的语法和数组很像，只是没有固定长度而已。
一个slice由三个部分构成：指针、长度和容量。指针指向第一个slice元素对应的底层数组元素的地址，要注意的是slice的第一个元素并不一定就是数组的第一个元素。长度对应slice中元素的数目；长度不能超过容量，容量一般是从slice的开始位置到底层数据的结尾位置。内置的len和cap函数分别返回slice的长度和容量。
多个slice之间可以共享底层的数据，并且引用的数组部分区间可能重叠。
使用make()函数构造切片
make([]T, size, cap) // T:切片类型 size 切片数量 cap 切片容量 append()方法为切片添加元素
sli := make([]int,0,10) sli = append(sli,1)	// 添加一个 1 arr := [4]int{6,7,8,9} sli = append(sle,arr...) // 把arr打散并全部添加 添加多个 fmt.Println(sli) // [1 6 7 8 9] 从切片中删除元素
// …  </content></entry><entry><title>golang函数</title><url>/post/go/golang_function/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  函数声明 函数声明包括函数名、形式参数列表、返回值列表（可省略）以及函数体。
func function-name(param...) (result...) { body } 形式参数列表描述了函数的参数名以及参数类型。这些参数作为局部变量，其值由参数调用者提供。返回值列表描述了函数返回值的变量名以及类型。如果函数返回一个无名变量或者没有返回值，返回值列表的括号是可以省略的。如果一个函数声明不包括返回值列表，那么函数体执行完毕后，不会返回任何值。
func hypot(x, y float64) float64 { return math.Sqrt(x*x + y*y) } fmt.Println(hypot(3,4)) // &amp;#34;5&amp;#34; 递归 函数可以是递归的，这意味着函数可以直接或间接的调用自身。对许多问题而言，递归是一种强有力的技术，例如处理递归的数据结构。
func a(i int) (res int){ if i == 1 { return i } return i * a(i - 1) } fmt.Println(a(5)) // 120 多返回值 在Go中，一个函数可以返回多个值。
func calculation(a,b int)(add,sub int) { add = a + b sub = a - b } 错误 在Go中有一部分函数总是能成功的运行，对各种可能的输入都做了良好的处理，使得运行时几乎不会失败，除非遇到灾难性的、不可预料的情况，比如运行时的内存溢出。导致这种错误的原因很复杂，难以处理，从错误中恢复的可能性也很低。
panic是来自被调函数的信号，表示发生了某个已知的bug。一个良好的程序永远不应该发生panic异常。
value, ok := cache.Lookup(key) if !ok { // ...cache[key] does not exist… } 错误处理策略 当一次函数调用返回错误时，调用者有应该选择何时的方式处理错误。根据情况的不同，有很多处理方式.
resp,err := http.Get(&amp;#34;https://www.google.com&amp;#34;) if err != nil { fmt.Println(err) } 文件结尾错误（EOF） 函数经常会返回多种错误，这对终端用户来说可能会 …  ]]></content></entry><entry><title>golang基础结构</title><url>/post/go/golang_infrastructure/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html">  命名 Go语言中的函数名、变量名、常量名、类型名、语句标号和包名等所有的命名,都遵循一个简单的命名规则：一个名字必须以一个字母（Unicode字母）或下划线开头,后面可以跟任意数量的字母、数字或下划线.大写字母和小写字母是不同的：heapSort和Heapsort是两个不同的名字.
Go语言的关键字有25个,关键字不能用于自定义名字. 分别为:
break default func interface select case defer go map struct chan else goto package switch const fallthrough if range type continue for import return var 还有大约30多个预定义的名字,这些内部预先定义的名字并不是关键字，你可以在定义中重新使用它们。在一些特殊的场景中重新定义它们也是有意义的，但是也要注意避免过度而引起语义混乱.
内建常量: true false iota nil 内建类型: int int8 int16 int32 int64 uint uint8 uint16 uint32 uint64 uintptr float32 float64 complex128 complex64 bool byte rune string error 内建函数: make len cap new append copy close delete complex real imag panic recover 在习惯上，Go语言程序员推荐使用 驼峰式 命名，当名字有几个单词组成的时优先使用大小写分隔，而不是优先用下划线分隔。
声明 Go语言主要有四种类型的声明语句：var、const、type和func，分别对应变量、常量、类型和函数实体对象的声明。
一个Go语言编写的程序对应一个或多个以.go为文件后缀名的源文件中。每个源文件以包的声明语句开始，说明该源文件是属于哪个包。包声明语句之后是import语句导入依赖的其它包，然后是包一级的类型、变量、常量、函数的声明语句.
package main // main包 import &amp;amp;#34;fmt&amp;amp;#34; // 引入fmt内部包 const price = 212.0 // 浮点型常量 func main() { var f = …  </content></entry><entry><title>golang基础类型</title><url>/post/go/golang_basic_types/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  整型 Go语言同时提供了有符号和无符号类型的整数运算。这里有int8、int16、int32和int64四种截然不同大小的有符号整数类型，分别对应8、16、32、64bit大小的有符号整数，与此对应的是uint8、uint16、uint32和uint64四种无符号整数类型。
Unicode字符rune类型是和int32等价的类型，通常用于表示一个Unicode码点。这两个名称可以互换使用。同样byte也是uint8类型的等价类型，byte类型一般用于强调数值是一个原始的数据而不是一个小的整数。
下面是Go语言中关于算术运算、逻辑运算和比较运算的二元运算符，它们按照优先级递减的顺序排列：
* / % &amp;gt; &amp;amp; &amp;amp;^ + - | ^ == != &amp;gt;= &amp;amp;&amp;amp; || 两个相同的整数类型可以使用下面的二元比较运算符进行比较；比较表达式的结果是布尔类型。
== // 等于 != // 不等于 &amp;lt; // 小于 &amp;lt;= // 小于等于 &amp;gt; // 大于 &amp;gt;= // 大于等于 浮点型 Go语言提供了两种精度的浮点数，float32和float64。它们的算术规范由IEEE754浮点数国际标准定义，该浮点数规范被所有现代的CPU支持。
float32类型的浮点数可以提供大约6个十进制数的精度，而float64则可以提供约15个十进制数的精度；通常应该优先使用float64类型，因为float32类型的累计计算误差很容易扩散，
var f float32 = 212213 fmt.Println(f == f + 1) 复数 Go语言提供了两种精度的复数类型：complex64和complex128，分别对应float32和float64两种浮点数精度。内置的complex函数用于构建复数，内建的real和imag函数分别返回复数的实部和虚部：
var x complex128 = complex(1, 2) // 1+2i var y complex128 = complex(3, 4) // 3+4i fmt.Println(x*y) // &amp;#34;(-5+10i)&amp;#34; fmt.Println(real(x*y)) // &amp;#34;-5&amp;#34; fmt.Println(imag(x*y)) // …  ]]></content></entry><entry><title>golang接口</title><url>/post/go/golang_interface/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  接口的定义 接口类型是对其它类型行为的抽象和概括；因为接口类型不会和特定的实现细节绑定在一起，通过这种抽象的方式我们可以让我们的函数更加灵活和更具有适应能力。
很多面向对象的语言都有相似的接口概念，但Go语言中接口类型的独特之处在于它是满足隐式实现的。也就是说，我们没有必要对于给定的具体类型定义所有满足的接口类型；简单地拥有一些必需的方法就足够了。这种设计可以让你创建一个新的接口类型满足已经存在的具体类型却不会去改变这些类型的定义；当我们使用的类型来自于不受我们控制的包时这种设计尤其有用。
接口（interface）定义了一个对象的行为规范，只定义规范不实现，由具体的对象来实现规范的细节。接口类型是一种抽象的类型。它不会暴露出它所代表的对象的内部值的结构和这个对象支持的基础操作的集合；它们只会展示出它们自己的方法。也就是说当你有看到一个接口类型的值时，你不知道它是什么，唯一知道的就是可以通过它的方法来做什么。
package main import &amp;#34;fmt&amp;#34; type canSay interface{ Say() } type dog struct { name string } type cat struct { name string } func (d dog) Say() { fmt.Println(d.name,&amp;#34;say&amp;#34;) } func main() { var tom2 canSay tom := dog{name: &amp;#34;汤姆&amp;#34;} tom2 = tom tom2.Say() // 汤姆 say mi := cat{name: &amp;#34;猫咪&amp;#34;} tom2 = mi // 报错 因为cat没有实现接口规定的say方法 } 接口值 接口值，由两个部分组成，一个具体的类型和那个类型的值。它们被称为接口的动态类型和动态值。在我们的概念模型中，一些提供每个类型信息的值被称为类型描述符，比如类型的名称和方法。在一个接口值中，类型部分代表与之相关类型的描述符。
package main import ( &amp;#34;bytes&amp;#34; &amp;#34;fmt&amp;#34; &amp;#34;io&amp;#34; &amp;#34;os&amp;#34; ) func main() { var w io.Writer fmt.Printf(&amp;#34; …  ]]></content></entry><entry><title>golang time包</title><url>/post/go/golang_time_package/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  时间类型 time.Time类型表示时间。
func demo() { now := time.Now() //获取当前时间 fmt.Printf(&#34;Now:%v\n&#34;, now) // Now:2020-08-19 21:53:31.1633023 +0800 CST m=+0.003989401 year := now.Year() //年 month := now.Month() //月 day := now.Day() //日 hour := now.Hour() //小时 minute := now.Minute() //分钟 second := now.Second() //秒 fmt.Printf(&#34;%d-%02d-%02d %02d:%02d:%02d\n&#34;, year, month, day, hour, minute, second) // 2020-08-19 21:53:31 } 时间戳 func stamp() { now := time.Now() //获取当前时间 timestamp1 := now.Unix() //时间戳 timestamp2 := now.UnixNano() //纳秒时间戳 fmt.Printf(&#34;秒时间戳:%v\n&#34;, timestamp1) // 秒时间戳:1597845356 fmt.Printf(&#34;纳秒时间戳:%v\n&#34;, timestamp2) // 纳秒时间戳:1597845356562315400 } 使用time.Unix()函数可以将时间戳转为时间格式。
func demo2(timestamp int64) { timeObj := time.Unix(1462032000, 0) //将时间戳转为时间格式 fmt.Println(timeObj) // 2016-05-01 00:00:00 +0800 CST } 时间格式化 时间类型有一个自带的方法Format进行格式化，需要注意的是Go语言中格式化时间模板不是常见的Y-m-d H:M:S而是使用Go的诞生时间2006年1月2号15点04分
func demo4() { now := time.Now() fmt.Println(now.Format(&#34;2006-01-02 15:04:05.000 Mon Jan&#34;)) // 2020-08-19 22:02:46.296 Wed Aug fmt.Println(now.Format(&#34;2006-01-02 03:04:05.000 PM Mon Jan&#34;)) // 2020-08-19 10:02:46.296 PM Wed Aug fmt.Println(now.Format(&#34;2006*01*02&#34;)) // 2020*08*19 } 解析字符串格式的时间
// 加载时区 loc, err := time.LoadLocation(&#34;Asia/Shanghai&#34;) if err != nil { fmt.Println(err) return } // 解析字符串时间 timeObj, err := time.ParseInLocation(&#34;2006/01/02 15:04:05&#34;, &#34;2016/04/30 22:00:00&#34;, loc) if err != nil { fmt.Println(err) return } fmt.Println(timeObj) // 2016-04-30 22:00:00 +0800 CST fmt.Println(timeObj.Unix()) // 1462024800 时间操作 func (t Time) Add(d Duration) Time加时间 func (t Time) Sub(u Time) Duration减时间 func (t Time) Before(u Time) bool在u之前 func (t Time) After(u Time) bool在u之后 package main import ( &#34;fmt&#34; &#34;time&#34; ) func formatDemo() { now := time.Now() fmt.Println(now.Format(&#34;2006-01-02 15:04:05.000 Mon Jan&#34;)) // 2020-08-19 22:02:46.296 Wed Aug fmt.Println(now.Format(&#34;2006-01-02 03:04:05.000 PM Mon Jan&#34;)) // 2020-08-19 10:02:46.296 PM Wed Aug fmt.Println(now.Format(&#34;2006*01*02&#34;)) // 2020*08*19 } func main() { // 加载时区 loc, err := time.LoadLocation(&#34;Asia/Shanghai&#34;) if err != nil { fmt.Println(err) return } // 解析字符串时间 timeObj, err := time.ParseInLocation(&#34;2006/01/02 15:04:05&#34;, &#34;2016/04/30 22:00:00&#34;, loc) if err != nil { fmt.Println(err) return } fmt.Println(timeObj) // 2016-04-30 22:00:00 +0800 CST now := time.Now() a := now.Add(time.Hour) fmt.Println(a) // 2020-08-19 23:15:30.0153059 +0800 CST m=+3600.002023801 s := now.Sub(timeObj) fmt.Println(s) // 37728h15m30.0153059s fmt.Println(now.Before(timeObj)) // false fmt.Println(now.After(timeObj)) // true } 定时器 使用time.Tick(时间间隔)来设置定时器，定时器的本质上是一个channel
func tickDemo() { ticker := time.Tick(time.Second) //定义一个1秒间隔的定时器 for i := range ticker { fmt.Println(i) //每秒都会打印时间 } }   ]]></content></entry><entry><title>About me</title><url>/about/</url><categories/><tags/><content type="html">  Follow Me My Github My Bilibili My Email   </content></entry><entry><title>golang error错误处理</title><url>/post/go/golang_error_error_handling/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  error定义 数据结构 go语言error是一普通的值，实现方式为简单一个接口。
// The error built-in interface type is the conventional interface for // representing an error condition, with the nil value representing no error. type error interface { Error() string } 创建error
使用errors.New()
// New returns an error that formats as the given text. // Each call to New returns a distinct error value even if the text is identical. func New(text string) error { return &amp;amp;errorString{text} } // errorString is a trivial implementation of error. type errorString struct { s string } func (e *errorString) Error() string { return e.s } 返回的是errorString结构体 实现了error接口的Error()方法
使用fmt.Errorf（）创建
创建方式为把字符串拼接起来，然后调用errors.New().
基础库中的自定义的error bufio中的错误：
ErrTooLong = errors.New(&amp;#34;bufio.Scanner: token too long&amp;#34;) ErrNegativeAdvance = errors.New(&amp;#34;bufio.Scanner: SplitFunc returns negative advance count&amp;#34;) ErrAdvanceTooFar = errors.New(&amp;#34;bufio.Scanner: SplitFunc returns advance count beyond input&amp;#34;) ErrBadReadCount = …  ]]></content></entry><entry><title>golang fmt包</title><url>/post/go/golang_fmt_package/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html">  fmt fmt包实现了类似C语言printf和scanf的格式化I/O。主要分为向外输出内容和获取输入内容两大部分。
向外输出 标准库fmt提供了以下几种输出相关函数。
Print Print系列函数会将内容输出到系统的标准输出，区别在于Print函数直接输出内容，Printf函数支持格式化输出字符串，Println函数会在输出内容的结尾添加一个换行符。
func Print(a ...interface{}) (n int, err error) func Printf(format string, a ...interface{}) (n int, err error) func Println(a ...interface{}) (n int, err error) Fprint Fprint系列函数会将内容输出到一个io.Writer接口类型的变量w中，我们通常用这个函数往文件中写入内容。
func Fprint(w io.Writer, a ...interface{}) (n int, err error) func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) func Fprintln(w io.Writer, a ...interface{}) (n int, err error) Sprint Sprint系列函数会把传入的数据生成并返回一个字符串。
func Sprint(a ...interface{}) string func Sprintf(format string, a ...interface{}) string func Sprintln(a ...interface{}) string Errorf Errorf函数根据format参数生成格式化字符串并返回一个包含该字符串的错误。
func Errorf(format string, a ...interface{}) error 格式化占位符 *printf系列函数都支持format格式化参数，在这里我们按照占位符将被替换的变量类型划分，方便查询和记忆。
通用占位符 占位符 说明 %v 值的默认格式表示 %+v 类似%v，但输出结构体时会添加字段名 %#v 值的Go …  </content></entry></search>